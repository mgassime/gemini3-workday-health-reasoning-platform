{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè¢ Workday Health Reasoning Platform\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Sedentary work is one of the most underestimated modern health risks.**  \n",
    "The World Health Organization reports that **31% of adults worldwide (‚âà1.8 billion people)** are insufficiently physically active ‚Äî a pattern strongly linked to chronic disease risk and premature mortality. WHO also warns that insufficient physical activity is associated with a **20‚Äì30% higher risk of death**, and recommends actively reducing sedentary time throughout the day.  \n",
    "\n",
    "At the same time, long screen exposure has become the default. Digital Eye Strain (Computer Vision Syndrome) is widely reported among screen users, causing symptoms such as **dry eyes, blurred vision, headaches, and difficulty focusing**, especially when workdays are built around uninterrupted monitor time.\n",
    "\n",
    "The result is a predictable cycle for desk workers:  \n",
    "**back and neck pain ‚Üí fatigue ‚Üí low productivity ‚Üí stress ‚Üí worse sleep ‚Üí repeat.**\n",
    "\n",
    "The **Workday Health Reasoning Platform** is a **privacy-first, local-only, context-aware preventive health assistant** designed specifically for office and remote desk workers.  \n",
    "It helps users reflect on their daily workplace behaviors (posture, hydration, stress, eye strain, productivity, musculoskeletal symptoms, sleep recovery, and longitudinal lab trends) and then produces **clear, non-diagnostic, evidence-aligned recommendations**.\n",
    "\n",
    "This platform is not a symptom checker and does not attempt to replace clinicians.  \n",
    "Instead, it acts as a **structured reasoning layer** between everyday work habits and actionable prevention ‚Äî translating scattered inputs into practical steps, reminders, and habit nudges.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Problem & Target Users\n",
    "\n",
    "### The problem\n",
    "Desk work concentrates multiple risk factors into a single routine:\n",
    "- prolonged sitting and low movement,\n",
    "- poor posture and repetitive strain,\n",
    "- screen-based eye fatigue and headaches,\n",
    "- mental overload, stress, and burnout patterns,\n",
    "- inconsistent hydration, recovery, and sleep.\n",
    "\n",
    "Many existing tools either:\n",
    "- collect health data without generating meaningful guidance, or\n",
    "- rely on cloud-based processing that compromises privacy and user control.\n",
    "\n",
    "### Target users\n",
    "- Office and remote desk workers  \n",
    "- Knowledge workers with long screen hours  \n",
    "- Professionals with chronic fatigue, posture pain, or eye strain  \n",
    "- Health-conscious users who value **privacy, autonomy, and clarity**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Key Features\n",
    "\n",
    "- **Modular Health Tabs**  \n",
    "  Baseline, Workspace, MSK, Eye, Mental, Hydration, Productivity, Recovery/Sleep, Checklist, Reminders.\n",
    "\n",
    "- **Local-Only Storage (Privacy by Design)**  \n",
    "  All user data is stored locally as JSON ‚Äî no automatic uploads, no hidden telemetry.\n",
    "\n",
    "- **Context-Aware Reasoning**  \n",
    "  The system builds a cross-domain context from real user inputs, allowing the assistant to detect patterns (e.g., hydration + headaches + screen time + poor sleep).\n",
    "\n",
    "- **Safety Guardrails**  \n",
    "  Explicit checks for high-risk signals (e.g., severe symptoms, mental distress keywords, extreme values) to trigger urgent warnings.\n",
    "\n",
    "- **Optional AI Integration (Graceful Fallback)**  \n",
    "  Uses a language model only when configured; otherwise runs locally with safe placeholder logic.\n",
    "\n",
    "- **Actionable Output, Not Just Tracking**  \n",
    "  Generates clear recommendations plus structured **tasks and reminders** that convert insight into daily behavior change.\n",
    "\n",
    "- **Internationalization (i18n)**  \n",
    "  Built-in multilingual support (English & Arabic included), designed for global deployment.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Architecture & Data\n",
    "\n",
    "The platform is built around a simple but powerful principle:\n",
    "\n",
    "**Collect structured user inputs ‚Üí build contextual memory ‚Üí apply reasoning ‚Üí output practical prevention guidance.**\n",
    "\n",
    "Each module stores user entries and AI outputs in domain-specific JSON files.  \n",
    "A lightweight shared context layer allows cross-domain summaries without exposing raw histories, enabling explainable reasoning while maintaining performance and privacy.\n",
    "\n",
    "This notebook is a **self-contained, executable skeleton** demonstrating:\n",
    "- how user health inputs are collected,\n",
    "- how context is constructed across domains,\n",
    "- how safe reasoning is applied,\n",
    "- and how the full system runs locally with optional AI support.\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Why This Matters\n",
    "\n",
    "Workplace health is not only a medical issue ‚Äî it is a productivity and sustainability issue.  \n",
    "Preventable desk-work habits contribute to pain, fatigue, reduced concentration, and long-term chronic risk.  \n",
    "By turning routine behaviors into actionable guidance, this platform helps individuals regain control over their health **without giving up their data**.\n",
    "\n",
    "The goal is simple:\n",
    "\n",
    "**help desk workers build healthier workdays ‚Äî one small decision at a time.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba414526",
   "metadata": {},
   "source": [
    "\n",
    "**Key design choice:**  \n",
    "The AI never sees raw historical logs unless explicitly composed ‚Äî it only receives **curated, summarized context**.\n",
    "\n",
    "---\n",
    "\n",
    "## üîê Safety & Privacy Principles\n",
    "\n",
    "- **Local-first by default**  \n",
    "  No data leaves the device unless the user enables an AI model.\n",
    "\n",
    "- **Non-diagnostic outputs**  \n",
    "  All recommendations are preventive and informational.\n",
    "\n",
    "- **Explicit safety flags**  \n",
    "  When concerning signals appear (e.g., self-harm keywords), the system prioritizes clear warnings and encourages external help.\n",
    "\n",
    "- **User control**  \n",
    "  Context can be viewed, reset, or fully deleted at any time.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ñ∂Ô∏è How to Run This Notebook\n",
    "\n",
    "1. Ensure Python 3.10+ is available  \n",
    "2. (Optional) Create a `.env` file for AI usage:\n",
    "   ```text\n",
    "   GEMINI_API_KEY=your_key_here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d2da81",
   "metadata": {},
   "source": [
    "## Environment Setup & Dependencies\n",
    "\n",
    "This cell installs the Python packages required to run the notebook.\n",
    "It ensures a consistent execution environment across different machines,\n",
    "including local development, review, and evaluation.\n",
    "\n",
    "The dependencies include:\n",
    "- The UI framework used to build the interactive application\n",
    "- The generative AI client used for model calls\n",
    "- Supporting libraries for configuration and HTTP requests\n",
    "\n",
    "This installation step is included to make the notebook **self-contained**\n",
    "and easy to run without prior environment preparation.\n",
    "\n",
    "In a production setup, these dependencies would typically be managed using\n",
    "a virtual environment and installed via a standard workflow (e.g. `pip install -r requirements.txt`\n",
    "in an `app.py`-based project). For this notebook-based submission, installing\n",
    "them inline prioritizes reproducibility and ease of evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4427b9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio>=4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 1)) (6.5.1)\n",
      "Requirement already satisfied: google-generativeai>=0.4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 2)) (0.8.6)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 3)) (1.1.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from -r requirements.txt (line 5)) (8.1.8)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (4.10.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.128.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==2.0.3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (2.0.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.34.4)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: pandas<4.0,>=1.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (11.3.0)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (2.11.7)\n",
      "Requirement already satisfied: pydub in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.0.22)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.17.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio>=4.0->-r requirements.txt (line 1)) (0.35.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio-client==2.0.3->gradio>=4.0->-r requirements.txt (line 1)) (2025.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio>=4.0->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5.0,>=3.0->gradio>=4.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fastapi<1.0,>=0.115.2->gradio>=4.0->-r requirements.txt (line 1)) (0.0.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio>=4.0->-r requirements.txt (line 1)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio>=4.0->-r requirements.txt (line 1)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio>=4.0->-r requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0->-r requirements.txt (line 1)) (3.19.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio>=4.0->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<4.0,>=1.0->gradio>=4.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<4.0,>=1.0->gradio>=4.0->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio>=4.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio>=4.0->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio>=4.0->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio>=4.0->-r requirements.txt (line 1)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio>=4.0->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio>=4.0->-r requirements.txt (line 1)) (14.1.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai>=0.4.0->-r requirements.txt (line 2)) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai>=0.4.0->-r requirements.txt (line 2)) (2.29.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai>=0.4.0->-r requirements.txt (line 2)) (2.189.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai>=0.4.0->-r requirements.txt (line 2)) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai>=0.4.0->-r requirements.txt (line 2)) (5.29.6)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (1.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (1.70.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31.0->-r requirements.txt (line 4)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.31.0->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (9.10.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipywidgets->-r requirements.txt (line 5)) (3.0.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio>=4.0->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.8.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<4.0,>=1.0->gradio>=4.0->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\owner\\appdata\\roaming\\python\\python313\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (0.31.2)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.1 in c:\\users\\owner\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.4.0->-r requirements.txt (line 2)) (3.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "### Setup\n",
    "\n",
    "#Install dependencies before running the notebook:\n",
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493e52f",
   "metadata": {},
   "source": [
    "## Core Imports & Notebook Execution Model\n",
    "\n",
    "This cell defines the core Python imports used throughout the notebook.\n",
    "Because Jupyter notebooks share a single execution kernel, running this cell\n",
    "once makes these imports available to all subsequent cells.\n",
    "\n",
    "Some individual cells also repeat imports intentionally. This is done to ensure\n",
    "that each section can be executed independently without relying on execution\n",
    "order‚Äîa common requirement during review, debugging, or evaluation.\n",
    "\n",
    "For this notebook-based submission, redundancy is preferred over hidden\n",
    "dependencies to maximize robustness and reproducibility.\n",
    "\n",
    "In a production or deployment setting, this structure can be easily refactored\n",
    "into a standard `app.py` and supporting `.py` modules, where imports would be\n",
    "centralized and managed conventionally. The current approach prioritizes\n",
    "clarity and safe execution within a notebook environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091e9e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Core Imports (run once at the top of the notebook)\n",
    "# =========================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import threading\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4c30cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gradio.components.markdown.Markdown at 0x1aeeef0e7b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gradio as gr\n",
    "\n",
    "gr.Markdown(\"\"\"\n",
    "# üß† Workday Health Reasoning Platform\n",
    "\n",
    "‚ö†Ô∏è **Important Disclaimer**\n",
    "This tool provides **general wellness and preventive guidance only**.  \n",
    "It does **not** provide medical diagnosis or treatment advice.  \n",
    "If you have severe symptoms or an emergency, seek professional medical help immediately.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a669b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea84795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# DEMO ENGINE (Gradual + Input Preview)\n",
    "# ==========================================\n",
    "\n",
    "import json\n",
    "import time\n",
    "from typing import Optional, List, Tuple\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict\n",
    "\n",
    "# Global hook registry\n",
    "_DEMO_HOOKS: Dict[str, \"DemoHook\"] = {}\n",
    "\n",
    "@dataclass\n",
    "class DemoHook:\n",
    "    domain: str\n",
    "    label: str\n",
    "    generate_fn: Callable\n",
    "\n",
    "\n",
    "def register_demo_hook(domain: str, label: str, generate_fn: Callable):\n",
    "    \"\"\"Modules call this to register themselves for the demo button.\"\"\"\n",
    "    _DEMO_HOOKS[domain] = DemoHook(\n",
    "        domain=domain,\n",
    "        label=label,\n",
    "        generate_fn=generate_fn\n",
    "    )\n",
    "\n",
    "\n",
    "def _load_latest_user_input(store, user_file: str):\n",
    "    raw = store.load_json(user_file, [])\n",
    "    if not isinstance(raw, list) or not raw:\n",
    "        return None\n",
    "    last = raw[-1]\n",
    "    if not isinstance(last, dict):\n",
    "        return None\n",
    "    return last.get(\"user_input\", None)\n",
    "\n",
    "\n",
    "def _preview_dict(d: dict, max_items: int = 10) -> str:\n",
    "    if not isinstance(d, dict) or not d:\n",
    "        return \"(No input data found)\"\n",
    "\n",
    "    items = list(d.items())[:max_items]\n",
    "    lines = []\n",
    "    for k, v in items:\n",
    "        lines.append(f\"- **{k}**: {v}\")\n",
    "\n",
    "    if len(d) > max_items:\n",
    "        lines.append(f\"- ‚Ä¶ _(and {len(d)-max_items} more fields)_\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def run_full_demo_gradual(\n",
    "    domains_order: Optional[List[str]] = None,\n",
    "    delay_seconds: float = 0.7\n",
    ") -> Tuple[str, str, Optional[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Same demo as before, but returns:\n",
    "    - report_md (full report)\n",
    "    - status_md\n",
    "    - schedule_df\n",
    "    \"\"\"\n",
    "\n",
    "    if \"_DEMO_HOOKS\" not in globals() or not _DEMO_HOOKS:\n",
    "        return \"\", \"‚ùå No demo hooks registered yet.\", None\n",
    "\n",
    "    store = globals().get(\"store\")\n",
    "    if store is None:\n",
    "        return \"\", \"‚ùå Store not found. Run setup cells first.\", None\n",
    "\n",
    "    if domains_order is None:\n",
    "        domains_order = [\n",
    "            \"general_recommendations\",\n",
    "            \"ask_ai\",\n",
    "            \"baseline\",\n",
    "            \"workspace\",\n",
    "            \"longitudinal\",\n",
    "            \"msk\",\n",
    "            \"eye\",\n",
    "            \"mental\",\n",
    "            \"hydration\",\n",
    "            \"productivity\",\n",
    "            \"recovery_sleep\",\n",
    "        ]\n",
    "\n",
    "    parts = []\n",
    "    status_lines = []\n",
    "\n",
    "    parts.append(\"# üöÄ Guided Demo Walkthrough\")\n",
    "    parts.append(\"This demo runs module-by-module and shows what the demo user entered before generating AI output.\\n\")\n",
    "\n",
    "    for dom in domains_order:\n",
    "        hook = _DEMO_HOOKS.get(dom)\n",
    "        if not hook:\n",
    "            status_lines.append(f\"‚ö†Ô∏è {dom}: not registered\")\n",
    "            continue\n",
    "\n",
    "        parts.append(\"\\n---\")\n",
    "        parts.append(f\"## {hook.label}\")\n",
    "\n",
    "        # Try to show saved input (if file exists)\n",
    "        # We assume hook.domain matches file name pattern\n",
    "        user_file_guess = f\"{dom}_user_input.json\"\n",
    "        demo_input = None\n",
    "        try:\n",
    "            demo_input = _load_latest_user_input(store, user_file_guess)\n",
    "        except Exception:\n",
    "            demo_input = None\n",
    "\n",
    "        if demo_input:\n",
    "            parts.append(\"### üë§ Demo User Entered\")\n",
    "            parts.append(_preview_dict(demo_input, max_items=10))\n",
    "        else:\n",
    "            parts.append(\"### üë§ Demo User Entered\")\n",
    "            parts.append(\"_(No saved input found for this module ‚Äî using general guidance if possible.)_\")\n",
    "\n",
    "        # Now generate AI output\n",
    "        try:\n",
    "            result = hook.generate_fn()\n",
    "\n",
    "            if isinstance(result, tuple) and len(result) >= 1:\n",
    "                output_text = result[0]\n",
    "            else:\n",
    "                output_text = result\n",
    "\n",
    "            output_text = str(output_text or \"\").strip()\n",
    "            if not output_text:\n",
    "                output_text = \"_(No output returned)_\"\n",
    "\n",
    "            parts.append(\"\\n### ü§ñ AI Output\")\n",
    "            parts.append(output_text)\n",
    "\n",
    "            status_lines.append(f\"‚úÖ {hook.label}: generated\")\n",
    "\n",
    "        except Exception as e:\n",
    "            parts.append(f\"\\n‚ùå Generate failed: `{e}`\")\n",
    "            status_lines.append(f\"‚ùå {hook.label}: failed\")\n",
    "\n",
    "        # Delay between modules (feels gradual)\n",
    "        time.sleep(delay_seconds)\n",
    "\n",
    "    # Reminder schedule preview\n",
    "    schedule_df = None\n",
    "    try:\n",
    "        sched = store.load_json(\"reminder_schedule.json\", {})\n",
    "        if isinstance(sched, dict) and isinstance(sched.get(\"schedule\"), list):\n",
    "            schedule_df = pd.DataFrame(sched[\"schedule\"])\n",
    "    except Exception:\n",
    "        schedule_df = None\n",
    "\n",
    "    report_md = \"\\n\".join(parts)\n",
    "    status_md = \"## Demo Status\\n\" + \"\\n\".join(f\"- {s}\" for s in status_lines)\n",
    "\n",
    "    return report_md, status_md, schedule_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdbf7bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bc870ad1754f309beeed22f5a3795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='üöÄ Run Guided Demo', style=ButtonStyle()), Button(bu‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1166820a76ad4167a2755dfda96ee434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================\n",
    "# üöÄ Notebook Demo Button (TRUE gradual output) ‚Äî FIXED STORE RESOLUTION\n",
    "# ==========================================\n",
    "\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure hooks dict exists even if demo engine cell hasn't run yet\n",
    "if \"_DEMO_HOOKS\" not in globals():\n",
    "    _DEMO_HOOKS = {}\n",
    "\n",
    "# --- UI Widgets ---\n",
    "demo_btn = widgets.Button(\n",
    "    description=\"üöÄ Run Guided Demo\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "refresh_btn = widgets.Button(\n",
    "    description=\"üîÑ Refresh Hooks\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "clear_btn = widgets.Button(\n",
    "    description=\"üßπ Clear Output\",\n",
    "    button_style=\"\"\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Store Resolver (FIX)\n",
    "# =========================================================\n",
    "def _resolve_store():\n",
    "    \"\"\"\n",
    "    Attempts to find a working LocalStore instance.\n",
    "    If missing, it creates one using DATA_DIR or ./data.\n",
    "    Does NOT change any app logic.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Use existing global store if present\n",
    "    store_obj = globals().get(\"store\")\n",
    "    if store_obj is not None:\n",
    "        return store_obj\n",
    "\n",
    "    # 2) Try to build it if LocalStore exists\n",
    "    LocalStore_cls = globals().get(\"LocalStore\")\n",
    "    if LocalStore_cls is None:\n",
    "        return None\n",
    "\n",
    "    # 3) Determine data directory\n",
    "    data_dir = globals().get(\"DATA_DIR\")\n",
    "    if data_dir is None:\n",
    "        data_dir = Path(\"data\")\n",
    "\n",
    "    try:\n",
    "        data_dir = Path(data_dir)\n",
    "        data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        store_obj = LocalStore_cls(data_dir)\n",
    "\n",
    "        # Save globally so all hooks see it\n",
    "        globals()[\"store\"] = store_obj\n",
    "        return store_obj\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[demo] ‚ùå Failed to create store: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def show_registered_hooks():\n",
    "    if \"_DEMO_HOOKS\" not in globals():\n",
    "        return \"‚ùå `_DEMO_HOOKS` is not defined yet.\"\n",
    "\n",
    "    if not _DEMO_HOOKS:\n",
    "        return \"‚ö†Ô∏è No hooks registered yet.\"\n",
    "\n",
    "    lines = [\"‚úÖ Registered hooks:\"]\n",
    "    for k in sorted(_DEMO_HOOKS.keys()):\n",
    "        lines.append(f\"- **{k}**\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _load_latest_user_input(store, user_file: str):\n",
    "    raw = store.load_json(user_file, [])\n",
    "    if not isinstance(raw, list) or not raw:\n",
    "        return None\n",
    "    last = raw[-1]\n",
    "    if not isinstance(last, dict):\n",
    "        return None\n",
    "    return last.get(\"user_input\", None)\n",
    "\n",
    "\n",
    "def _preview_dict(d: dict, max_items: int = 10) -> str:\n",
    "    if not isinstance(d, dict) or not d:\n",
    "        return \"(No input data found)\"\n",
    "\n",
    "    items = list(d.items())[:max_items]\n",
    "    lines = []\n",
    "    for k, v in items:\n",
    "        lines.append(f\"- **{k}**: {v}\")\n",
    "\n",
    "    if len(d) > max_items:\n",
    "        lines.append(f\"- ‚Ä¶ _(and {len(d)-max_items} more fields)_\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def run_demo_notebook_gradual():\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        # ‚úÖ FIXED: auto resolve store\n",
    "        store = _resolve_store()\n",
    "        if store is None:\n",
    "            display(Markdown(\n",
    "                \"‚ùå `store` not found and could not be created.\\n\\n\"\n",
    "                \"Make sure the cell defining `LocalStore` and `DATA_DIR` has been executed.\"\n",
    "            ))\n",
    "            return\n",
    "\n",
    "        if \"_DEMO_HOOKS\" not in globals() or not _DEMO_HOOKS:\n",
    "            display(Markdown(\n",
    "                \"‚ö†Ô∏è Demo hooks are not registered yet.\\n\\n\"\n",
    "                \"‚û°Ô∏è Run all module cells (Run All), then click again.\"\n",
    "            ))\n",
    "            display(Markdown(show_registered_hooks()))\n",
    "            return\n",
    "\n",
    "        domains_order = [\n",
    "            \"general_recommendations\",\n",
    "            \"ask_ai\",\n",
    "            \"baseline\",\n",
    "            \"workspace\",\n",
    "            \"longitudinal\",\n",
    "            \"msk\",\n",
    "            \"eye\",\n",
    "            \"mental\",\n",
    "            \"hydration\",\n",
    "            \"productivity\",\n",
    "            \"recovery_sleep\",\n",
    "        ]\n",
    "\n",
    "        display(Markdown(\"# üöÄ Guided Demo Walkthrough\"))\n",
    "        display(Markdown(\"Generating module-by-module (output appears gradually).\"))\n",
    "        display(Markdown(show_registered_hooks()))\n",
    "        display(Markdown(\"---\"))\n",
    "\n",
    "        status_lines = []\n",
    "\n",
    "        for dom in domains_order:\n",
    "            hook = _DEMO_HOOKS.get(dom)\n",
    "            if not hook:\n",
    "                status_lines.append(f\"‚ö†Ô∏è {dom}: not registered\")\n",
    "                continue\n",
    "\n",
    "            display(Markdown(f\"## {hook.label}\"))\n",
    "\n",
    "            # Show saved input preview\n",
    "            user_file_guess = f\"{dom}_user_input.json\"\n",
    "            demo_input = None\n",
    "            try:\n",
    "                demo_input = _load_latest_user_input(store, user_file_guess)\n",
    "            except Exception:\n",
    "                demo_input = None\n",
    "\n",
    "            display(Markdown(\"### üë§ Demo User Entered\"))\n",
    "            if demo_input:\n",
    "                display(Markdown(_preview_dict(demo_input, max_items=10)))\n",
    "            else:\n",
    "                display(Markdown(\"_(No saved input found for this module.)_\"))\n",
    "\n",
    "            # Generate AI output\n",
    "            display(Markdown(\"### ü§ñ AI Output\"))\n",
    "            try:\n",
    "                result = hook.generate_fn()\n",
    "\n",
    "                if isinstance(result, tuple) and len(result) >= 1:\n",
    "                    output_text = result[0]\n",
    "                else:\n",
    "                    output_text = result\n",
    "\n",
    "                output_text = str(output_text or \"\").strip()\n",
    "                if not output_text:\n",
    "                    output_text = \"_(No output returned)_\"\n",
    "\n",
    "                display(Markdown(output_text))\n",
    "                status_lines.append(f\"‚úÖ {hook.label}: generated\")\n",
    "\n",
    "            except Exception as e:\n",
    "                display(Markdown(f\"‚ùå Generate failed: `{e}`\"))\n",
    "                status_lines.append(f\"‚ùå {hook.label}: failed\")\n",
    "\n",
    "            display(Markdown(\"---\"))\n",
    "            time.sleep(0.4)\n",
    "\n",
    "        # Show reminder schedule preview at end\n",
    "        try:\n",
    "            sched = store.load_json(\"reminder_schedule.json\", {})\n",
    "            if isinstance(sched, dict) and isinstance(sched.get(\"schedule\"), list):\n",
    "                df = pd.DataFrame(sched[\"schedule\"])\n",
    "                if not df.empty:\n",
    "                    display(Markdown(\"## üìÖ Reminder Schedule Preview\"))\n",
    "                    display(df)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # Final status summary\n",
    "        display(Markdown(\"## ‚úÖ Demo Status Summary\"))\n",
    "        display(Markdown(\"\\n\".join([f\"- {s}\" for s in status_lines])))\n",
    "\n",
    "\n",
    "def refresh_hooks_display():\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(\"## üîÑ Hook Status\"))\n",
    "        display(Markdown(show_registered_hooks()))\n",
    "\n",
    "\n",
    "def clear_demo_output():\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "\n",
    "# --- Wire Buttons ---\n",
    "demo_btn.on_click(lambda _: run_demo_notebook_gradual())\n",
    "refresh_btn.on_click(lambda _: refresh_hooks_display())\n",
    "clear_btn.on_click(lambda _: clear_demo_output())\n",
    "\n",
    "\n",
    "# --- Display Notebook Controls ---\n",
    "display(widgets.HBox([demo_btn, refresh_btn, clear_btn]))\n",
    "display(out)\n",
    "\n",
    "# Show current hook status immediately\n",
    "refresh_hooks_display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b854da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "üöÄ Workday Health Reasoning Platform INITIALIZED\n",
      "üìÅ DATA FOLDER: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\n",
      "üåç LOCALES: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\locales\n",
      "--------------------------------------------------\n",
      "Copy the DATA FOLDER path above to your file explorer to see your JSON files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------------\n",
    "# üìÇ Path Fixing Logic (Ensures visibility)\n",
    "# -------------------------------------------------\n",
    "\n",
    "# 1. Get the directory of the current notebook/script\n",
    "try:\n",
    "    # Works in standard Python scripts\n",
    "    base_path = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # Works in Jupyter/VS Code Notebooks\n",
    "    base_path = Path(os.getcwd()).resolve()\n",
    "\n",
    "# 2. Force DATA_DIR to be a folder named 'data' in your project folder\n",
    "DATA_DIR = base_path / \"data\"\n",
    "\n",
    "# Create the directories\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOCALES_DIR = base_path / \"locales\"\n",
    "HELP_DIR = base_path / \"help\"\n",
    "\n",
    "LOCALES_DIR.mkdir(exist_ok=True)\n",
    "HELP_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# App configuration\n",
    "# -------------------------------------------------\n",
    "APP_NAME = \"Workday Health Reasoning Platform\"\n",
    "DEFAULT_LANG = \"en\"\n",
    "SUPPORTED_LANGS = {\"en\": \"English\", \"ar\": \"ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\"}\n",
    "MAX_HISTORY_PER_METRIC = 200 \n",
    "MODEL_NAME = \"gemini-1.5-flash\" # Note: Ensure this matches your available model\n",
    "\n",
    "# -------------------------------------------------\n",
    "# ‚úÖ SUCCESS CHECK\n",
    "# -------------------------------------------------\n",
    "print(\"-\" * 50)\n",
    "print(f\"üöÄ {APP_NAME} INITIALIZED\")\n",
    "print(f\"üìÅ DATA FOLDER: {DATA_DIR.absolute()}\")\n",
    "print(f\"üåç LOCALES: {LOCALES_DIR.absolute()}\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Copy the DATA FOLDER path above to your file explorer to see your JSON files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975f292a",
   "metadata": {},
   "source": [
    "Core Components\n",
    "The project contains core modules that implement essential logic and services used by the UI. We will go through each of these core components:\n",
    "Local Data Storage (LocalStore): Manages saving and loading JSON data files locally.\n",
    "Internationalization (i18n): Handles loading language files and providing a translation function.\n",
    "Safety Checks (safety.py): Provides functions to detect urgent health or mental health flags in user inputs.\n",
    "Input Registry (input_registry.py): Defines which data files are considered \"canonical\" user inputs for global analysis.\n",
    "Context Manager (context_manager.py): Manages summarized context memory for each domain (stores short summaries to be used across sessions or for global recommendations).\n",
    "Gemini API Client (gemini_client.py): Placeholder client to interface with the Gemini LLM API (with a safe fallback if not configured).\n",
    "OCR Pipeline (ocr_pipeline.py): Utility for optical character recognition on files (using Gemini's multimodal capabilities).\n",
    "Below, each of these modules is presented with its code and a brief explanation.\n",
    "Local Data Storage (LocalStore)\n",
    "This module (storage.py) defines the LocalStore class, which provides methods for local persistence of data. It stores JSON data and text files under the configured data directory. Key features: - Initialization: Accepts a data directory path and ensures it exists. - Save/Load JSON: Methods save_json(name, obj) and load_json(name) to write and read JSON files (using json.dump/json.load). If a file doesn't exist, load_json returns a default value. - Save/Load Text: Similar save_text and load_text methods for plain text, used for storing things like last AI outputs. - Utility: A helper last_output_name(domain) to standardize filenames for the last output of a given domain (e.g., 'baseline_last.txt').\n",
    "This class is used by the tabs to persist user inputs and AI outputs locally so that data is retained across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef13431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "class LocalStore:\n",
    "    \"\"\"\n",
    "    Local-only storage for:\n",
    "    - structured JSON (reasoning)\n",
    "    - human-readable text (UI continuity)\n",
    "\n",
    "    Improved:\n",
    "    - flexible JSON saving (handles non-JSON types safely)\n",
    "    - prints detailed errors instead of failing silently\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: Path):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def _path(self, name: str) -> Path:\n",
    "        \"\"\"Helper to get full path for a file name in the data directory.\"\"\"\n",
    "        return self.data_dir / name\n",
    "\n",
    "    def save_json(self, name: str, obj: Any) -> None:\n",
    "        \"\"\"\n",
    "        Save JSON safely.\n",
    "        - Uses default=str to avoid crashing on non-serializable objects\n",
    "          (numpy types, tuples, Path, datetime, etc.)\n",
    "        - Prints errors if something goes wrong\n",
    "        \"\"\"\n",
    "        path = self._path(name)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(obj, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "            print(f\"[LocalStore] ‚úÖ JSON saved: {path.resolve()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LocalStore] ‚ùå ERROR saving JSON: {path.resolve()}\")\n",
    "            print(f\"[LocalStore] Exception: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load_json(self, name: str, default: Any = None) -> Any:\n",
    "        \"\"\"\n",
    "        Load JSON safely.\n",
    "        - If file doesn't exist ‚Üí returns default\n",
    "        - If file is corrupted or unreadable ‚Üí prints error and returns default\n",
    "        \"\"\"\n",
    "        path = self._path(name)\n",
    "\n",
    "        if not path.exists():\n",
    "            print(f\"[LocalStore] ‚ö†Ô∏è JSON file not found: {path.resolve()}\")\n",
    "            return default\n",
    "\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            print(f\"[LocalStore] ‚úÖ JSON loaded: {path.resolve()}\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LocalStore] ‚ùå ERROR loading JSON: {path.resolve()}\")\n",
    "            print(f\"[LocalStore] Exception: {e}\")\n",
    "            return default\n",
    "\n",
    "    def save_text(self, name: str, text: str) -> None:\n",
    "        \"\"\"\n",
    "        Save plain text safely with error logging.\n",
    "        \"\"\"\n",
    "        path = self._path(name)\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)\n",
    "\n",
    "            print(f\"[LocalStore] ‚úÖ Text saved: {path.resolve()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LocalStore] ‚ùå ERROR saving text: {path.resolve()}\")\n",
    "            print(f\"[LocalStore] Exception: {e}\")\n",
    "            raise\n",
    "\n",
    "    def load_text(self, name: str, default: str = \"\") -> str:\n",
    "        \"\"\"\n",
    "        Load plain text safely.\n",
    "        \"\"\"\n",
    "        path = self._path(name)\n",
    "\n",
    "        if not path.exists():\n",
    "            print(f\"[LocalStore] ‚ö†Ô∏è Text file not found: {path.resolve()}\")\n",
    "            return default\n",
    "\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "\n",
    "            print(f\"[LocalStore] ‚úÖ Text loaded: {path.resolve()}\")\n",
    "            return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LocalStore] ‚ùå ERROR loading text: {path.resolve()}\")\n",
    "            print(f\"[LocalStore] Exception: {e}\")\n",
    "            return default\n",
    "\n",
    "    def last_output_name(self, domain: str) -> str:\n",
    "        return f\"{domain}_last.txt\"\n",
    "\n",
    "    def load_last_output(self, domain: str) -> str:\n",
    "        return self.load_text(self.last_output_name(domain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db46fae",
   "metadata": {},
   "source": [
    "Internationalization (i18n)\n",
    "The i18n.py module handles loading of locale files and translating text keys. It loads language files (JSON) from the locales directory and caches them. Key elements: - load_locale(lang, locales_dir): Reads the JSON file for the given language (lang.json) and stores it in a cache. This allows quick reuse without re-reading the file repeatedly. - t(lang, key, locales_dir, default=None): Retrieves the translated string for the given key in the specified language. It falls back to English if the key is missing in the target language, and if not found there either, it returns a provided default or the key itself. This function also supports formatting with **kwargs if placeholders are present in the string.\n",
    "This allows the UI to display text (like titles, labels) in the user's language (English or Arabic by default, extendable to others by adding locale files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "033d49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "_CACHE: Dict[str, Dict[str, str]] = {}\n",
    "\n",
    "def load_locale(lang: str, locales_dir: Path) -> Dict[str, str]:\n",
    "    if lang in _CACHE:\n",
    "        return _CACHE[lang]\n",
    "    path = locales_dir / f\"{lang}.json\"\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        data = {}\n",
    "    _CACHE[lang] = data\n",
    "    return data\n",
    "\n",
    "def t(lang: str, key: str, locales_dir: Path, default: str | None = None, **kwargs: Any) -> str:\n",
    "    \"\"\"Translate a key using JSON locales; fallback to English; then to default; then to key.\"\"\"\n",
    "    locale = load_locale(lang, locales_dir)\n",
    "    if key in locale:\n",
    "        text = locale[key]\n",
    "    else:\n",
    "        # Fallback to English\n",
    "        locale_en = load_locale(\"en\", locales_dir)\n",
    "        if key in locale_en:\n",
    "            text = locale_en[key]\n",
    "        elif default is not None:\n",
    "            text = default\n",
    "        else:\n",
    "            text = key\n",
    "    # If there are placeholders for formatting, fill them in\n",
    "    try:\n",
    "        return text.format(**kwargs)\n",
    "    except Exception:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a31144",
   "metadata": {},
   "source": [
    "Safety Checks\n",
    "The safety.py module provides simple functions to detect urgent health concerns in the user's input: - bp_red_flag(systolic, diastolic): Checks blood pressure readings. If either systolic ‚â• 180 or diastolic ‚â• 120, it returns a flag (True) with a warning message indicating a hypertensive crisis (advising prompt medical attention). Otherwise it returns False with no message. - mental_red_flag(text): Checks a piece of text for certain keywords that suggest severe distress or suicidal ideation (like \"suicide\", \"kill myself\", \"can't go on\", etc.). If any such phrase is found, it flags True with a message urging the user to seek immediate help. - apply_safety_checks(payload): Given a dictionary of user input fields (e.g., might contain 'bp' for blood pressure and 'free_text' for user-entered text), this function runs all relevant checks. It aggregates any flags into a list payload['safety_flags'] and returns the payload. Tabs like the baseline or mental health tab can use this to check if the user's data contains any urgent issues and ensure the UI can alert the user appropriately.\n",
    "These safety checks add a layer of precaution, ensuring the app can warn the user if something critical is detected in their inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e3b1b",
   "metadata": {},
   "source": [
    "# üõ°Ô∏è Central Safety Engine (One-Stop Safety Layer)\n",
    "\n",
    "This cell defines the **global safety framework** for the entire platform.\n",
    "\n",
    "Instead of adding red-flag logic inside every tab (Baseline, Mental, MSK, Eye, Hydration, etc.),  \n",
    "we use **one centralized safety engine** that can be integrated directly into the **GeminiClient**.\n",
    "\n",
    "That means:\n",
    "\n",
    "‚úÖ Every AI response passes through one safety checkpoint  \n",
    "‚úÖ Red-flag warnings are detected consistently across all modules  \n",
    "‚úÖ No need to repeat emergency logic in each tab prompt  \n",
    "‚úÖ Safety rules can be updated once, and the whole system benefits immediately  \n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ What this Safety Engine Does\n",
    "\n",
    "The safety system works in **three layers**:\n",
    "\n",
    "### 1) Rule-Based Risk Detection (Fast + Reliable)\n",
    "The engine checks structured user data such as:\n",
    "\n",
    "- **Blood pressure values**\n",
    "- **mental health crisis keywords**\n",
    "- **emergency symptom keywords in free text**\n",
    "\n",
    "It returns a list of **safety flags**, each containing:\n",
    "\n",
    "- `type` (e.g., bp_risk, mental_urgent)\n",
    "- `severity` (info / warning / urgent)\n",
    "- `message` (human-readable warning)\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Standardized Safety Flag Output\n",
    "All detected risks are stored as:\n",
    "\n",
    "```python\n",
    "payload[\"safety_flags\"] = [...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951715fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Any, Tuple, List, Optional\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# SAFETY FLAGS HELPERS\n",
    "# ==========================================================\n",
    "\n",
    "def _flag(flag_type: str, message: str, severity: str = \"warning\") -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Standard safety flag structure.\n",
    "    severity: \"info\" | \"warning\" | \"urgent\"\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"type\": flag_type,\n",
    "        \"severity\": severity,\n",
    "        \"message\": message.strip(),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# RULE-BASED SAFETY CHECKS\n",
    "# ==========================================================\n",
    "\n",
    "def bp_red_flag(systolic: Optional[float], diastolic: Optional[float]) -> Tuple[bool, str]:\n",
    "    if systolic is None or diastolic is None:\n",
    "        return False, \"\"\n",
    "\n",
    "    # Conservative urgent thresholds (non-diagnostic).\n",
    "    if systolic >= 180 or diastolic >= 120:\n",
    "        return True, (\n",
    "            \"Blood pressure is very high (urgent range). \"\n",
    "            \"If you have chest pain, severe headache, shortness of breath, weakness, or confusion, \"\n",
    "            \"seek urgent medical care immediately.\"\n",
    "        )\n",
    "\n",
    "    # Moderate warning threshold (optional)\n",
    "    if systolic >= 160 or diastolic >= 100:\n",
    "        return True, (\n",
    "            \"Blood pressure is high. Consider re-checking after resting 5‚Äì10 minutes \"\n",
    "            \"and consult a healthcare professional soon if it stays elevated.\"\n",
    "        )\n",
    "\n",
    "    return False, \"\"\n",
    "\n",
    "\n",
    "def mental_red_flag(text: str) -> Tuple[bool, str]:\n",
    "    if not text:\n",
    "        return False, \"\"\n",
    "\n",
    "    low = text.lower()\n",
    "    keywords = [\n",
    "        \"suicide\", \"kill myself\", \"self harm\", \"self-harm\",\n",
    "        \"end my life\", \"end it\", \"can't go on\", \"cant go on\",\n",
    "        \"hopeless\", \"i want to die\"\n",
    "    ]\n",
    "\n",
    "    if any(k in low for k in keywords):\n",
    "        return True, (\n",
    "            \"If you're in immediate danger or feel you might harm yourself, \"\n",
    "            \"please seek urgent help right now (local emergency services, a trusted person, \"\n",
    "            \"or a nearby medical facility). You do not have to handle this alone.\"\n",
    "        )\n",
    "\n",
    "    return False, \"\"\n",
    "\n",
    "\n",
    "def emergency_symptom_red_flag(text: str) -> Tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Optional generic emergency detection based on free text symptoms.\n",
    "    Not diagnostic, only triggers caution warnings.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return False, \"\"\n",
    "\n",
    "    low = text.lower()\n",
    "\n",
    "    emergency_keywords = [\n",
    "        \"chest pain\",\n",
    "        \"pressure in chest\",\n",
    "        \"can't breathe\",\n",
    "        \"cannot breathe\",\n",
    "        \"shortness of breath\",\n",
    "        \"severe headache\",\n",
    "        \"fainting\",\n",
    "        \"passed out\",\n",
    "        \"stroke\",\n",
    "        \"slurred speech\",\n",
    "        \"one side weakness\",\n",
    "        \"seizure\",\n",
    "        \"vomiting blood\",\n",
    "        \"blood in stool\",\n",
    "    ]\n",
    "\n",
    "    if any(k in low for k in emergency_keywords):\n",
    "        return True, (\n",
    "            \"Some symptoms described may require urgent medical evaluation. \"\n",
    "            \"If symptoms are severe, sudden, or worsening, seek emergency care immediately.\"\n",
    "        )\n",
    "\n",
    "    return False, \"\"\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# MAIN SAFETY ENGINE\n",
    "# ==========================================================\n",
    "\n",
    "def apply_safety_checks(payload: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Runs safety checks and attaches safety_flags to payload.\n",
    "    Expected payload keys (optional):\n",
    "      - payload[\"bp\"] = {\"sys\": ..., \"dia\": ...}\n",
    "      - payload[\"free_text\"] = \"... notes ...\"\n",
    "    \"\"\"\n",
    "\n",
    "    flags: List[Dict[str, str]] = []\n",
    "\n",
    "    # --- Blood Pressure ---\n",
    "    bp = payload.get(\"bp\") or {}\n",
    "    sys_val = bp.get(\"sys\")\n",
    "    dia_val = bp.get(\"dia\")\n",
    "\n",
    "    try:\n",
    "        sys_val = float(sys_val) if sys_val is not None else None\n",
    "    except Exception:\n",
    "        sys_val = None\n",
    "\n",
    "    try:\n",
    "        dia_val = float(dia_val) if dia_val is not None else None\n",
    "    except Exception:\n",
    "        dia_val = None\n",
    "\n",
    "    rf, msg = bp_red_flag(sys_val, dia_val)\n",
    "    if rf and msg:\n",
    "        flags.append(_flag(\"bp_risk\", msg, severity=\"urgent\"))\n",
    "\n",
    "    # --- Mental Health / Self-harm ---\n",
    "    free_text = (payload.get(\"free_text\") or \"\").strip()\n",
    "    rf, msg = mental_red_flag(free_text)\n",
    "    if rf and msg:\n",
    "        flags.append(_flag(\"mental_urgent\", msg, severity=\"urgent\"))\n",
    "\n",
    "    # --- Emergency Symptoms in Free Text ---\n",
    "    rf, msg = emergency_symptom_red_flag(free_text)\n",
    "    if rf and msg:\n",
    "        flags.append(_flag(\"symptom_urgent\", msg, severity=\"urgent\"))\n",
    "\n",
    "    payload[\"safety_flags\"] = flags\n",
    "    return payload\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# DISPLAY HELPERS (OPTION A: PREPEND WARNING TO AI OUTPUT)\n",
    "# ==========================================================\n",
    "\n",
    "def format_safety_warnings(flags: List[Dict[str, str]], lang: str = \"en\") -> str:\n",
    "    \"\"\"\n",
    "    Convert safety flags into a warning block that can be prepended to AI output.\n",
    "    \"\"\"\n",
    "\n",
    "    if not flags:\n",
    "        return \"\"\n",
    "\n",
    "    # sort urgent first\n",
    "    def _rank(f):\n",
    "        sev = f.get(\"severity\", \"warning\")\n",
    "        if sev == \"urgent\":\n",
    "            return 0\n",
    "        if sev == \"warning\":\n",
    "            return 1\n",
    "        return 2\n",
    "\n",
    "    flags_sorted = sorted(flags, key=_rank)\n",
    "\n",
    "    # Basic language support (simple)\n",
    "    if lang.startswith(\"ar\"):\n",
    "        header = \"‚ö†Ô∏è ÿ™ŸÜÿ®ŸäŸá ŸÖŸáŸÖ\"\n",
    "    else:\n",
    "        header = \"‚ö†Ô∏è Important Safety Notice\"\n",
    "\n",
    "    lines = [header]\n",
    "\n",
    "    for f in flags_sorted:\n",
    "        msg = (f.get(\"message\") or \"\").strip()\n",
    "        if msg:\n",
    "            lines.append(f\"- {msg}\")\n",
    "\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "\n",
    "def inject_safety_warnings(ai_text: str, flags: List[Dict[str, str]], lang: str = \"en\") -> str:\n",
    "    \"\"\"\n",
    "    Option A behavior:\n",
    "    - If flags exist, prepend them to AI response.\n",
    "    \"\"\"\n",
    "    ai_text = (ai_text or \"\").strip()\n",
    "\n",
    "    warning_block = format_safety_warnings(flags, lang=lang)\n",
    "\n",
    "    if not warning_block:\n",
    "        return ai_text\n",
    "\n",
    "    if ai_text:\n",
    "        return f\"{warning_block}\\n\\n{ai_text}\"\n",
    "\n",
    "    return warning_block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314808d7",
   "metadata": {},
   "source": [
    "Input Registry\n",
    "The input_registry.py module defines which user input files are considered \"canonical\" for inclusion in global reasoning (recommendations). It avoids automatically using any arbitrary file by explicitly listing allowed files. It contains: - CANONICAL_INPUT_FILES: A set of file names (strings) that represent user inputs (such as 'baseline_data.json', 'mental.json', etc.). Only data from these files should be aggregated for global analysis. - is_canonical_input(filename): Checks if a given file name is in the above set (returns True/False). - list_canonical_inputs(): Returns a sorted list of the canonical input file names.\n",
    "This ensures the global recommendations or reports only consider intended data sources, following the principle of being explicit about what data to aggregate.\n",
    "\"\"\"\n",
    "Input Registry\n",
    "\n",
    "This module defines which files represent canonical user-provided inputs.\n",
    "Only files listed here are allowed to participate in global reasoning\n",
    "(e.g. Global Recommendations).\n",
    "\n",
    "Design principles:\n",
    "- Explicit > implicit\n",
    "- No auto-discovery\n",
    "- No model involvement\n",
    "- Easy to expand safely\n",
    "\"\"\"\n",
    "\n",
    "from typing import List, Set\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Canonical input files (single source of truth)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "CANONICAL_INPUT_FILES: Set[str] = {\n",
    "    \"workspace.json\",\n",
    "    \"msk.json\",\n",
    "    \"mental.json\",\n",
    "    \"hydration.json\",\n",
    "    \"eye.json\",\n",
    "    \"baseline_data.json\",\n",
    "    \"baseline_surveys.json\",\n",
    "    \"longitudinal_logs.json\",\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Public helpers\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def is_canonical_input(filename: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the given filename is a declared user input file.\n",
    "    \"\"\"\n",
    "    return filename in CANONICAL_INPUT_FILES\n",
    "\n",
    "def list_canonical_inputs() -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns a sorted list of canonical input filenames.\n",
    "    Useful for audits, debugging, or UI explanations.\n",
    "    \"\"\"\n",
    "    return sorted(CANONICAL_INPUT_FILES)\n",
    "Context Manager\n",
    "The context_manager.py module manages the storage of summarized context for each domain. As the user interacts with different tabs, each tab can produce a short summary of the user's state in that area (to avoid having to process full history each time). The module includes: - ContextBundle dataclass: Defines a structured object with fields for each domain (baseline, longitudinal, msk, mental, etc.), which could be used to hold context strings. (This is not heavily used in the skeleton but outlines the context structure.) - CONTEXT_FILE: Name of the JSON file (e.g., 'context_summaries.json') where these summaries are saved. - load_context(store): Loads the entire context summaries dictionary from storage (or returns an empty dict if none saved). - save_context(store, ctx): Saves the context summaries dictionary to file. - update_domain_summary(store, domain, summary): Convenience function to update one domain's summary in the context file (loads current context, updates/adds the given domain's entry, and saves it back). Returns the updated context dict. - delete_domain(store, domain): Removes a domain from the context summaries (for example, if one wants to reset context for that domain) and saves changes. - compose_relevant_context(store, domains): Given a list of domain names, it fetches their summaries and composes a single string with each domain's summary on a new line (prefixed by the domain name). This is useful to build a prompt context string for the AI that includes only relevant domains.\n",
    "By maintaining a short summary of each domain's information, the app can provide the AI model with a concise context (rather than long histories) when generating recommendations or reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29254262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, List\n",
    "\n",
    "\n",
    "\n",
    "CONTEXT_FILE = \"context_summaries.json\"\n",
    "\n",
    "@dataclass\n",
    "class ContextBundle:\n",
    "    baseline: str = \"\"\n",
    "    longitudinal: str = \"\"\n",
    "    msk: str = \"\"\n",
    "    mental: str = \"\"\n",
    "    eye: str = \"\"\n",
    "    hydration: str = \"\"\n",
    "    productivity: str = \"\"\n",
    "\n",
    "    # You can extend this dataclass with more fields if needed (e.g., recovery_sleep, etc.)\n",
    "\n",
    "    def to_dict(self) -> Dict[str, str]:\n",
    "        return {\n",
    "            \"baseline\": self.baseline,\n",
    "            \"longitudinal\": self.longitudinal,\n",
    "            \"msk\": self.msk,\n",
    "            \"mental\": self.mental,\n",
    "            \"eye\": self.eye,\n",
    "            \"hydration\": self.hydration,\n",
    "            \"productivity\": self.productivity,\n",
    "        }\n",
    "\n",
    "def load_context(store: LocalStore) -> Dict[str, str]:\n",
    "    data = store.load_json(CONTEXT_FILE, default={})\n",
    "    return data if isinstance(data, dict) else {}\n",
    "\n",
    "def save_context(store: LocalStore, ctx: Dict[str, str]) -> None:\n",
    "    store.save_json(CONTEXT_FILE, ctx)\n",
    "\n",
    "def update_domain_summary(store: LocalStore, domain: str, summary: str) -> Dict[str, str]:\n",
    "    ctx = load_context(store)\n",
    "    ctx[domain] = summary.strip()\n",
    "    save_context(store, ctx)\n",
    "    return ctx\n",
    "\n",
    "def delete_domain(store: LocalStore, domain: str) -> Dict[str, str]:\n",
    "    ctx = load_context(store)\n",
    "    if domain in ctx:\n",
    "        del ctx[domain]\n",
    "    save_context(store, ctx)\n",
    "    return ctx\n",
    "\n",
    "def compose_relevant_context(store: LocalStore, domains: List[str]) -> str:\n",
    "    \"\"\"Return a compact, readable context block using only requested domains.\"\"\"\n",
    "    ctx = load_context(store)\n",
    "    lines = []\n",
    "    for d in domains:\n",
    "        val = (ctx.get(d) or \"\").strip()\n",
    "        if val:\n",
    "            lines.append(f\"- {d}: {val}\")\n",
    "    return \"\\n\".join(lines).strip()\n",
    "def load_latest_session(domain: str, store) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Loads the latest saved session record for a given domain.\n",
    "    Expected file format: LIST of records [{timestamp, user_input, ai_output}, ...]\n",
    "    \"\"\"\n",
    "    user_file = f\"{domain}_user_input.json\"\n",
    "    ai_file = f\"{domain}_ai_output.json\"\n",
    "\n",
    "    # Try AI file first (usually contains ai_output)\n",
    "    raw_ai = store.load_json(ai_file, [])\n",
    "    if isinstance(raw_ai, list) and raw_ai:\n",
    "        return raw_ai[-1]\n",
    "\n",
    "    # Fallback: try user file\n",
    "    raw_user = store.load_json(user_file, [])\n",
    "    if isinstance(raw_user, list) and raw_user:\n",
    "        return raw_user[-1]\n",
    "\n",
    "    return None\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "def _safe_t(lang: str, key: str, locales_dir: Optional[Path], default: str) -> str:\n",
    "    \"\"\"Safe translation wrapper (won't crash if t() is missing).\"\"\"\n",
    "    try:\n",
    "        if \"t\" in globals() and callable(globals()[\"t\"]):\n",
    "            return globals()[\"t\"](lang, key, locales_dir, default=default)\n",
    "    except Exception as e:\n",
    "        print(f\"[i18n] ‚ö†Ô∏è t() failed for key={key}: {e}\")\n",
    "    return default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e415ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "from typing import Any, Optional, Sequence\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def _now() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"\")\n",
    "\n",
    "\n",
    "def _safe_t(lang: str, key: str, locales_dir: Optional[Path], default: str) -> str:\n",
    "    \"\"\"Safe translation wrapper: uses global t() if available, otherwise returns default.\"\"\"\n",
    "    try:\n",
    "        if \"t\" in globals() and callable(globals()[\"t\"]):\n",
    "            return globals()[\"t\"](lang, key, locales_dir, default=default)\n",
    "    except Exception as e:\n",
    "        print(f\"[i18n] ‚ö†Ô∏è t() failed for key={key}: {e}\")\n",
    "    return default\n",
    "\n",
    "\n",
    "def _to_int(x: Any, default: int = 0) -> int:\n",
    "    try:\n",
    "        if x is None or x == \"\":\n",
    "            return default\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _to_float(x: Any, default: float = 0.0) -> float:\n",
    "    try:\n",
    "        if x is None or x == \"\":\n",
    "            return default\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _to_bool(x: Any) -> bool:\n",
    "    try:\n",
    "        return bool(x)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def _to_str(x: Any, default: str = \"\") -> str:\n",
    "    try:\n",
    "        if x is None:\n",
    "            return default\n",
    "        s = str(x).strip()\n",
    "        return s if s else default\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _to_list(x: Any) -> list:\n",
    "    if x is None:\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if isinstance(x, tuple):\n",
    "        return list(x)\n",
    "    if isinstance(x, set):\n",
    "        return list(x)\n",
    "    if isinstance(x, str):\n",
    "        return [x]\n",
    "    if isinstance(x, Sequence):\n",
    "        return list(x)\n",
    "    return [x]\n",
    "\n",
    "\n",
    "def _debug_store_path(store: Any, filename: str) -> str:\n",
    "    try:\n",
    "        if hasattr(store, \"_path\") and callable(store._path):\n",
    "            return str(store._path(filename).resolve())\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        if hasattr(store, \"data_dir\"):\n",
    "            return str((Path(store.data_dir) / filename).resolve())\n",
    "    except Exception:\n",
    "        pass\n",
    "    return filename\n",
    "\n",
    "\n",
    "def _save_json_best_effort(store: Any, name: str, obj: Any) -> None:\n",
    "    \"\"\"Prefer store.save_json; fallback to writing to store.data_dir (or ./data).\"\"\"\n",
    "    try:\n",
    "        store.save_json(name, obj)\n",
    "        print(f\"[store] ‚úÖ store.save_json OK -> {_debug_store_path(store, name)}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"[store] ‚ùå store.save_json failed for {name}: {e}\")\n",
    "\n",
    "    data_dir = Path(getattr(store, \"data_dir\", Path(\"data\")))\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    path = (data_dir / name).resolve()\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "    print(f\"[store] ‚úÖ fallback write OK -> {path}\")\n",
    "\n",
    "\n",
    "def save_session(domain: str, user_input: Any, ai_output: str, store: Any) -> None:\n",
    "    \"\"\"Append snapshot to <domain>_user_input.json and <domain>_ai_output.json.\"\"\"\n",
    "    ts = _now()\n",
    "    user_file = f\"{domain}_user_input.json\"\n",
    "    ai_file = f\"{domain}_ai_output.json\"\n",
    "\n",
    "    if user_input is not None:\n",
    "        existing = store.load_json(user_file, [])\n",
    "        if not isinstance(existing, list):\n",
    "            existing = []\n",
    "        existing.append({\"timestamp\": ts, \"user_input\": user_input})\n",
    "        _save_json_best_effort(store, user_file, existing)\n",
    "\n",
    "    if ai_output is not None:\n",
    "        existing = store.load_json(ai_file, [])\n",
    "        if not isinstance(existing, list):\n",
    "            existing = []\n",
    "        existing.append({\"timestamp\": ts, \"ai_output\": str(ai_output)})\n",
    "        _save_json_best_effort(store, ai_file, existing)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_context_from_data_folder(store) -> str:\n",
    "    \"\"\"\n",
    "    Builds unified context ONLY from user input files in data folder.\n",
    "    Reads: *_user_input.json\n",
    "    Uses the latest record from each file (if list).\n",
    "    Excludes AI outputs and summaries.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = Path(getattr(store, \"data_dir\", Path(\"data\")))\n",
    "    if not data_dir.exists():\n",
    "        return \"\"\n",
    "\n",
    "    domains_context = {}\n",
    "\n",
    "    for p in sorted(data_dir.glob(\"*_user_input.json\")):\n",
    "        try:\n",
    "            raw = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "            # file stem: baseline_user_input -> baseline\n",
    "            domain = p.stem.replace(\"_user_input\", \"\").strip()\n",
    "\n",
    "            # If stored as list (append history)\n",
    "            if isinstance(raw, list) and raw:\n",
    "                last = raw[-1]\n",
    "                if isinstance(last, dict) and \"user_input\" in last:\n",
    "                    domains_context[domain] = last[\"user_input\"]\n",
    "                else:\n",
    "                    domains_context[domain] = last\n",
    "\n",
    "            # If stored as dict\n",
    "            elif isinstance(raw, dict):\n",
    "                if \"user_input\" in raw:\n",
    "                    domains_context[domain] = raw[\"user_input\"]\n",
    "                else:\n",
    "                    domains_context[domain] = raw\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[context] ‚ö†Ô∏è Failed reading {p.name}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not domains_context:\n",
    "        return \"\"\n",
    "\n",
    "    # Pretty text output for prompt usage\n",
    "    blocks = []\n",
    "    for dom, data in domains_context.items():\n",
    "        blocks.append(f\"## {dom.upper()}\\n{json.dumps(data, indent=2, ensure_ascii=False)}\")\n",
    "\n",
    "    return \"\\n\\n\".join(blocks)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preflight_check() -> None:\n",
    "    required = [\n",
    "        \"_safe_t\",\"_now\",\"_save_json_best_effort\",\n",
    "        \"_to_int\",\"_to_float\",\"_to_bool\",\"_to_str\",\"_to_list\",\n",
    "        \"save_session\",\"build_context_from_data_folder\",\n",
    "    ]\n",
    "    missing = [n for n in required if n not in globals()]\n",
    "    if missing:\n",
    "        raise NameError(f\"Missing globals: {missing}\")\n",
    "    print(\"‚úÖ Preflight OK\")\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "def domain_files(domain: str) -> Tuple[str, str]:\n",
    "    return f\"{domain}_user_input.json\", f\"{domain}_ai_output.json\"\n",
    "\n",
    "def _as_history_list(raw: Any) -> List[Dict[str, Any]]:\n",
    "    # supports old formats too\n",
    "    if isinstance(raw, list):\n",
    "        return raw\n",
    "    if isinstance(raw, dict) and raw:\n",
    "        return [raw]\n",
    "    return []\n",
    "\n",
    "def _first_existing(store: Any, candidates: List[str]) -> str:\n",
    "    # Try to detect which filename actually exists on disk\n",
    "    for name in candidates:\n",
    "        try:\n",
    "            if hasattr(store, \"_path\") and callable(store._path):\n",
    "                p = Path(store._path(name))\n",
    "            else:\n",
    "                p = Path(getattr(store, \"data_dir\", \"data\")) / name\n",
    "            if p.exists():\n",
    "                return name\n",
    "        except Exception:\n",
    "            pass\n",
    "    return candidates[0]  # fallback\n",
    "\n",
    "def load_domain_history(\n",
    "    store: Any,\n",
    "    domain: str,\n",
    "    legacy_user_files: Optional[List[str]] = None,\n",
    "    legacy_ai_files: Optional[List[str]] = None,\n",
    ") -> Tuple[Dict[str, Any], str]:\n",
    "    user_file, ai_file = domain_files(domain)\n",
    "\n",
    "    user_candidates = [user_file] + (legacy_user_files or [])\n",
    "    ai_candidates   = [ai_file]   + (legacy_ai_files or [])\n",
    "\n",
    "    user_file = _first_existing(store, user_candidates)\n",
    "    ai_file   = _first_existing(store, ai_candidates)\n",
    "\n",
    "    raw_user = store.load_json(user_file, [])\n",
    "    user_hist = _as_history_list(raw_user)\n",
    "    latest_user_record = user_hist[-1] if user_hist else {}\n",
    "    saved_user_input = latest_user_record.get(\"user_input\", {})\n",
    "    if not isinstance(saved_user_input, dict):\n",
    "        saved_user_input = {}\n",
    "\n",
    "    raw_ai = store.load_json(ai_file, [])\n",
    "    ai_hist = _as_history_list(raw_ai)\n",
    "    latest_ai_record = ai_hist[-1] if ai_hist else {}\n",
    "    saved_ai_text = latest_ai_record.get(\"ai_output\", \"\")\n",
    "    if not isinstance(saved_ai_text, str):\n",
    "        saved_ai_text = str(saved_ai_text)\n",
    "\n",
    "    # Debug (super useful during restart issues)\n",
    "    try:\n",
    "        print(f\"[{domain}] load user={user_file} ai={ai_file}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return saved_user_input, saved_ai_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bacd0fb",
   "metadata": {},
   "source": [
    "Helper for the Add info button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a505fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from info_variables import (\n",
    "    HYDRATION_INFO_MD,\n",
    "    MENTAL_WELLBEING_INFO_MD,\n",
    "    WORKSPACE_INFO_MD,\n",
    "    MSK_INFO_MD,\n",
    "    EYE_HEALTH_INFO_MD,\n",
    "    PRODUCTIVITY_INFO_MD,\n",
    "    RECOVERY_SLEEP_INFO_MD,ABOUT_APP_MD\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def add_info_panel(\n",
    "    title: str,\n",
    "    content_md: str,\n",
    "    button_label: str = \"‚ÑπÔ∏è About this tab\",\n",
    "    open_label: str = \"‚ùå Hide info\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a toggle button + hidden markdown panel.\n",
    "    Returns: (button, panel_component)\n",
    "    \"\"\"\n",
    "\n",
    "    info_state = gr.State(False)  # hidden by default\n",
    "\n",
    "    btn = gr.Button(button_label, variant=\"secondary\")\n",
    "\n",
    "    with gr.Accordion(title, open=False, visible=False) as panel:\n",
    "        md = gr.Markdown(content_md)\n",
    "\n",
    "    def _toggle(current):\n",
    "        new_state = not current\n",
    "        return (\n",
    "            new_state,\n",
    "            gr.update(visible=new_state),\n",
    "            open_label if new_state else button_label\n",
    "        )\n",
    "\n",
    "    btn.click(\n",
    "        fn=_toggle,\n",
    "        inputs=[info_state],\n",
    "        outputs=[info_state, panel, btn],\n",
    "    )\n",
    "\n",
    "    return btn, panel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c2740",
   "metadata": {},
   "source": [
    "Gemini API Client\n",
    "The gemini_client.py module provides a wrapper for interacting with the Google Gemini API (a large language model). In this skeleton, it functions as a placeholder with a fallback if no API key is configured: - GeminiResponse (dataclass): A simple container for responses, holding the generated text, the model name, and a used_fallback flag indicating if the result is a placeholder. - GeminiClient class: - Initialization (__init__): Attempts to retrieve an API key from the environment (GEMINI_API_KEY). If found, it sets up a genai.Client (from Google's genai library) for the specified model. If no key is present, it marks the client as disabled (self.enabled=False), meaning actual API calls won't be made. - generate(prompt, response_language): If the client is enabled, it sends the prompt to the Gemini model (with an instruction to respond in the given language) and returns the model's response as a GeminiResponse. If not enabled (no API key), it returns a GeminiResponse with a placeholder text (indicating Gemini is not configured). - generate_with_file(prompt, file_path, response_language): Similar to generate, but allows including a file (image or PDF) in the prompt. It reads the file bytes and sends them along with the prompt to the model. If not enabled, returns a placeholder response. There's also an internal helper _detect_mime to determine the file's MIME type (only certain types are supported).\n",
    "All tabs use gemini.generate() (and some use gemini.generate_with_file()) to get AI-generated insights. In the absence of a real API key, the calls will just produce placeholder messages, which is suitable for testing the UI flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3eccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\AppData\\Local\\Temp\\ipykernel_30548\\1049567649.py:5: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DeepSeek enabled (Primary): deepseek-chat\n",
      "‚úÖ Gemini enabled (Secondary): gemini-2.5-flash\n",
      "‚úÖ Groq enabled (Fallback): llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from typing import Optional, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env to ensure keys are available\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# =================================================\n",
    "# 1. Find Available Gemini Model (Auto)\n",
    "# =================================================\n",
    "def pick_best_gemini_model(prefer_flash=True) -> str:\n",
    "    \"\"\"\n",
    "    Picks the best available Gemini model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        models = list(genai.list_models())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not list Gemini models: {e}\")\n",
    "        return \"gemini-1.5-flash\"\n",
    "\n",
    "    valid = [m.name.replace(\"models/\", \"\") for m in models \n",
    "             if \"generateContent\" in m.supported_generation_methods]\n",
    "\n",
    "    if not valid:\n",
    "        return \"gemini-1.5-flash\"\n",
    "\n",
    "    # Priority 1: Flash models (fast/cheap)\n",
    "    # Priority 2: Pro models\n",
    "    flash_models = [x for x in valid if \"flash\" in x]\n",
    "    pro_models = [x for x in valid if \"pro\" in x]\n",
    "\n",
    "    if prefer_flash and flash_models: \n",
    "        return flash_models[0]\n",
    "    return pro_models[0] if pro_models else valid[0]\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# Response Wrapper\n",
    "# =================================================\n",
    "class AIResponse:\n",
    "    def __init__(self, text, model, safety_flags=None):\n",
    "        self.text = text\n",
    "        self.model = model\n",
    "        self.safety_flags = safety_flags or []\n",
    "\n",
    "\n",
    "# =================================================\n",
    "# 2. Gemini-Only Client\n",
    "# =================================================\n",
    "class GeminiClient:\n",
    "    def __init__(self, gemini_api_key: Optional[str] = None):\n",
    "        # API Key lookup\n",
    "        self.api_key = gemini_api_key or os.getenv(\"GEMINI_API_KEY\")\n",
    "        \n",
    "        if not self.api_key:\n",
    "            print(\"‚ùå Error: No GEMINI_API_KEY found in .env or passed as argument.\")\n",
    "            self.enabled = False\n",
    "            self.model_name = \"none\"\n",
    "        else:\n",
    "            genai.configure(api_key=self.api_key)\n",
    "            self.model_name = pick_best_gemini_model()\n",
    "            self.enabled = True\n",
    "            print(f\"‚úÖ Gemini Client Active: {self.model_name}\")\n",
    "\n",
    "    # --- Safety & Utilities ---\n",
    "\n",
    "    def _run_safety_checks(self, safety_payload: Optional[Dict[str, Any]]) -> list:\n",
    "        \"\"\"Looks for an external safety check function in globals.\"\"\"\n",
    "        if not safety_payload: \n",
    "            return []\n",
    "        try:\n",
    "            if \"apply_safety_checks\" in globals():\n",
    "                checked = globals()[\"apply_safety_checks\"](safety_payload)\n",
    "                return checked.get(\"safety_flags\", []) if isinstance(checked, dict) else []\n",
    "        except: \n",
    "            pass\n",
    "        return []\n",
    "\n",
    "    def _format_safety_banner(self, flags) -> str:\n",
    "        \"\"\"Formats the safety warning banner for the UI.\"\"\"\n",
    "        if not flags: \n",
    "            return \"\"\n",
    "        lines = [\"## ‚ö†Ô∏è Safety Notice\"]\n",
    "        for f in flags:\n",
    "            msg = f.get(\"message\") if isinstance(f, dict) else str(f)\n",
    "            if msg: lines.append(f\"- {msg}\")\n",
    "        return \"\\n\".join(lines) + \"\\n\\n\"\n",
    "\n",
    "    # =================================================\n",
    "    # Main Generate Function\n",
    "    # =================================================\n",
    "    def generate(self, prompt, response_language=\"en\", safety_payload: Optional[Dict[str, Any]] = None):\n",
    "        # 1. Safety Checks\n",
    "        safety_flags = self._run_safety_checks(safety_payload)\n",
    "        safety_banner = self._format_safety_banner(safety_flags)\n",
    "\n",
    "        if not self.enabled:\n",
    "            return AIResponse(\n",
    "                text=safety_banner + \"Gemini is not configured. Please check your API key.\",\n",
    "                model=\"none\",\n",
    "                safety_flags=safety_flags\n",
    "            )\n",
    "\n",
    "        # 2. Prepare Prompt\n",
    "        system_rule = (\n",
    "            \"STYLE: Friendly, supportive, encouraging. Simple language.\\n\"\n",
    "            \"DATA RULE: Ignore numeric 0 unless clearly valid.\\n\\n\"\n",
    "        )\n",
    "        full_prompt = f\"Respond in {response_language}.\\n\\n{system_rule}{prompt}\"\n",
    "\n",
    "        # 3. Call Gemini\n",
    "        try:\n",
    "            model = genai.GenerativeModel(self.model_name)\n",
    "            response = model.generate_content(full_prompt)\n",
    "            \n",
    "            # Extract text safely\n",
    "            generated_text = response.text if response.text else \"The AI returned an empty response.\"\n",
    "            \n",
    "            return AIResponse(\n",
    "                text=safety_banner + generated_text.strip(),\n",
    "                model=self.model_name,\n",
    "                safety_flags=safety_flags\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Gemini Execution Error: {e}\")\n",
    "            return AIResponse(\n",
    "                text=safety_banner + f\"Sorry, I encountered an error: {str(e)}\",\n",
    "                model=self.model_name,\n",
    "                safety_flags=safety_flags\n",
    "            )\n",
    "\n",
    "# --- Initialize global client ---\n",
    "# Every other cell in your notebook should use 'gemini.generate(...)'\n",
    "gemini = GeminiClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e345c16",
   "metadata": {},
   "source": [
    "OCR Pipeline\n",
    "The ocr_pipeline.py module provides a function for handling OCR (Optical Character Recognition) using the AI (Gemini) for file inputs. It contains: - extract_text_from_file(gemini, file_path, lang='en'): This function is meant to take a file path (to an image or PDF) and use the GeminiClient to extract text from it. It likely constructs a prompt instructing the model to perform OCR on the file. If gemini is not enabled (no API), this would return a placeholder or raise an error.\n",
    "This utility can be used in conjunction with the Longitudinal tab or other features where a user might upload a document or image to extract health-related text (for example, scanning a medical report for analysis). It's not extensively used in the default tabs but is provided for future extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98b8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def extract_text_from_file(gemini, file_path: str | Path, lang: str = \"en\") -> str:\n",
    "    \"\"\"\n",
    "    OCR / transcription pipeline.\n",
    "    Uses Gemini multimodal capability to extract raw text from\n",
    "    PDF or image files.\n",
    "\n",
    "    Returns:\n",
    "        Plain extracted text (string)\n",
    "\n",
    "    Raises:\n",
    "        Exception: If Gemini is not configured or an error occurs.\n",
    "    \"\"\"\n",
    "    # Define an OCR-specific prompt (this can be adjusted as needed)\n",
    "    ocr_prompt = \"Extract all textual content from this document/image.\"\n",
    "    # Use the Gemini client to perform the OCR\n",
    "    resp = gemini.generate_with_file(\n",
    "        prompt=ocr_prompt,\n",
    "        file_path=file_path,\n",
    "        response_language=lang,\n",
    "    )\n",
    "    if resp.used_fallback:\n",
    "        # If Gemini isn't configured, raise an exception (or handle accordingly)\n",
    "        raise Exception(\"Gemini is not configured for OCR.\")\n",
    "    return resp.text or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c4e4c",
   "metadata": {},
   "source": [
    "User Interface (Gradio) Setup\n",
    "The main user interface is defined in the app.py module. This script ties together the core components and the tabs within a Gradio app. Key points about app.py: - It uses Gradio Blocks to build the interface and define the layout (with a title, some description, and tabs). - It loads environment variables from a .env file (if present) via load_dotenv() to configure things like API keys. - It initializes the core services: a LocalStore for data storage and a GeminiClient for AI (which will be disabled if no API key is set). - It sets up a state variable lang_state to keep track of the current language (with default from config.DEFAULT_LANG). This state can be updated by the UI (e.g., if a language switcher were implemented) and is passed to tabs so they know what language to generate responses in. - Header: The app displays a title and subtitle using Markdown, pulling the text from the locale files via the translation function t(...). It also shows a notice about data being local-only (also from locales, likely msg.local_only). - Tabs: The interface is organized into tabs using gr.TabItem. The first tab is a general \"üè¢ General Recommendations\" tab (the Action Center) which is built by build_global_recommendations_tab(...). Then, the app dynamically creates tabs for each domain by iterating over the TAB_BUILDERS list (imported from the tabs package). For each entry (which has a translation key for the title and the corresponding build function), it opens a new tab and calls the builder function with the necessary parameters (store, gemini, etc.). This way, all tabs are added to the UI. - Finally, the build_app() function returns the constructed Gradio Blocks app (assigned to demo in the code). If the script is run as __main__, it calls build_app() and then launches the app with app.launch(...) on the specified host and port.\n",
    "Below is the content of app.py illustrating the above functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcb9355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Load environment variables from .env\n",
    "# -------------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GeminiResponse:\n",
    "    text: str\n",
    "    model: str\n",
    "    used_fallback: bool = False\n",
    "    safety_flags: List[Any] = field(default_factory=list)\n",
    "\n",
    "\n",
    "class GeminiClient:\n",
    "    \"\"\"\n",
    "    Hybrid Gemini client with:\n",
    "    - Text generation\n",
    "    - File (PDF / image) generation for OCR\n",
    "    - Local LM Studio fallback for text-only calls\n",
    "\n",
    "    Priority:\n",
    "    1. Gemini API\n",
    "    2. Local LM Studio (text only)\n",
    "    3. Placeholder\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: Optional[str] = None,\n",
    "        model_name: str = \"gemini-2.5-flash-lite\",\n",
    "        use_local_fallback: bool = True,\n",
    "        lmstudio_url: Optional[str] = None,\n",
    "        lmstudio_model: str = \"ewaast-medgemma-1.5-4b\",\n",
    "    ):\n",
    "        # -------------------------\n",
    "        # Gemini setup\n",
    "        # -------------------------\n",
    "        self.api_key = api_key or os.getenv(\"GEMINI_API_KEY\")\n",
    "        self.model_name = model_name\n",
    "        self.gemini_enabled = bool(self.api_key)\n",
    "\n",
    "        if self.gemini_enabled:\n",
    "            genai.configure(api_key=self.api_key)\n",
    "\n",
    "        # -------------------------\n",
    "        # Local LM Studio setup (text-only)\n",
    "        # -------------------------\n",
    "        self.use_local_fallback = use_local_fallback\n",
    "        self.lmstudio_url = (\n",
    "            lmstudio_url\n",
    "            or os.getenv(\"LMSTUDIO_URL\")\n",
    "            or \"http://192.168.1.34:1234/v1/chat/completions\"\n",
    "        )\n",
    "        self.lmstudio_model = lmstudio_model\n",
    "\n",
    "    # =================================================\n",
    "    # TEXT GENERATION\n",
    "    # =================================================\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        response_language: str = \"en\",\n",
    "    ) -> GeminiResponse:\n",
    "\n",
    "        # 1Ô∏è‚É£ Gemini text generation\n",
    "        if self.gemini_enabled:\n",
    "            try:\n",
    "                model = genai.GenerativeModel(self.model_name)\n",
    "                response = model.generate_content(\n",
    "                    f\"Respond in {response_language}.\\n\\n{prompt}\"\n",
    "                )\n",
    "\n",
    "                return GeminiResponse(\n",
    "                    text=response.text or \"\",\n",
    "                    model=self.model_name,\n",
    "                    used_fallback=False,\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                gemini_error = str(e)\n",
    "        else:\n",
    "            gemini_error = \"Gemini API key not configured.\"\n",
    "\n",
    "        # 2Ô∏è‚É£ Local LM Studio fallback (text only)\n",
    "        if self.use_local_fallback:\n",
    "            try:\n",
    "                text = self._generate_local(\n",
    "                    prompt=prompt,\n",
    "                    response_language=response_language,\n",
    "                )\n",
    "\n",
    "                return GeminiResponse(\n",
    "                    text=text,\n",
    "                    model=self.lmstudio_model,\n",
    "                    used_fallback=True,\n",
    "                )\n",
    "\n",
    "            except Exception as e:\n",
    "                local_error = str(e)\n",
    "        else:\n",
    "            local_error = \"Local fallback disabled.\"\n",
    "\n",
    "        # 3Ô∏è‚É£ Placeholder\n",
    "        return GeminiResponse(\n",
    "            text=(\n",
    "                \"AI is temporarily unavailable.\\n\\n\"\n",
    "                \"General guidance:\\n\"\n",
    "                \"- Take regular breaks\\n\"\n",
    "                \"- Prioritize sleep and hydration\\n\"\n",
    "                \"- Use simple stress-reduction techniques\\n\"\n",
    "                \"- Seek professional support if concerns persist\"\n",
    "            ),\n",
    "            model=\"placeholder\",\n",
    "            used_fallback=True,\n",
    "        )\n",
    "\n",
    "    # =================================================\n",
    "    # FILE / OCR GENERATION (Gemini only)\n",
    "    # =================================================\n",
    "    def generate_with_file(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        prompt: str,\n",
    "        response_language: str = \"en\",\n",
    "    ) -> GeminiResponse:\n",
    "        \"\"\"\n",
    "        Generate content using a file (PDF / image) + text prompt.\n",
    "        Used for OCR and document understanding.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.gemini_enabled:\n",
    "            return GeminiResponse(\n",
    "                text=\"File processing unavailable (Gemini API not configured).\",\n",
    "                model=\"fallback\",\n",
    "                used_fallback=True,\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            uploaded_file = genai.upload_file(file_path)\n",
    "\n",
    "            model = genai.GenerativeModel(self.model_name)\n",
    "            response = model.generate_content(\n",
    "                [\n",
    "                    uploaded_file,\n",
    "                    f\"Respond in {response_language}.\\n\\n{prompt}\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            return GeminiResponse(\n",
    "                text=response.text or \"\",\n",
    "                model=self.model_name,\n",
    "                used_fallback=False,\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            return GeminiResponse(\n",
    "                text=f\"Gemini file processing error: {e}\",\n",
    "                model=self.model_name,\n",
    "                used_fallback=True,\n",
    "            )\n",
    "\n",
    "    # =================================================\n",
    "    # LOCAL LM STUDIO (TEXT ONLY)\n",
    "    # =================================================\n",
    "    def _generate_local(self, prompt: str, response_language: str) -> str:\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.lmstudio_model,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        f\"Respond in {response_language}. \"\n",
    "                        \"Provide safe, supportive, non-diagnostic health guidance.\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                },\n",
    "            ],\n",
    "            \"temperature\": 0.5,\n",
    "            \"max_tokens\": 200,\n",
    "            \"stream\": False,\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            self.lmstudio_url,\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=120,\n",
    "        )\n",
    "\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f47055",
   "metadata": {},
   "source": [
    "Tabs Implementation\n",
    "The application includes numerous tabs, each corresponding to a specific aspect of health or app functionality. Each tab is built by a function (e.g., build_baseline_tab) that creates Gradio interface elements and defines how user inputs are handled. All tab builder functions accept the same parameters: the store (for data persistence), gemini (for AI calls), lang_state (to track the current language), and locales_dir (for translations). They typically load any previously saved data, set up input fields (numbers, text boxes, sliders, etc.), and define output displays or actions (like generating a summary or saving data).\n",
    "The tabs can be grouped into categories:\n",
    "General Assessment: Baseline, Workspace, Longitudinal ‚Äì initial assessments, workspace setup info, and long-term tracking of health metrics.\n",
    "Health Domains: Musculoskeletal (MSK), Eye, Mental, Hydration ‚Äì domain-specific health tracking (e.g., exercise/posture, eye strain, mental well-being, water intake), each providing recommendations or summaries related to that domain.\n",
    "Work & Rest: Productivity, Recovery/Sleep ‚Äì tracking work productivity and rest/sleep quality, offering suggestions to balance work and recovery.\n",
    "Action Plans: Checklist, Reminders ‚Äì execution-oriented tabs; a checklist for healthy tasks and a reminders schedule for routine health activities.\n",
    "Meta/Utility: Context, Reports, Settings, Help ‚Äì supporting features, including viewing aggregated context summaries, generating overall reports, adjusting settings (like clearing data), and viewing help information.\n",
    "We will go through each tab module below, showing its code and describing its functionality.\n",
    "General Recommendations Tab\n",
    "This tab (the \"Action Center\") aggregates inputs from all domains and provides overall health recommendations. It loads recent outputs or context from each domain and uses the AI to generate general advice. It may highlight urgent issues (safety flags) and give the user a summary of what to focus on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417a4d6",
   "metadata": {},
   "source": [
    "Baseline Tab\n",
    "The Baseline tab collects the user's baseline health information (e.g., initial metrics like height and weight, and possibly other survey data). On submission, it saves the data to a JSON file and uses the AI to produce initial health recommendations. It also runs safety checks on the provided data (for example, checking for dangerously high metrics) and includes any urgent warnings in the output. The resulting summary is saved to the context memory for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725658e9",
   "metadata": {},
   "source": [
    "# ü©∫ Baseline Module (Baseline Health Check-In)\n",
    "\n",
    "This module collects baseline biometric and lifestyle information such as height, weight, blood pressure, resting heart rate,\n",
    "and physical activity level.\n",
    "\n",
    "It is designed to generate **preventive, non-diagnostic** recommendations, focusing on lifestyle improvements and workplace\n",
    "health risks.\n",
    "\n",
    "Baseline data is used as the foundation for other modules and future personalized guidance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757aa055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Baseline Module ‚Äî Config + History Load (SAFE)\n",
    "# ==========================================\n",
    "\n",
    "def load_baseline_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Baseline module.\n",
    "    Uses the universal loader: load_domain_history()\n",
    "    \"\"\"\n",
    "    local_domain = \"baseline\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539037db",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Baseline Biometrics)\n",
    "\n",
    "This section builds the Baseline tab input UI.\n",
    "\n",
    "The baseline data includes:\n",
    "- Height and weight\n",
    "- Optional blood pressure and resting heart rate\n",
    "- Optional body fat and waist circumference\n",
    "- Activity level\n",
    "- Additional notes (free text)\n",
    "\n",
    "These inputs allow the system to provide general preventive recommendations and detect workplace health risk patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d33f07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Baseline Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_baseline_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    with gr.Row():\n",
    "        height_input = gr.Number(\n",
    "            value=saved_user_input.get(\"height\"),\n",
    "            label=_safe_t(lang, \"baseline.height\", locales_dir, default=\"Height (cm)\")\n",
    "        )\n",
    "        weight_input = gr.Number(\n",
    "            value=saved_user_input.get(\"weight\"),\n",
    "            label=_safe_t(lang, \"baseline.weight\", locales_dir, default=\"Weight (kg)\")\n",
    "        )\n",
    "\n",
    "    gr.Markdown(\"### Vitals & Biometrics (Optional)\")\n",
    "    with gr.Row():\n",
    "        systolic = gr.Number(value=saved_user_input.get(\"bp_systolic\"), label=\"Systolic BP (mmHg)\")\n",
    "        diastolic = gr.Number(value=saved_user_input.get(\"bp_diastolic\"), label=\"Diastolic BP (mmHg)\")\n",
    "        rhr = gr.Number(value=saved_user_input.get(\"rhr\"), label=\"Resting Heart Rate (BPM)\")\n",
    "\n",
    "    with gr.Row():\n",
    "        body_fat = gr.Number(value=saved_user_input.get(\"body_fat\"), label=\"Body Fat %\")\n",
    "        waist = gr.Number(value=saved_user_input.get(\"waist_cm\"), label=\"Waist Circumference (cm)\")\n",
    "\n",
    "    activity_level = gr.Dropdown(\n",
    "        choices=[\"Sedentary\", \"Moderately active\", \"Very active\"],\n",
    "        value=saved_user_input.get(\"activity_level\", \"Sedentary\"),\n",
    "        label=_safe_t(lang, \"baseline.activity\", locales_dir, default=\"Activity Level\"),\n",
    "    )\n",
    "\n",
    "    notes_input = gr.Textbox(\n",
    "        value=saved_user_input.get(\"notes\", \"\"),\n",
    "        label=_safe_t(lang, \"baseline.notes\", locales_dir, default=\"Additional Notes\"),\n",
    "        lines=3,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"height_input\": height_input,\n",
    "        \"weight_input\": weight_input,\n",
    "        \"systolic\": systolic,\n",
    "        \"diastolic\": diastolic,\n",
    "        \"rhr\": rhr,\n",
    "        \"body_fat\": body_fat,\n",
    "        \"waist\": waist,\n",
    "        \"activity_level\": activity_level,\n",
    "        \"notes_input\": notes_input,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0f6f7",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "This section defines:\n",
    "\n",
    "- A status message area for saving / generation feedback\n",
    "- A read-only output textbox that displays Gemini-generated recommendations\n",
    "\n",
    "The latest saved AI output is loaded automatically so the user can resume from their previous baseline report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26d315e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Baseline Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_baseline_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"baseline.output\", locales_dir, default=\"Baseline Recommendations\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=12\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a63492",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Recommendations + Safety Checks + Saving\n",
    "\n",
    "This section implements the Baseline logic:\n",
    "\n",
    "- Collect baseline user inputs into a structured JSON format\n",
    "- Run optional safety checks on free text / blood pressure values\n",
    "- Generate preventive recommendations using Gemini\n",
    "- Save user inputs and AI outputs as timestamped history records\n",
    "\n",
    "This ensures baseline data can be reused later in longitudinal tracking and other health modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bd0f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Baseline Module ‚Äî AI + Saving + Wiring\n",
    "# ==========================================\n",
    "\n",
    "def connect_baseline_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # IMPORTANT: local names (prevents cross-tab overwrite bugs)\n",
    "    local_domain = \"baseline\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect user input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(h, w, sys, dia, heart, fat, waist_val, activity, notes):\n",
    "        return {\n",
    "            \"height\": _to_float(h, 0.0),\n",
    "            \"weight\": _to_float(w, 0.0),\n",
    "            \"bp_systolic\": _to_int(sys, 0),\n",
    "            \"bp_diastolic\": _to_int(dia, 0),\n",
    "            \"rhr\": _to_int(heart, 0),\n",
    "            \"body_fat\": _to_float(fat, 0.0),\n",
    "            \"waist_cm\": _to_float(waist_val, 0.0),\n",
    "            \"activity_level\": str(activity or \"\"),\n",
    "            \"notes\": (notes or \"\").strip(),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(h, w, sys, dia, heart, fat, waist_val, activity, notes):\n",
    "        print(\"[baseline] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(h, w, sys, dia, heart, fat, waist_val, activity, notes)\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "\n",
    "            # ‚úÖ direct save\n",
    "            store.save_json(local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Baseline user input saved -> `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[baseline] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(h, w, sys, dia, heart, fat, waist_val, activity, notes):\n",
    "        print(\"[baseline] üîò Generate AI clicked\")\n",
    "\n",
    "        user_input = collect_user_input(h, w, sys, dia, heart, fat, waist_val, activity, notes)\n",
    "\n",
    "        payload = {\n",
    "            \"bp\": {\n",
    "                \"systolic\": user_input.get(\"bp_systolic\"),\n",
    "                \"diastolic\": user_input.get(\"bp_diastolic\"),\n",
    "            },\n",
    "            \"free_text\": user_input.get(\"notes\", \"\")\n",
    "        }\n",
    "\n",
    "        flags = []\n",
    "        try:\n",
    "            safety_fn = globals().get(\"apply_safety_checks\")\n",
    "            if safety_fn:\n",
    "                payload_checked = safety_fn(payload)\n",
    "                flags = payload_checked.get(\"safety_flags\", []) if isinstance(payload_checked, dict) else []\n",
    "        except Exception as e:\n",
    "            print(f\"[baseline] ‚ö†Ô∏è apply_safety_checks failed: {e}\")\n",
    "\n",
    "        rec_prompt = (\n",
    "            \"You are a preventive health assistant.\\n\"\n",
    "            \"Use the baseline data below to provide non-diagnostic health recommendations.\\n\"\n",
    "            \"Focus on lifestyle, prevention, desk-work risk factors, and practical next steps.\\n\\n\"\n",
    "            f\"BASELINE DATA:\\n{json.dumps(user_input, indent=2, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            rec = gemini.generate(prompt=rec_prompt, response_language=current_lang)\n",
    "            rec_text = rec.text.strip() if hasattr(rec, \"text\") and rec.text else str(rec).strip()\n",
    "        except Exception as e:\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not rec_text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        if flags:\n",
    "            warnings = \" \".join(f.get(\"message\", \"\") for f in flags if isinstance(f, dict))\n",
    "            warnings = warnings.strip()\n",
    "            if warnings:\n",
    "                rec_text = f\"‚ö†Ô∏è {warnings}\\n\\n{rec_text}\"\n",
    "\n",
    "        return rec_text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[baseline] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "\n",
    "            # ‚úÖ direct save\n",
    "            store.save_json(local_ai_file, existing)\n",
    "\n",
    "            # Update domain summary\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[baseline] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Baseline AI output saved -> `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[baseline] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Recommendations\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"height_input\"],\n",
    "        ui_inputs[\"weight_input\"],\n",
    "        ui_inputs[\"systolic\"],\n",
    "        ui_inputs[\"diastolic\"],\n",
    "        ui_inputs[\"rhr\"],\n",
    "        ui_inputs[\"body_fat\"],\n",
    "        ui_inputs[\"waist\"],\n",
    "        ui_inputs[\"activity_level\"],\n",
    "        ui_inputs[\"notes_input\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (Baseline) ‚Äî SAFE\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _baseline_demo_generate():\n",
    "            print(\"[baseline-demo] üöÄ Demo generate using saved baseline data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved baseline demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved baseline record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace health assistant.\\n\"\n",
    "                \"Analyze the following baseline health data and provide actionable, non-diagnostic recommendations.\\n\"\n",
    "                \"Focus on lifestyle prevention, general health risk awareness, and workplace habits.\\n\"\n",
    "                \"Mention missing values gently.\\n\"\n",
    "                \"Include red-flag warning signs if needed.\\n\\n\"\n",
    "                f\"BASELINE DATA:\\n{last}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Baseline demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"Baseline Module\",\n",
    "            generate_fn=_baseline_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[baseline] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33b968e",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Baseline Tab Builder\n",
    "\n",
    "This function is the entry point used by the main Gradio app.\n",
    "\n",
    "It:\n",
    "- Loads the latest Baseline history\n",
    "- Builds the input UI components\n",
    "- Builds the output UI components\n",
    "- Connects button callbacks to AI generation and saving logic\n",
    "\n",
    "The Baseline module is usually the first module users complete, and it provides foundational data for other modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef00a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Baseline Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_baseline_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None\n",
    "):\n",
    "\n",
    "    # -------------------------\n",
    "    # Local safe constants\n",
    "    # -------------------------\n",
    "    local_domain = \"baseline\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[baseline] ‚úÖ build_baseline_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    # -------------------------\n",
    "    # Load latest saved history\n",
    "    # -------------------------\n",
    "    saved_user_input, saved_ai_text = load_domain_history(store, local_domain)\n",
    "\n",
    "    # -------------------------\n",
    "    # UI\n",
    "    # -------------------------\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"baseline.title\",\n",
    "            locales_dir,\n",
    "            default=\"Baseline Health Check-In\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ui_inputs = build_baseline_inputs(saved_user_input, lang, locales_dir)\n",
    "\n",
    "    output, status = build_baseline_outputs(saved_ai_text, lang, locales_dir)\n",
    "\n",
    "    # -------------------------\n",
    "    # Logic wiring\n",
    "    # -------------------------\n",
    "    connect_baseline_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88131d",
   "metadata": {},
   "source": [
    "Workspace Tab\n",
    "The Workspace tab gathers information about the user's work environment or habits (like ergonomics, posture, or work setup). Based on these inputs, it generates recommendations to improve the workspace for better health (e.g., posture tips, ergonomic adjustments). The tab updates the context summary for the workspace domain, which can be used for global recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a932f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# ü™ë Workspace & Ergonomics Module  \n",
       "*Physical Environment & Posture Awareness*\n",
       "\n",
       "The physical workspace plays a central role in musculoskeletal health, comfort,\n",
       "and sustained productivity. Desk-based work often involves prolonged sitting,\n",
       "repetitive movements, and fixed postures that can gradually place strain on the\n",
       "neck, shoulders, back, wrists, and eyes‚Äîoften without immediate pain.\n",
       "\n",
       "This module is designed to support **workspace and posture awareness**, not\n",
       "diagnosis. It helps identify everyday environmental and ergonomic factors that may\n",
       "contribute to discomfort, fatigue, or long-term strain during desk work.\n",
       "\n",
       "### What this module captures\n",
       "- Type of workspace (office, home, shared)\n",
       "- Chair and desk setup\n",
       "- Screen height and viewing distance\n",
       "- Keyboard and mouse positioning\n",
       "- Sitting duration and movement breaks\n",
       "- Posture-related discomfort or pain signals\n",
       "- Use of ergonomic supports (chair, stand, external devices)\n",
       "\n",
       "### Why this matters\n",
       "Poor ergonomics rarely cause sudden injury. Instead, strain typically accumulates\n",
       "through small mismatches between the body and the work environment‚Äîsuch as low\n",
       "screens, unsupported seating, or long periods without movement.\n",
       "\n",
       "Over time, these factors can contribute to musculoskeletal discomfort, reduced\n",
       "concentration, and decreased work endurance. Early awareness allows for simple,\n",
       "low-cost adjustments that may significantly reduce long-term risk.\n",
       "\n",
       "### How AI is used in this section\n",
       "The AI provides **non-diagnostic, preventive guidance** focused on:\n",
       "- Practical ergonomic adjustments for desk-based work\n",
       "- Posture and movement reminders that fit real workdays\n",
       "- Reducing strain through small environmental changes\n",
       "- Simple habits to support long-term musculoskeletal health\n",
       "\n",
       "The goal is to promote comfort, sustainability, and prevention‚Äînot to replace\n",
       "professional ergonomic or medical assessment.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(WORKSPACE_INFO_MD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d710c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Workspace Module ‚Äî Config + History Load (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def load_workspace_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Workspace module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"workspace\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b5616f",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Workspace Setup + Daily Habits)\n",
    "\n",
    "This section builds the workspace input UI.\n",
    "\n",
    "The user records:\n",
    "- Whether posture was good today\n",
    "- Break frequency and eating at desk\n",
    "- Workstation equipment and physical setup\n",
    "- Environmental factors such as noise and temperature\n",
    "- Additional notes\n",
    "\n",
    "These signals are later converted into a structured JSON payload and passed to Gemini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "008c1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Workspace Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_workspace_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(\"### Daily Habits\")\n",
    "\n",
    "    with gr.Row():\n",
    "        posture = gr.Checkbox(\n",
    "            value=bool(saved_user_input.get(\"good_posture\", False)),\n",
    "            label=_safe_t(lang, \"workspace.posture\", locales_dir, default=\"Maintained good posture today\")\n",
    "        )\n",
    "\n",
    "        breaks = gr.Radio(\n",
    "            choices=[\"Hourly breaks\", \"Few breaks\", \"No breaks\"],\n",
    "            value=saved_user_input.get(\"breaks\", \"Few breaks\"),\n",
    "            label=_safe_t(lang, \"workspace.breaks\", locales_dir, default=\"Break Frequency\")\n",
    "        )\n",
    "\n",
    "        eat_at_desk = gr.Checkbox(\n",
    "            value=bool(saved_user_input.get(\"eat_at_desk\", False)),\n",
    "            label=\"Ate lunch at desk\"\n",
    "        )\n",
    "\n",
    "    with gr.Accordion(\"Workstation Equipment & Geometry (Click to Expand)\", open=False):\n",
    "        gr.Markdown(\"Update this section only when your physical setup changes.\")\n",
    "\n",
    "        with gr.Row():\n",
    "            input_device = gr.Dropdown(\n",
    "                choices=[\"Standard Mouse\", \"Vertical/Ergo Mouse\", \"Trackpad\", \"Trackball\"],\n",
    "                value=saved_user_input.get(\"input_device\", \"Standard Mouse\"),\n",
    "                label=\"Primary Input Device\"\n",
    "            )\n",
    "\n",
    "            keyboard_type = gr.Dropdown(\n",
    "                choices=[\"Standard\", \"Mechanical\", \"Split/Ergonomic\", \"Laptop Keyboard\"],\n",
    "                value=saved_user_input.get(\"keyboard_type\", \"Standard\"),\n",
    "                label=\"Keyboard Type\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            wrist_support = gr.Radio(\n",
    "                choices=[\"Yes\", \"No\"],\n",
    "                value=saved_user_input.get(\"wrist_support\", \"No\"),\n",
    "                label=\"Uses Wrist Support?\"\n",
    "            )\n",
    "\n",
    "            armrests = gr.Dropdown(\n",
    "                choices=[\"Level with desk\", \"Too High\", \"Too Low\", \"None\"],\n",
    "                value=saved_user_input.get(\"armrests\", \"Level with desk\"),\n",
    "                label=\"Armrest Position\"\n",
    "            )\n",
    "\n",
    "            lumbar = gr.Checkbox(\n",
    "                value=bool(saved_user_input.get(\"lumbar_support\", True)),\n",
    "                label=\"Chair has Lumbar Support\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            monitor_height = gr.Dropdown(\n",
    "                choices=[\"Eye Level\", \"Below Eye Level (Looking Down)\", \"Above Eye Level\"],\n",
    "                value=saved_user_input.get(\"monitor_height\", \"Below Eye Level (Looking Down)\"),\n",
    "                label=\"Monitor Height\"\n",
    "            )\n",
    "\n",
    "            feet_position = gr.Dropdown(\n",
    "                choices=[\"Flat on floor\", \"On footrest\", \"Dangling/Crossed\"],\n",
    "                value=saved_user_input.get(\"feet_position\", \"Flat on floor\"),\n",
    "                label=\"Feet Position\"\n",
    "            )\n",
    "\n",
    "    with gr.Accordion(\"Environment & Atmosphere\", open=False):\n",
    "        with gr.Row():\n",
    "            noise = gr.Dropdown(\n",
    "                choices=[\"Silent\", \"Hum/White Noise\", \"Distracting/Loud\"],\n",
    "                value=saved_user_input.get(\"noise_level\", \"Hum/White Noise\"),\n",
    "                label=\"Noise Level\"\n",
    "            )\n",
    "\n",
    "            temp = gr.Dropdown(\n",
    "                choices=[\"Cold\", \"Comfortable\", \"Warm\"],\n",
    "                value=saved_user_input.get(\"temperature\", \"Comfortable\"),\n",
    "                label=\"Room Temperature\"\n",
    "            )\n",
    "\n",
    "            clutter = gr.Dropdown(\n",
    "                choices=[\"Minimal\", \"Average\", \"Cluttered\"],\n",
    "                value=saved_user_input.get(\"clutter\", \"Average\"),\n",
    "                label=\"Desk Clutter\"\n",
    "            )\n",
    "\n",
    "    notes_input = gr.Textbox(\n",
    "        value=saved_user_input.get(\"notes\", \"\"),\n",
    "        label=_safe_t(lang, \"workspace.notes\", locales_dir, default=\"Additional Notes\"),\n",
    "        lines=2\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"posture\": posture,\n",
    "        \"breaks\": breaks,\n",
    "        \"eat_at_desk\": eat_at_desk,\n",
    "        \"input_device\": input_device,\n",
    "        \"keyboard_type\": keyboard_type,\n",
    "        \"wrist_support\": wrist_support,\n",
    "        \"armrests\": armrests,\n",
    "        \"lumbar\": lumbar,\n",
    "        \"monitor_height\": monitor_height,\n",
    "        \"feet_position\": feet_position,\n",
    "        \"noise\": noise,\n",
    "        \"temp\": temp,\n",
    "        \"clutter\": clutter,\n",
    "        \"notes_input\": notes_input,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a7f82",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "This section defines:\n",
    "\n",
    "- A status message area (save / error / generation feedback)\n",
    "- A read-only AI output textbox that displays ergonomic recommendations\n",
    "\n",
    "The latest saved output is loaded automatically to preserve continuity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b0c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Workspace Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_workspace_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"workspace.output\", locales_dir, default=\"Workspace Recommendations\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=10\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03e329d",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Recommendations + Saving\n",
    "\n",
    "This section handles the core logic:\n",
    "\n",
    "- Collecting workspace inputs into a structured JSON object\n",
    "- Saving user input history to `workspace_user_input.json`\n",
    "- Sending the workspace data to Gemini\n",
    "- Saving AI output history to `workspace_ai_output.json`\n",
    "\n",
    "The generated recommendations focus on ergonomic improvements, micro-break planning,\n",
    "and prevention of pain and fatigue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c7978ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Workspace Module ‚Äî AI + Saving + Wiring (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def connect_workspace_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # -----------------------------------\n",
    "    # Local domain config (FIXED)\n",
    "    # -----------------------------------\n",
    "    local_domain = \"workspace\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        posture_val, breaks_val, eat_val,\n",
    "        input_dev, key_type, wrist, arms, lumb, mon_h, feet,\n",
    "        noise_val, temp_val, clutter_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        return {\n",
    "            \"good_posture\": _to_bool(posture_val),\n",
    "            \"breaks\": _to_str(breaks_val, \"\"),\n",
    "            \"eat_at_desk\": _to_bool(eat_val),\n",
    "            \"input_device\": _to_str(input_dev, \"\"),\n",
    "            \"keyboard_type\": _to_str(key_type, \"\"),\n",
    "            \"wrist_support\": _to_str(wrist, \"\"),\n",
    "            \"armrests\": _to_str(arms, \"\"),\n",
    "            \"lumbar_support\": _to_bool(lumb),\n",
    "            \"monitor_height\": _to_str(mon_h, \"\"),\n",
    "            \"feet_position\": _to_str(feet, \"\"),\n",
    "            \"noise_level\": _to_str(noise_val, \"\"),\n",
    "            \"temperature\": _to_str(temp_val, \"\"),\n",
    "            \"clutter\": _to_str(clutter_val, \"\"),\n",
    "            \"notes\": _to_str(notes_val, \"\").strip(),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        posture_val, breaks_val, eat_val,\n",
    "        input_dev, key_type, wrist, arms, lumb, mon_h, feet,\n",
    "        noise_val, temp_val, clutter_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        print(\"[workspace] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                posture_val, breaks_val, eat_val,\n",
    "                input_dev, key_type, wrist, arms, lumb, mon_h, feet,\n",
    "                noise_val, temp_val, clutter_val,\n",
    "                notes_val\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Workspace user input saved -> `{_debug_store_path(store, local_user_file)}`\"\n",
    "        except Exception as e:\n",
    "            print(f\"[workspace] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        posture_val, breaks_val, eat_val,\n",
    "        input_dev, key_type, wrist, arms, lumb, mon_h, feet,\n",
    "        noise_val, temp_val, clutter_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        print(\"[workspace] üîò Generate AI clicked\")\n",
    "\n",
    "        user_input = collect_user_input(\n",
    "            posture_val, breaks_val, eat_val,\n",
    "            input_dev, key_type, wrist, arms, lumb, mon_h, feet,\n",
    "            noise_val, temp_val, clutter_val,\n",
    "            notes_val\n",
    "        )\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a preventive workplace ergonomics assistant.\\n\"\n",
    "            \"Analyze the following workspace data and provide actionable, non-diagnostic recommendations.\\n\"\n",
    "            \"Identify ergonomic risks and suggest specific physical adjustments.\\n\"\n",
    "            \"If breaks are 'No breaks', recommend a realistic micro-break plan.\\n\\n\"\n",
    "            f\"WORKSPACE DATA:\\n{json.dumps(user_input, indent=2, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[workspace] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_ai_file, existing)\n",
    "\n",
    "            # Update domain summary\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[workspace] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Workspace AI output saved -> `{_debug_store_path(store, local_ai_file)}`\"\n",
    "        except Exception as e:\n",
    "            print(f\"[workspace] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Recommendations\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"posture\"],\n",
    "        ui_inputs[\"breaks\"],\n",
    "        ui_inputs[\"eat_at_desk\"],\n",
    "        ui_inputs[\"input_device\"],\n",
    "        ui_inputs[\"keyboard_type\"],\n",
    "        ui_inputs[\"wrist_support\"],\n",
    "        ui_inputs[\"armrests\"],\n",
    "        ui_inputs[\"lumbar\"],\n",
    "        ui_inputs[\"monitor_height\"],\n",
    "        ui_inputs[\"feet_position\"],\n",
    "        ui_inputs[\"noise\"],\n",
    "        ui_inputs[\"temp\"],\n",
    "        ui_inputs[\"clutter\"],\n",
    "        ui_inputs[\"notes_input\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # =====================================================\n",
    "    # Demo Hook Registration (Workspace)  ‚úÖ FIXED\n",
    "    # =====================================================\n",
    "    try:\n",
    "        def _workspace_demo_generate():\n",
    "            print(\"[workspace-demo] üöÄ Demo generate using saved workspace data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved workspace demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved workspace record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace ergonomics assistant.\\n\"\n",
    "                \"Analyze the following workspace setup data and provide actionable, non-diagnostic ergonomic recommendations.\\n\"\n",
    "                \"Focus on posture, chair/desk setup, screen height, breaks, and practical adjustments.\\n\"\n",
    "                \"Mention missing values gently.\\n\\n\"\n",
    "                f\"WORKSPACE DATA:\\n{json.dumps(last, indent=2, ensure_ascii=False)}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Workspace demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"Workspace Module\",\n",
    "            generate_fn=_workspace_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[workspace] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e6aeb",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Workspace Tab Builder\n",
    "\n",
    "This function is the main entry point for the Workspace tab.\n",
    "\n",
    "It:\n",
    "- Loads the latest saved history\n",
    "- Builds the UI inputs and outputs\n",
    "- Connects the UI buttons to saving + Gemini generation logic\n",
    "\n",
    "The Workspace module supports ergonomic improvements and injury prevention for desk workers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "348aac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Workspace Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_workspace_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    # -------------------------\n",
    "    # Local safe constants\n",
    "    # -------------------------\n",
    "    local_domain = \"workspace\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[workspace] ‚úÖ build_workspace_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    # -------------------------\n",
    "    # Load latest saved history\n",
    "    # -------------------------\n",
    "    saved_user_input, saved_ai_text = load_workspace_history(store)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"workspace.title\",\n",
    "            locales_dir,\n",
    "            default=\"ü™ë Workspace Ergonomics and Habits\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (Workspace Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò Workspace Tab Guide\",\n",
    "        content_md=WORKSPACE_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è Workspace Info\",\n",
    "        open_label=\"‚ùå Hide Workspace Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_workspace_inputs(\n",
    "        saved_user_input,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output, status = build_workspace_outputs(\n",
    "        saved_ai_text,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_workspace_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc37cf5",
   "metadata": {},
   "source": [
    "Longitudinal Tab\n",
    "The Longitudinal tab handles long-term tracking of the user's health metrics or progress. It might log periodic inputs (like weekly or monthly check-ins) and uses the AI to identify trends or changes over time. This helps in understanding improvements or deteriorations in the user's health across all tracked metrics. The tab likely composes summaries of these trends and updates the context for the longitudinal domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af80014",
   "metadata": {},
   "source": [
    "# üìà Longitudinal Module (Progress Tracker & Health Wallet)\n",
    "\n",
    "This module acts as a personal \"Health Wallet\" where users can store repeated lab test results and health notes over time.\n",
    "\n",
    "Key features:\n",
    "- Manual entry of common lab values (CBC, metabolic panel, vitamins, hormones)\n",
    "- Free-text journaling of symptoms, fatigue, energy, and progress\n",
    "- Upload of PDF or image lab reports\n",
    "- OCR extraction (via Gemini or OCR pipeline) to auto-fill lab fields\n",
    "- AI interpretation of each longitudinal entry\n",
    "\n",
    "All saved entries are stored as timestamped records to support trend tracking over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60bced46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Longitudinal Module ‚Äî Config + History Load (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def _safe_float(x):\n",
    "    try:\n",
    "        if x is None or x == \"\":\n",
    "            return None\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_longitudinal_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Longitudinal module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"longitudinal\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575beef",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Manual Entry + Upload + Journal)\n",
    "\n",
    "This section builds the Longitudinal input UI.\n",
    "\n",
    "Users can enter:\n",
    "- Notes or journal text (symptoms, fatigue, energy, progress)\n",
    "- Upload a lab report (PDF/image)\n",
    "- Manual structured lab values (CBC, metabolic, vitamins, hormones)\n",
    "- Custom marker (any test the user wants)\n",
    "\n",
    "The uploaded file can be processed via OCR and used to auto-fill structured lab fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "957fd0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Longitudinal Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_longitudinal_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    with gr.Row():\n",
    "        log_input = gr.Textbox(\n",
    "            label=_safe_t(lang, \"longitudinal.log\", locales_dir, default=\"Journal/Notes\"),\n",
    "            placeholder=\"How are you feeling? Or paste text from a report...\",\n",
    "            lines=3,\n",
    "            value=saved_user_input.get(\"notes\", \"\")\n",
    "        )\n",
    "\n",
    "        file_input = gr.File(\n",
    "            label=_safe_t(lang, \"longitudinal.upload\", locales_dir, default=\"Upload Lab Report (PDF/Image)\")\n",
    "        )\n",
    "\n",
    "    gr.Markdown(\"### Manual Lab Entry (Optional)\")\n",
    "\n",
    "    with gr.Accordion(\"ü©∏ CBC & Immunity (Energy Levels)\", open=False):\n",
    "        with gr.Row():\n",
    "            hb = gr.Number(label=\"Hemoglobin (g/dL)\", value=saved_user_input.get(\"hb\"))\n",
    "            wbc = gr.Number(label=\"WBC Count (10^9/L)\", value=saved_user_input.get(\"wbc\"))\n",
    "            platelets = gr.Number(label=\"Platelets (10^9/L)\", value=saved_user_input.get(\"platelets\"))\n",
    "\n",
    "    with gr.Accordion(\"üç¨ Metabolic & Heart Health\", open=False):\n",
    "        with gr.Row():\n",
    "            glucose = gr.Number(label=\"Fasting Glucose (mg/dL)\", value=saved_user_input.get(\"glucose\"))\n",
    "            hba1c = gr.Number(label=\"HbA1c (%)\", value=saved_user_input.get(\"hba1c\"))\n",
    "        with gr.Row():\n",
    "            cholesterol = gr.Number(label=\"Total Cholesterol (mg/dL)\", value=saved_user_input.get(\"cholesterol\"))\n",
    "            triglycerides = gr.Number(label=\"Triglycerides (mg/dL)\", value=saved_user_input.get(\"triglycerides\"))\n",
    "\n",
    "    with gr.Accordion(\"‚ö° Focus Drivers (Vitamins & Hormones)\", open=False):\n",
    "        with gr.Row():\n",
    "            vit_d = gr.Number(label=\"Vitamin D (ng/mL)\", value=saved_user_input.get(\"vit_d\"))\n",
    "            vit_b12 = gr.Number(label=\"Vitamin B12 (pg/mL)\", value=saved_user_input.get(\"vit_b12\"))\n",
    "            tsh = gr.Number(label=\"TSH (Thyroid) (uIU/mL)\", value=saved_user_input.get(\"tsh\"))\n",
    "\n",
    "    with gr.Accordion(\"üîß Custom / Other Marker\", open=False):\n",
    "        with gr.Row():\n",
    "            custom_name = gr.Textbox(label=\"Marker Name (e.g. Magnesium)\", value=saved_user_input.get(\"custom_name\", \"\"))\n",
    "            custom_val = gr.Number(label=\"Value\", value=saved_user_input.get(\"custom_value\"))\n",
    "            custom_unit = gr.Textbox(label=\"Unit\", value=saved_user_input.get(\"custom_unit\", \"\"))\n",
    "\n",
    "    return {\n",
    "        \"log_input\": log_input,\n",
    "        \"file_input\": file_input,\n",
    "\n",
    "        \"hb\": hb,\n",
    "        \"wbc\": wbc,\n",
    "        \"platelets\": platelets,\n",
    "\n",
    "        \"glucose\": glucose,\n",
    "        \"hba1c\": hba1c,\n",
    "        \"cholesterol\": cholesterol,\n",
    "        \"triglycerides\": triglycerides,\n",
    "\n",
    "        \"vit_d\": vit_d,\n",
    "        \"vit_b12\": vit_b12,\n",
    "        \"tsh\": tsh,\n",
    "\n",
    "        \"custom_name\": custom_name,\n",
    "        \"custom_val\": custom_val,\n",
    "        \"custom_unit\": custom_unit,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f170a3d",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "This section defines the main output UI:\n",
    "\n",
    "- A status box for extraction/saving feedback\n",
    "- A read-only AI output textbox showing the interpretation of the current entry\n",
    "\n",
    "The latest saved interpretation is automatically loaded when the tab is opened.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c60d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Longitudinal Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_longitudinal_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status_box = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"longitudinal.output\", locales_dir, default=\"Longitudinal Analysis\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=12\n",
    "    )\n",
    "\n",
    "    return output, status_box\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f213f43",
   "metadata": {},
   "source": [
    "## Step 3A ‚Äî OCR + Auto-Fill Extraction\n",
    "\n",
    "This part implements automatic extraction of lab values.\n",
    "\n",
    "Workflow:\n",
    "1. User writes notes OR uploads a lab report (PDF/image)\n",
    "2. OCR extracts raw text from the file (if provided)\n",
    "3. Gemini receives the text and returns STRICT JSON\n",
    "4. Extracted values are parsed and inserted into the structured lab fields\n",
    "\n",
    "This allows the app to support paper-based lab reports and scanned PDFs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d32b9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Longitudinal Module ‚Äî OCR + Auto-Fill Extractor\n",
    "# ==========================================\n",
    "\n",
    "def build_longitudinal_extractor(store, gemini, lang_state, ui_inputs, status_box):\n",
    "    \"\"\"\n",
    "    Creates the \"Extract Lab Values\" button and its callback.\n",
    "    Returns the extract button so it can be used in the main tab.\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_structured_from_text_and_file(log_text, file):\n",
    "        print(\"[longitudinal] üîò Extract Lab Values clicked\")\n",
    "\n",
    "        text_content = (log_text or \"\").strip()\n",
    "\n",
    "        # OCR if file provided\n",
    "        if file is not None:\n",
    "            try:\n",
    "                extractor = globals().get(\"extract_text_from_file\")\n",
    "                if extractor:\n",
    "                    extracted = extractor(\n",
    "                        gemini,\n",
    "                        file.name,\n",
    "                        lang=lang_state.value if hasattr(lang_state, \"value\") else lang_state,\n",
    "                    )\n",
    "                    extracted = extracted.strip() if extracted else \"\"\n",
    "                    if extracted:\n",
    "                        text_content += f\"\\n\\n[FILE CONTENT START]\\n{extracted}\\n[FILE CONTENT END]\"\n",
    "                else:\n",
    "                    return (\n",
    "                        None, None, None,\n",
    "                        None, None, None, None,\n",
    "                        None, None, None,\n",
    "                        \"\", None, \"\",\n",
    "                        \"‚ö†Ô∏è OCR function not found.\"\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                return (\n",
    "                    None, None, None,\n",
    "                    None, None, None, None,\n",
    "                    None, None, None,\n",
    "                    \"\", None, \"\",\n",
    "                    f\"‚ö†Ô∏è OCR failed: {e}\"\n",
    "                )\n",
    "\n",
    "        if not text_content.strip():\n",
    "            return (\n",
    "                None, None, None,\n",
    "                None, None, None, None,\n",
    "                None, None, None,\n",
    "                \"\", None, \"\",\n",
    "                \"‚ö†Ô∏è No text or file content provided.\"\n",
    "            )\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a medical data extraction assistant.\\n\"\n",
    "            \"Extract any lab values from the text below.\\n\\n\"\n",
    "            \"Return STRICT JSON only (no explanation, no markdown).\\n\"\n",
    "            \"JSON schema:\\n\"\n",
    "            \"{\\n\"\n",
    "            '  \"cbc\": {\"hb\": number|null, \"wbc\": number|null, \"platelets\": number|null},\\n'\n",
    "            '  \"metabolic\": {\"glucose\": number|null, \"hba1c\": number|null, \"cholesterol\": number|null, \"triglycerides\": number|null},\\n'\n",
    "            '  \"vitamins\": {\"vit_d\": number|null, \"vit_b12\": number|null, \"tsh\": number|null},\\n'\n",
    "            '  \"custom\": {\"name\": string|null, \"value\": number|null, \"unit\": string|null}\\n'\n",
    "            \"}\\n\\n\"\n",
    "            f\"TEXT:\\n{text_content}\\n\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            raw = resp.text.strip() if hasattr(resp, \"text\") and resp.text else \"\"\n",
    "        except Exception as e:\n",
    "            return (\n",
    "                None, None, None,\n",
    "                None, None, None, None,\n",
    "                None, None, None,\n",
    "                \"\", None, \"\",\n",
    "                f\"‚ö†Ô∏è Extraction AI failed: {e}\"\n",
    "            )\n",
    "\n",
    "        if not raw:\n",
    "            return (\n",
    "                None, None, None,\n",
    "                None, None, None, None,\n",
    "                None, None, None,\n",
    "                \"\", None, \"\",\n",
    "                \"‚ö†Ô∏è Model returned empty extraction output.\"\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            extracted_json = json.loads(raw)\n",
    "        except Exception:\n",
    "            return (\n",
    "                None, None, None,\n",
    "                None, None, None, None,\n",
    "                None, None, None,\n",
    "                \"\", None, \"\",\n",
    "                \"‚ö†Ô∏è Extraction failed: model did not return valid JSON.\"\n",
    "            )\n",
    "\n",
    "        cbc = extracted_json.get(\"cbc\", {}) if isinstance(extracted_json, dict) else {}\n",
    "        metabolic = extracted_json.get(\"metabolic\", {}) if isinstance(extracted_json, dict) else {}\n",
    "        vitamins = extracted_json.get(\"vitamins\", {}) if isinstance(extracted_json, dict) else {}\n",
    "        custom = extracted_json.get(\"custom\", {}) if isinstance(extracted_json, dict) else {}\n",
    "\n",
    "        hb_val = _safe_float(cbc.get(\"hb\"))\n",
    "        wbc_val = _safe_float(cbc.get(\"wbc\"))\n",
    "        plt_val = _safe_float(cbc.get(\"platelets\"))\n",
    "\n",
    "        gluc_val = _safe_float(metabolic.get(\"glucose\"))\n",
    "        a1c_val = _safe_float(metabolic.get(\"hba1c\"))\n",
    "        chol_val = _safe_float(metabolic.get(\"cholesterol\"))\n",
    "        tri_val = _safe_float(metabolic.get(\"triglycerides\"))\n",
    "\n",
    "        d_val = _safe_float(vitamins.get(\"vit_d\"))\n",
    "        b12_val = _safe_float(vitamins.get(\"vit_b12\"))\n",
    "        tsh_val = _safe_float(vitamins.get(\"tsh\"))\n",
    "\n",
    "        cust_name = custom.get(\"name\") or \"\"\n",
    "        cust_value = _safe_float(custom.get(\"value\"))\n",
    "        cust_unit = custom.get(\"unit\") or \"\"\n",
    "\n",
    "        return (\n",
    "            hb_val, wbc_val, plt_val,\n",
    "            gluc_val, a1c_val, chol_val, tri_val,\n",
    "            d_val, b12_val, tsh_val,\n",
    "            cust_name, cust_value, cust_unit,\n",
    "            \"‚úÖ Extracted values filled into the fields.\"\n",
    "        )\n",
    "\n",
    "    extract_btn = gr.Button(\"Extract Lab Values (Auto-Fill)\", variant=\"secondary\")\n",
    "\n",
    "    extract_btn.click(\n",
    "        fn=extract_structured_from_text_and_file,\n",
    "        inputs=[ui_inputs[\"log_input\"], ui_inputs[\"file_input\"]],\n",
    "        outputs=[\n",
    "            ui_inputs[\"hb\"], ui_inputs[\"wbc\"], ui_inputs[\"platelets\"],\n",
    "            ui_inputs[\"glucose\"], ui_inputs[\"hba1c\"], ui_inputs[\"cholesterol\"], ui_inputs[\"triglycerides\"],\n",
    "            ui_inputs[\"vit_d\"], ui_inputs[\"vit_b12\"], ui_inputs[\"tsh\"],\n",
    "            ui_inputs[\"custom_name\"], ui_inputs[\"custom_val\"], ui_inputs[\"custom_unit\"],\n",
    "            status_box\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return extract_btn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9534ad",
   "metadata": {},
   "source": [
    "## Step 3B ‚Äî Longitudinal Reasoning + Saving History\n",
    "\n",
    "This section performs the main reasoning step:\n",
    "\n",
    "- Combines structured lab fields + notes + OCR text (if provided)\n",
    "- Sends the combined entry to Gemini for interpretation\n",
    "- Highlights possible abnormal markers and their relevance to energy, focus, fatigue, and desk-work performance\n",
    "- Saves user input history and AI output history as timestamped records\n",
    "\n",
    "This enables the platform to function as a long-term personal health progress tracker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01563643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Longitudinal Module ‚Äî AI + Saving + Wiring (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def connect_longitudinal_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status_box: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # -------------------------\n",
    "    # LOCAL DOMAIN CONSTANTS\n",
    "    # -------------------------\n",
    "    local_domain = \"longitudinal\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect user input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        log_text,\n",
    "        hb_v, wbc_v, plt_v,\n",
    "        gluc_v, a1c_v, chol_v, tri_v,\n",
    "        d_v, b12_v, tsh_v,\n",
    "        cust_n, cust_v, cust_u\n",
    "    ):\n",
    "        return {\n",
    "            \"notes\": (log_text or \"\").strip(),\n",
    "            \"hb\": hb_v,\n",
    "            \"wbc\": wbc_v,\n",
    "            \"platelets\": plt_v,\n",
    "            \"glucose\": gluc_v,\n",
    "            \"hba1c\": a1c_v,\n",
    "            \"cholesterol\": chol_v,\n",
    "            \"triglycerides\": tri_v,\n",
    "            \"vit_d\": d_v,\n",
    "            \"vit_b12\": b12_v,\n",
    "            \"tsh\": tsh_v,\n",
    "            \"custom_name\": cust_n,\n",
    "            \"custom_value\": cust_v,\n",
    "            \"custom_unit\": cust_u,\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        log_text,\n",
    "        hb_v, wbc_v, plt_v,\n",
    "        gluc_v, a1c_v, chol_v, tri_v,\n",
    "        d_v, b12_v, tsh_v,\n",
    "        cust_n, cust_v, cust_u\n",
    "    ):\n",
    "        print(\"[longitudinal] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                log_text,\n",
    "                hb_v, wbc_v, plt_v,\n",
    "                gluc_v, a1c_v, chol_v, tri_v,\n",
    "                d_v, b12_v, tsh_v,\n",
    "                cust_n, cust_v, cust_u\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Longitudinal user input saved -> `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[longitudinal] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI interpretation\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        log_text, file,\n",
    "        hb_v, wbc_v, plt_v,\n",
    "        gluc_v, a1c_v, chol_v, tri_v,\n",
    "        d_v, b12_v, tsh_v,\n",
    "        cust_n, cust_v, cust_u\n",
    "    ):\n",
    "        print(\"[longitudinal] üîò Generate AI clicked\")\n",
    "\n",
    "        text_content = (log_text or \"\").strip()\n",
    "\n",
    "        # OCR if file provided\n",
    "        if file is not None:\n",
    "            try:\n",
    "                extractor = globals().get(\"extract_text_from_file\")\n",
    "                if extractor:\n",
    "                    extracted = extractor(\n",
    "                        gemini,\n",
    "                        file.name,\n",
    "                        lang=lang_state.value if hasattr(lang_state, \"value\") else lang_state,\n",
    "                    )\n",
    "                    extracted = extracted.strip() if extracted else \"\"\n",
    "                    if extracted:\n",
    "                        text_content += f\"\\n\\n[FILE CONTENT START]\\n{extracted}\\n[FILE CONTENT END]\"\n",
    "                else:\n",
    "                    text_content += \"\\n[OCR Function Not Found]\"\n",
    "            except Exception as e:\n",
    "                text_content += f\"\\n[OCR failed: {e}]\"\n",
    "\n",
    "        user_input = collect_user_input(\n",
    "            text_content,\n",
    "            hb_v, wbc_v, plt_v,\n",
    "            gluc_v, a1c_v, chol_v, tri_v,\n",
    "            d_v, b12_v, tsh_v,\n",
    "            cust_n, cust_v, cust_u\n",
    "        )\n",
    "\n",
    "        if not text_content.strip() and all(v is None or v == \"\" for v in [\n",
    "            hb_v, wbc_v, plt_v, gluc_v, a1c_v, chol_v, tri_v, d_v, b12_v, tsh_v, cust_v\n",
    "        ]):\n",
    "            return \"\", \"‚ö†Ô∏è No input provided.\"\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a preventive health reasoning assistant.\\n\"\n",
    "            \"Interpret the following longitudinal entry.\\n\"\n",
    "            \"Highlight abnormal values and explain potential impact on desk-work energy, focus, fatigue, sleep.\\n\"\n",
    "            \"Provide non-diagnostic actionable guidance and when to seek medical review.\\n\\n\"\n",
    "            f\"CURRENT ENTRY:\\n{json.dumps(user_input, indent=2, ensure_ascii=False)}\\n\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            analysis_resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            analysis_text = analysis_resp.text.strip() if hasattr(analysis_resp, \"text\") and analysis_resp.text else \"\"\n",
    "        except Exception as e:\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not analysis_text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return analysis_text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[longitudinal] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_ai_file, existing)\n",
    "\n",
    "            # optional summary update\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[longitudinal] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Longitudinal AI output saved -> `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[longitudinal] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Interpretation\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    save_inputs_list = [\n",
    "        ui_inputs[\"log_input\"],\n",
    "        ui_inputs[\"hb\"], ui_inputs[\"wbc\"], ui_inputs[\"platelets\"],\n",
    "        ui_inputs[\"glucose\"], ui_inputs[\"hba1c\"], ui_inputs[\"cholesterol\"], ui_inputs[\"triglycerides\"],\n",
    "        ui_inputs[\"vit_d\"], ui_inputs[\"vit_b12\"], ui_inputs[\"tsh\"],\n",
    "        ui_inputs[\"custom_name\"], ui_inputs[\"custom_val\"], ui_inputs[\"custom_unit\"],\n",
    "    ]\n",
    "\n",
    "    gen_inputs_list = [\n",
    "        ui_inputs[\"log_input\"], ui_inputs[\"file_input\"],\n",
    "        ui_inputs[\"hb\"], ui_inputs[\"wbc\"], ui_inputs[\"platelets\"],\n",
    "        ui_inputs[\"glucose\"], ui_inputs[\"hba1c\"], ui_inputs[\"cholesterol\"], ui_inputs[\"triglycerides\"],\n",
    "        ui_inputs[\"vit_d\"], ui_inputs[\"vit_b12\"], ui_inputs[\"tsh\"],\n",
    "        ui_inputs[\"custom_name\"], ui_inputs[\"custom_val\"], ui_inputs[\"custom_unit\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=save_inputs_list, outputs=[status_box])\n",
    "    gen_btn.click(fn=generate_ai, inputs=gen_inputs_list, outputs=[output, status_box])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status_box])\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (Longitudinal) ‚Äî FIXED\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _longitudinal_demo_generate():\n",
    "            print(\"[longitudinal-demo] üöÄ Demo generate using saved longitudinal data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved longitudinal demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved longitudinal record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace health trend assistant.\\n\"\n",
    "                \"Analyze the following longitudinal lab/health tracking data.\\n\"\n",
    "                \"Provide trend-based, non-diagnostic insights.\\n\"\n",
    "                \"Highlight possible improvement areas and when medical review may be needed.\\n\"\n",
    "                \"Mention missing values gently.\\n\\n\"\n",
    "                f\"LONGITUDINAL DATA:\\n{last}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Longitudinal demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"Longitudinal Module\",\n",
    "            generate_fn=_longitudinal_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[longitudinal] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5b6a4",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Longitudinal Tab Builder\n",
    "\n",
    "This is the final wrapper function used by the main Gradio app.\n",
    "\n",
    "It:\n",
    "- Loads the latest saved longitudinal history\n",
    "- Builds the input UI (notes, upload, structured lab fields)\n",
    "- Builds the output UI (analysis + status)\n",
    "- Adds OCR extraction button (auto-fill)\n",
    "- Connects saving and Gemini reasoning logic\n",
    "\n",
    "This module is the core \"Health Wallet\" component of the platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adeb32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Longitudinal Module ‚Äî Final Tab Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_longitudinal_tab(store, gemini, lang_state: gr.State, locales_dir: Optional[Path] = None):\n",
    "    print(\"[longitudinal] ‚úÖ build_longitudinal_tab executed\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_longitudinal_history(store)\n",
    "\n",
    "\n",
    "    gr.Markdown(_safe_t(lang, \"longitudinal.title\", locales_dir, default=\"Longitudinal Progress Tracker & Health Wallet\"))\n",
    "\n",
    "    ui_inputs = build_longitudinal_inputs(saved_user_input, lang, locales_dir)\n",
    "\n",
    "    output, status_box = build_longitudinal_outputs(saved_ai_text, lang, locales_dir)\n",
    "\n",
    "    # OCR + Extraction Button\n",
    "    build_longitudinal_extractor(store, gemini, lang_state, ui_inputs, status_box)\n",
    "\n",
    "    # Saving + AI reasoning logic\n",
    "    connect_longitudinal_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status_box=status_box,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a121781",
   "metadata": {},
   "source": [
    "MSK Tab\n",
    "The Musculoskeletal (MSK) tab focuses on physical health related to muscles and posture. The user can input information about physical activity, aches/pains, or posture habits. The AI then provides suggestions such as exercises, stretches, or ergonomic advice to improve musculoskeletal health. A summary of the user's MSK status or advice is stored for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "142acf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# ü¶¥ Musculoskeletal (MSK) Health Module  \n",
       "*Movement, Load & Pain Awareness*\n",
       "\n",
       "Musculoskeletal discomfort is one of the most common consequences of prolonged\n",
       "desk-based work. Limited movement, static postures, repetitive tasks, and poor\n",
       "load distribution can gradually affect the neck, shoulders, back, hips, and\n",
       "upper limbs‚Äîoften starting as mild discomfort before progressing further.\n",
       "\n",
       "This module is designed to support **musculoskeletal health awareness**, not\n",
       "diagnosis. It focuses on identifying movement patterns, pain signals, and daily\n",
       "habits that may influence physical comfort and long-term joint and muscle health.\n",
       "\n",
       "### What this module captures\n",
       "- Presence and location of musculoskeletal pain\n",
       "- Pain intensity and frequency\n",
       "- Stiffness or reduced mobility\n",
       "- Duration of sitting and physical inactivity\n",
       "- Break frequency and movement habits\n",
       "- Physical strain related to work tasks\n",
       "- Use of stretching or physical activity for relief\n",
       "\n",
       "### Why this matters\n",
       "Musculoskeletal strain typically develops gradually rather than through sudden\n",
       "injury. Ignoring early warning signs such as stiffness or recurring pain can allow\n",
       "problems to accumulate over time.\n",
       "\n",
       "By increasing awareness of pain patterns and movement behavior, this module helps\n",
       "highlight opportunities for simple preventive actions that may reduce discomfort\n",
       "and support long-term physical function.\n",
       "\n",
       "### How AI is used in this section\n",
       "The AI provides **non-diagnostic, preventive guidance** focused on:\n",
       "- Gentle movement and stretching suggestions\n",
       "- Reducing prolonged static load during work\n",
       "- Encouraging regular movement breaks\n",
       "- Supporting sustainable physical habits at work\n",
       "\n",
       "The aim is prevention and early awareness‚Äînot medical assessment or treatment.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(MSK_INFO_MD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17001f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MSK Module ‚Äî Config + History Load (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def load_msk_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the MSK module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"msk\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff8f72",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Symptoms + Triggers)\n",
    "\n",
    "This section builds the MSK symptom input UI.\n",
    "\n",
    "It captures:\n",
    "- Pain severity (0‚Äì10)\n",
    "- Timing of pain onset\n",
    "- Pain location(s) and type of sensation\n",
    "- Mobility limitations (neck ROM, sitting duration)\n",
    "- Triggers and relief strategies\n",
    "- Whether symptoms affect work and sleep\n",
    "\n",
    "These inputs are converted into a structured JSON payload used by the AI reasoning engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98ba23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MSK Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_msk_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(\"### Current Symptoms\")\n",
    "\n",
    "    with gr.Row():\n",
    "        pain_level = gr.Slider(\n",
    "            minimum=0, maximum=10, step=1,\n",
    "            value=_to_int(saved_user_input.get(\"pain_level\", 0), 0),\n",
    "            label=_safe_t(lang, \"msk.pain\", locales_dir, default=\"Pain Intensity (0-10)\")\n",
    "        )\n",
    "\n",
    "        onset_choices = [\"Upon Waking\", \"Mid-Day\", \"End of Workday\", \"After Specific Tasks\", \"Constant\"]\n",
    "        saved_onset = _to_str(saved_user_input.get(\"onset_timing\", \"End of Workday\"), \"End of Workday\")\n",
    "        if saved_onset not in onset_choices:\n",
    "            saved_onset = \"End of Workday\"\n",
    "\n",
    "        onset_timing = gr.Dropdown(\n",
    "            choices=onset_choices,\n",
    "            value=saved_onset,\n",
    "            label=\"When does it start?\"\n",
    "        )\n",
    "\n",
    "    focus_choices = [\"Neck\", \"Shoulders/Upper Back\", \"Lower Back\", \"Wrists/Hands\", \"Hips/Glutes\", \"Knees\", \"None\"]\n",
    "    saved_focus = _to_list(saved_user_input.get(\"focus_area\", []))\n",
    "    saved_focus = [x for x in saved_focus if x in focus_choices]\n",
    "\n",
    "    if not saved_focus:\n",
    "        saved_focus = [\"None\"]\n",
    "\n",
    "    nature_choices = [\"Stiffness/Tightness\", \"Dull Ache\", \"Sharp/Stabbing\", \"Burning\", \"Numbness/Tingling\"]\n",
    "    saved_nature = _to_str(saved_user_input.get(\"pain_nature\", \"Stiffness/Tightness\"), \"Stiffness/Tightness\")\n",
    "    if saved_nature not in nature_choices:\n",
    "        saved_nature = \"Stiffness/Tightness\"\n",
    "\n",
    "    with gr.Row():\n",
    "        focus_area = gr.Dropdown(\n",
    "            choices=focus_choices,\n",
    "            value=saved_focus,\n",
    "            multiselect=True,\n",
    "            label=_safe_t(lang, \"msk.area\", locales_dir, default=\"Location(s) of Discomfort\")\n",
    "        )\n",
    "\n",
    "        pain_nature = gr.Dropdown(\n",
    "            choices=nature_choices,\n",
    "            value=saved_nature,\n",
    "            label=\"Nature of Sensation\"\n",
    "        )\n",
    "\n",
    "    with gr.Accordion(\"Mobility & Stiffness Checks\", open=False):\n",
    "        neck_choices = [\"Full & Painless\", \"Limited (Stiff)\", \"Painful to Move\"]\n",
    "        saved_neck = _to_str(saved_user_input.get(\"neck_rom\", \"Full & Painless\"), \"Full & Painless\")\n",
    "        if saved_neck not in neck_choices:\n",
    "            saved_neck = \"Full & Painless\"\n",
    "\n",
    "        seat_choices = [\"< 30 mins\", \"1 hour\", \"2+ hours\"]\n",
    "        saved_seat = _to_str(saved_user_input.get(\"seated_duration\", \"1 hour\"), \"1 hour\")\n",
    "        if saved_seat not in seat_choices:\n",
    "            saved_seat = \"1 hour\"\n",
    "\n",
    "        with gr.Row():\n",
    "            neck_rom = gr.Radio(\n",
    "                choices=neck_choices,\n",
    "                value=saved_neck,\n",
    "                label=\"Neck Range of Motion\"\n",
    "            )\n",
    "\n",
    "            seated_duration = gr.Radio(\n",
    "                choices=seat_choices,\n",
    "                value=saved_seat,\n",
    "                label=\"Typ. Time Seated w/o Move\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            morning_stiffness = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"morning_stiffness\", False)),\n",
    "                label=\"Wake up feeling stiff?\"\n",
    "            )\n",
    "\n",
    "            posture = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"good_posture\", False)),\n",
    "                label=_safe_t(lang, \"msk.posture\", locales_dir, default=\"Maintains good posture\")\n",
    "            )\n",
    "\n",
    "    with gr.Accordion(\"Impact & Triggers\", open=False):\n",
    "        triggers = gr.CheckboxGroup(\n",
    "            choices=[\"Stress/Tension\", \"Heavy Lifting\", \"Long Typing Sessions\", \"Cold Temperature\", \"Poor Sleep\"],\n",
    "            value=_to_list(saved_user_input.get(\"triggers\", [])),\n",
    "            label=\"Suspected Triggers\"\n",
    "        )\n",
    "\n",
    "        relief_methods = gr.CheckboxGroup(\n",
    "            choices=[\"Stretching\", \"Walking\", \"Heat/Cold Pack\", \"Painkillers\", \"Rest\"],\n",
    "            value=_to_list(saved_user_input.get(\"relief_methods\", [])),\n",
    "            label=\"What helps?\"\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            impact_work = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"impact_work\", False)),\n",
    "                label=\"Interferes with work?\"\n",
    "            )\n",
    "\n",
    "            impact_sleep = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"impact_sleep\", False)),\n",
    "                label=\"Interferes with sleep?\"\n",
    "            )\n",
    "\n",
    "    notes_input = gr.Textbox(\n",
    "        value=_to_str(saved_user_input.get(\"notes\", \"\"), \"\"),\n",
    "        label=_safe_t(lang, \"msk.notes\", locales_dir, default=\"Additional Notes\"),\n",
    "        lines=2\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"pain_level\": pain_level,\n",
    "        \"onset_timing\": onset_timing,\n",
    "        \"focus_area\": focus_area,\n",
    "        \"pain_nature\": pain_nature,\n",
    "\n",
    "        \"neck_rom\": neck_rom,\n",
    "        \"seated_duration\": seated_duration,\n",
    "        \"morning_stiffness\": morning_stiffness,\n",
    "        \"posture\": posture,\n",
    "\n",
    "        \"triggers\": triggers,\n",
    "        \"relief_methods\": relief_methods,\n",
    "        \"impact_work\": impact_work,\n",
    "        \"impact_sleep\": impact_sleep,\n",
    "\n",
    "        \"notes_input\": notes_input,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884d02a",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "This section defines:\n",
    "- A status message box for feedback (save success/errors)\n",
    "- A read-only AI output field containing MSK analysis and ergonomic recommendations\n",
    "\n",
    "The latest saved AI output is automatically loaded to preserve continuity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9beaeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MSK Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_msk_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"msk.output\", locales_dir, default=\"MSK Analysis & Recommendations\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=10\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d8014a",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Reasoning + Saving\n",
    "\n",
    "This section connects the MSK module to the reasoning engine.\n",
    "\n",
    "Workflow:\n",
    "1. Convert the UI inputs into a structured JSON object\n",
    "2. Save the user input entry as a timestamped record\n",
    "3. Generate AI recommendations using Gemini\n",
    "4. Save the AI interpretation as a timestamped record\n",
    "\n",
    "The model focuses on prevention, ergonomics, mobility, and red-flag symptom awareness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eccbf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MSK Module ‚Äî AI + Saving + Wiring (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def connect_msk_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # -------------------------\n",
    "    # LOCAL DOMAIN CONSTANTS\n",
    "    # -------------------------\n",
    "    local_domain = \"msk\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect user input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        pain_val, onset_val, focus_val, nature_val,\n",
    "        neck_val, seat_val, morn_val, post_val,\n",
    "        trig_val, relief_val, work_val, sleep_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        return {\n",
    "            \"pain_level\": _to_int(pain_val, 0),\n",
    "            \"onset_timing\": _to_str(onset_val, \"End of Workday\"),\n",
    "            \"focus_area\": _to_list(focus_val),\n",
    "            \"pain_nature\": _to_str(nature_val, \"Stiffness/Tightness\"),\n",
    "            \"neck_rom\": _to_str(neck_val, \"Full & Painless\"),\n",
    "            \"seated_duration\": _to_str(seat_val, \"1 hour\"),\n",
    "            \"morning_stiffness\": _to_bool(morn_val),\n",
    "            \"good_posture\": _to_bool(post_val),\n",
    "            \"triggers\": _to_list(trig_val),\n",
    "            \"relief_methods\": _to_list(relief_val),\n",
    "            \"impact_work\": _to_bool(work_val),\n",
    "            \"impact_sleep\": _to_bool(sleep_val),\n",
    "            \"notes\": _to_str(notes_val, \"\"),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        pain_val, onset_val, focus_val, nature_val,\n",
    "        neck_val, seat_val, morn_val, post_val,\n",
    "        trig_val, relief_val, work_val, sleep_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        print(\"[msk] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                pain_val, onset_val, focus_val, nature_val,\n",
    "                neck_val, seat_val, morn_val, post_val,\n",
    "                trig_val, relief_val, work_val, sleep_val,\n",
    "                notes_val\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ MSK input saved. File: `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[msk] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        pain_val, onset_val, focus_val, nature_val,\n",
    "        neck_val, seat_val, morn_val, post_val,\n",
    "        trig_val, relief_val, work_val, sleep_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        print(\"[msk] üîò Generate AI clicked\")\n",
    "\n",
    "        user_input = collect_user_input(\n",
    "            pain_val, onset_val, focus_val, nature_val,\n",
    "            neck_val, seat_val, morn_val, post_val,\n",
    "            trig_val, relief_val, work_val, sleep_val,\n",
    "            notes_val\n",
    "        )\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a preventive workplace musculoskeletal assistant.\\n\"\n",
    "            \"Analyze the following MSK data and provide actionable, non-diagnostic recommendations.\\n\"\n",
    "            \"1. Analyze relationship between pain nature, location, and triggers.\\n\"\n",
    "            \"2. If numbness/tingling exists, assess nerve compression risks.\\n\"\n",
    "            \"3. Suggest specific stretches and workstation adjustments.\\n\"\n",
    "            \"4. Provide red-flag warning signs requiring medical review.\\n\\n\"\n",
    "            f\"MSK DATA:\\n{json.dumps(user_input, indent=2, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[msk] ‚ùå AI generation failed: {e}\")\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[msk] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_ai_file, existing)\n",
    "\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[msk] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ MSK AI output saved. File: `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[msk] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI MSK Analysis\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"pain_level\"], ui_inputs[\"onset_timing\"], ui_inputs[\"focus_area\"], ui_inputs[\"pain_nature\"],\n",
    "        ui_inputs[\"neck_rom\"], ui_inputs[\"seated_duration\"], ui_inputs[\"morning_stiffness\"], ui_inputs[\"posture\"],\n",
    "        ui_inputs[\"triggers\"], ui_inputs[\"relief_methods\"], ui_inputs[\"impact_work\"], ui_inputs[\"impact_sleep\"],\n",
    "        ui_inputs[\"notes_input\"]\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (MSK) ‚Äî FIXED\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _msk_demo_generate():\n",
    "            print(\"[msk-demo] üöÄ Demo generate using saved MSK data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved MSK demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved MSK record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace musculoskeletal assistant.\\n\"\n",
    "                \"Analyze the following MSK data and provide actionable, non-diagnostic recommendations.\\n\"\n",
    "                \"1. Analyze relationship between pain nature, location, and triggers.\\n\"\n",
    "                \"2. Suggest specific stretches and workstation adjustments.\\n\"\n",
    "                \"3. Provide red-flag warning signs requiring medical review.\\n\\n\"\n",
    "                f\"MSK DATA:\\n{last}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ MSK demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"MSK Module\",\n",
    "            generate_fn=_msk_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[msk] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb1a7aa",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî MSK Tab Builder\n",
    "\n",
    "This is the wrapper function used by the main Gradio app.\n",
    "\n",
    "It:\n",
    "- Loads the latest MSK history\n",
    "- Builds the symptom input UI\n",
    "- Builds the output components\n",
    "- Connects AI generation + saving logic\n",
    "\n",
    "The MSK module is designed for prevention of desk-related pain and early detection of warning patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c85c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# MSK Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_msk_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    local_domain = \"msk\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[msk] ‚úÖ build_msk_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_msk_history(store)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"msk.title\",\n",
    "            locales_dir,\n",
    "            default=\"ü¶¥ Musculoskeletal Health & Pain Tracker\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (MSK Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò MSK Tab Guide\",\n",
    "        content_md=MSK_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è MSK Info\",\n",
    "        open_label=\"‚ùå Hide MSK Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_msk_inputs(\n",
    "        saved_user_input,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output, status = build_msk_outputs(\n",
    "        saved_ai_text,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_msk_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ded201",
   "metadata": {},
   "source": [
    "Eye Tab\n",
    "The Eye health tab addresses eye strain and vision care. It may take inputs like screen time, break frequency, or eye comfort level. Using those inputs, it outputs recommendations (for example, following the 20-20-20 rule, doing eye exercises, etc.) to reduce eye strain. The summary or key points are saved to context for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7b54bf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# üëÅÔ∏è Eye Health Module  \n",
       "*Visual Load & Screen Strain Awareness*\n",
       "\n",
       "Extended screen exposure is a defining feature of modern desk work. Prolonged\n",
       "visual focus, reduced blinking, glare, and improper screen positioning can place\n",
       "significant strain on the eyes‚Äîoften leading to symptoms such as dryness, blurred\n",
       "vision, headaches, or eye fatigue.\n",
       "\n",
       "This module is designed to support **eye health awareness**, not diagnosis. It\n",
       "helps identify daily screen-related behaviors and visual symptoms that may affect\n",
       "comfort, focus, and visual endurance during work.\n",
       "\n",
       "### What this module captures\n",
       "- Daily screen time duration\n",
       "- Frequency of visual breaks\n",
       "- Eye strain or discomfort symptoms\n",
       "- Headaches related to screen use\n",
       "- Screen distance and height\n",
       "- Lighting conditions and glare\n",
       "- Use of corrective lenses or filters\n",
       "\n",
       "### Why this matters\n",
       "Eye strain often develops silently and may be mistaken for general fatigue or\n",
       "headache. Without regular visual breaks and proper screen setup, symptoms can\n",
       "accumulate and affect both comfort and work performance.\n",
       "\n",
       "Early awareness allows for small, practical adjustments that can significantly\n",
       "reduce visual load and support long-term eye comfort.\n",
       "\n",
       "### How AI is used in this section\n",
       "The AI provides **non-diagnostic, preventive guidance** focused on:\n",
       "- Visual break strategies suitable for workdays\n",
       "- Screen positioning and lighting adjustments\n",
       "- Habits that support eye comfort during screen use\n",
       "- Reducing cumulative visual strain over time\n",
       "\n",
       "The goal is to promote visual comfort and sustainability‚Äînot to replace eye care\n",
       "assessment.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(EYE_HEALTH_INFO_MD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "260546d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Eye Module ‚Äî Config + History Load\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_eye_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Eye module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"eye\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f12cc",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Symptoms + Environment + Habits)\n",
    "\n",
    "This section builds the Eye Health input UI.\n",
    "\n",
    "The user records:\n",
    "- Strain severity and uninterrupted screen time\n",
    "- Common Computer Vision Syndrome symptoms\n",
    "- Lighting and glare environment\n",
    "- Vision correction tools used (glasses/contacts)\n",
    "- Eye care habits (drops, 20-20-20 rule)\n",
    "\n",
    "These values are later structured into JSON and sent to Gemini for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bad1cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Eye Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_eye_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(\"### Current Eye Status\")\n",
    "\n",
    "    with gr.Row():\n",
    "        strain_level = gr.Slider(\n",
    "            minimum=0, maximum=10, step=1,\n",
    "            value=_to_int(saved_user_input.get(\"strain_level\", 0), 0),\n",
    "            label=_safe_t(lang, \"eye.strain\", locales_dir, default=\"Eye Strain Level (0-10)\")\n",
    "        )\n",
    "\n",
    "        session_choices = [\"< 1 hour\", \"1-2 hours\", \"2-4 hours\", \"4+ hours\"]\n",
    "        saved_session = _to_str(saved_user_input.get(\"session_length\", \"1-2 hours\"), \"1-2 hours\")\n",
    "        if saved_session not in session_choices:\n",
    "            saved_session = \"1-2 hours\"\n",
    "\n",
    "        session_length = gr.Dropdown(\n",
    "            choices=session_choices,\n",
    "            value=saved_session,\n",
    "            label=\"Longest Uninterrupted Screen Time\"\n",
    "        )\n",
    "\n",
    "    symptoms = gr.CheckboxGroup(\n",
    "        choices=[\n",
    "            \"Dryness / Gritty feeling\",\n",
    "            \"Blurred Vision (end of day)\",\n",
    "            \"Light Sensitivity\",\n",
    "            \"Eye Twitching\",\n",
    "            \"Headache (behind eyes)\",\n",
    "            \"Watery Eyes\"\n",
    "        ],\n",
    "        value=_to_list(saved_user_input.get(\"symptoms\", [])),\n",
    "        label=\"Specific Symptoms Today\"\n",
    "    )\n",
    "\n",
    "    with gr.Accordion(\"Visual Environment & Lighting\", open=False):\n",
    "\n",
    "        lighting_choices = [\"Natural Light\", \"Fluorescent (Office)\", \"Dim/Dark Room\", \"Mixed\"]\n",
    "        saved_lighting = _to_str(saved_user_input.get(\"lighting\", \"Natural Light\"), \"Natural Light\")\n",
    "        if saved_lighting not in lighting_choices:\n",
    "            saved_lighting = \"Natural Light\"\n",
    "\n",
    "        brightness_choices = [\"Brighter than room\", \"Balanced\", \"Dimmer than room\"]\n",
    "        saved_brightness = _to_str(saved_user_input.get(\"screen_brightness\", \"Balanced\"), \"Balanced\")\n",
    "        if saved_brightness not in brightness_choices:\n",
    "            saved_brightness = \"Balanced\"\n",
    "\n",
    "        with gr.Row():\n",
    "            lighting = gr.Dropdown(\n",
    "                choices=lighting_choices,\n",
    "                value=saved_lighting,\n",
    "                label=\"Ambient Lighting\"\n",
    "            )\n",
    "\n",
    "            screen_brightness = gr.Radio(\n",
    "                choices=brightness_choices,\n",
    "                value=saved_brightness,\n",
    "                label=\"Screen Brightness vs. Room\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            glare = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"glare\", False)),\n",
    "                label=\"Glare/Reflection on Screen?\"\n",
    "            )\n",
    "\n",
    "            distance_check = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"distance_check\", True)),\n",
    "                label=\"Screen is arm's length away?\"\n",
    "            )\n",
    "\n",
    "    with gr.Accordion(\"Correction & Habits\", open=False):\n",
    "\n",
    "        correction_choices = [\"None (Naked Eye)\", \"Glasses\", \"Contact Lenses\", \"Blue Light Blockers\"]\n",
    "        saved_corr = _to_str(saved_user_input.get(\"correction\", \"None (Naked Eye)\"), \"None (Naked Eye)\")\n",
    "        if saved_corr not in correction_choices:\n",
    "            saved_corr = \"None (Naked Eye)\"\n",
    "\n",
    "        rule_choices = [\"Strictly followed\", \"Occasionally\", \"Forgot completely\"]\n",
    "        saved_rule = _to_str(saved_user_input.get(\"rule_20_20_20\", \"Occasionally\"), \"Occasionally\")\n",
    "        if saved_rule not in rule_choices:\n",
    "            saved_rule = \"Occasionally\"\n",
    "\n",
    "        with gr.Row():\n",
    "            correction = gr.Dropdown(\n",
    "                choices=correction_choices,\n",
    "                value=saved_corr,\n",
    "                label=\"Vision Correction Worn\"\n",
    "            )\n",
    "\n",
    "            rule_20_20_20 = gr.Radio(\n",
    "                choices=rule_choices,\n",
    "                value=saved_rule,\n",
    "                label=\"Adherence to 20-20-20 Rule\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            drops = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"used_drops\", False)),\n",
    "                label=\"Used Artificial Tears?\"\n",
    "            )\n",
    "\n",
    "    notes_input = gr.Textbox(\n",
    "        value=_to_str(saved_user_input.get(\"notes\", \"\"), \"\"),\n",
    "        label=_safe_t(lang, \"eye.notes\", locales_dir, default=\"Additional Observations\"),\n",
    "        lines=2\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"strain_level\": strain_level,\n",
    "        \"session_length\": session_length,\n",
    "        \"symptoms\": symptoms,\n",
    "\n",
    "        \"lighting\": lighting,\n",
    "        \"screen_brightness\": screen_brightness,\n",
    "        \"glare\": glare,\n",
    "        \"distance_check\": distance_check,\n",
    "\n",
    "        \"correction\": correction,\n",
    "        \"rule_20_20_20\": rule_20_20_20,\n",
    "        \"drops\": drops,\n",
    "\n",
    "        \"notes_input\": notes_input,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ae23c",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "This section defines:\n",
    "- A status box to display save/generation messages\n",
    "- A read-only AI output field for eye-care recommendations\n",
    "\n",
    "The latest saved AI response is loaded automatically for continuity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29395785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Eye Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_eye_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"eye.output\", locales_dir, default=\"Eye Care Recommendations\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=10\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c091c7c",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Reasoning + Saving\n",
    "\n",
    "This section connects the Eye module to Gemini.\n",
    "\n",
    "Workflow:\n",
    "1. Collect user inputs into structured JSON\n",
    "2. Save user input history (timestamped records)\n",
    "3. Generate non-diagnostic eye-care recommendations\n",
    "4. Save AI output history\n",
    "\n",
    "The AI focuses on Computer Vision Syndrome prevention, dryness relief, and healthy screen habits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b2f1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Eye Module ‚Äî AI + Saving + Wiring (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def connect_eye_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # IMPORTANT: local names (prevents cross-tab overwrite bugs)\n",
    "    domain = \"eye\"\n",
    "    user_file = f\"{domain}_user_input.json\"\n",
    "    ai_file = f\"{domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        strain_val, session_val, symp_val,\n",
    "        light_val, bright_val, glare_val, dist_val,\n",
    "        corr_val, rule_val, drops_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        return {\n",
    "            \"strain_level\": _to_int(strain_val, 0),\n",
    "            \"session_length\": _to_str(session_val, \"1-2 hours\"),\n",
    "            \"symptoms\": _to_list(symp_val),\n",
    "            \"lighting\": _to_str(light_val, \"Natural Light\"),\n",
    "            \"screen_brightness\": _to_str(bright_val, \"Balanced\"),\n",
    "            \"glare\": _to_bool(glare_val),\n",
    "            \"distance_check\": _to_bool(dist_val),\n",
    "            \"correction\": _to_str(corr_val, \"None (Naked Eye)\"),\n",
    "            \"rule_20_20_20\": _to_str(rule_val, \"Occasionally\"),\n",
    "            \"used_drops\": _to_bool(drops_val),\n",
    "            \"notes\": _to_str(notes_val, \"\"),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        strain_val, session_val, symp_val,\n",
    "        light_val, bright_val, glare_val, dist_val,\n",
    "        corr_val, rule_val, drops_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        print(\"[eye] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                strain_val, session_val, symp_val,\n",
    "                light_val, bright_val, glare_val, dist_val,\n",
    "                corr_val, rule_val, drops_val,\n",
    "                notes_val\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Eye input saved. File: `{_debug_store_path(store, user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[eye] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        strain_val, session_val, symp_val,\n",
    "        light_val, bright_val, glare_val, dist_val,\n",
    "        corr_val, rule_val, drops_val,\n",
    "        notes_val\n",
    "    ):\n",
    "        print(\"[eye] üîò Generate AI clicked\")\n",
    "\n",
    "        data = collect_user_input(\n",
    "            strain_val, session_val, symp_val,\n",
    "            light_val, bright_val, glare_val, dist_val,\n",
    "            corr_val, rule_val, drops_val,\n",
    "            notes_val\n",
    "        )\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a preventive eye health assistant for desk workers.\\n\"\n",
    "            \"Provide non-diagnostic, practical guidance.\\n\"\n",
    "            \"1. Identify risk factors for Computer Vision Syndrome.\\n\"\n",
    "            \"2. If strain_level > 5, suggest immediate relief techniques.\\n\"\n",
    "            \"3. Give advice about dryness (especially with contact lenses).\\n\"\n",
    "            \"4. Provide a short prevention plan for tomorrow.\\n\\n\"\n",
    "            f\"EYE DATA:\\n{json.dumps(data, indent=2, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[eye] ‚ùå AI generation failed: {e}\")\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[eye] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, ai_file, existing)\n",
    "\n",
    "            # Update domain summary\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[eye] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Eye AI output saved. File: `{_debug_store_path(store, ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[eye] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Eye Analysis\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"strain_level\"], ui_inputs[\"session_length\"], ui_inputs[\"symptoms\"],\n",
    "        ui_inputs[\"lighting\"], ui_inputs[\"screen_brightness\"], ui_inputs[\"glare\"], ui_inputs[\"distance_check\"],\n",
    "        ui_inputs[\"correction\"], ui_inputs[\"rule_20_20_20\"], ui_inputs[\"drops\"],\n",
    "        ui_inputs[\"notes_input\"]\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # =========================================================\n",
    "    # Demo Hook Registration (Eye) ‚Äî MUST BE INSIDE FUNCTION\n",
    "    # =========================================================\n",
    "    try:\n",
    "        def _eye_demo_generate():\n",
    "            print(\"[eye-demo] üöÄ Demo generate using saved eye data\")\n",
    "\n",
    "            raw = store.load_json(user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved eye demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved eye record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace eye strain assistant.\\n\"\n",
    "                \"Analyze the following eye health and screen exposure data.\\n\"\n",
    "                \"Provide actionable, non-diagnostic advice to reduce eye strain.\\n\"\n",
    "                \"Include lighting, screen distance, breaks (20-20-20 rule), and hydration links.\\n\"\n",
    "                \"Mention red-flag symptoms requiring eye doctor review.\\n\\n\"\n",
    "                f\"EYE DATA:\\n{json.dumps(last, indent=2, ensure_ascii=False)}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Eye demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=domain,\n",
    "            label=\"Eye Module\",\n",
    "            generate_fn=_eye_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[eye] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9993d7",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Eye Tab Builder\n",
    "\n",
    "This wrapper function is the entry point for the Eye Health module.\n",
    "\n",
    "It:\n",
    "- Loads the latest stored history\n",
    "- Builds the Eye input UI (symptoms + habits + environment)\n",
    "- Builds the output UI (recommendations + status)\n",
    "- Connects Gemini reasoning and saving logic\n",
    "\n",
    "This makes the Eye module fully modular and easy to maintain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ccb29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Eye Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_eye_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    local_domain = \"eye\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[eye] ‚úÖ build_eye_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_domain_history(store, local_domain)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"eye.title\",\n",
    "            locales_dir,\n",
    "            default=\"üëÅÔ∏è Eye Health & Computer Vision Tracker\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (Eye Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò Eye Health Tab Guide\",\n",
    "        content_md=EYE_HEALTH_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è Eye Health Info\",\n",
    "        open_label=\"‚ùå Hide Eye Health Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_eye_inputs(\n",
    "        saved_user_input,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output, status = build_eye_outputs(\n",
    "        saved_ai_text,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_eye_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28e044c",
   "metadata": {},
   "source": [
    "Mental Tab\n",
    "The Mental health tab allows the user to record their mood or feelings (possibly via a slider or text input for journaling). The AI can analyze the input to provide supportive suggestions or coping strategies. If any concerning keywords are detected (e.g., indications of self-harm), the safety check will flag an urgent message to encourage seeking help. The mental health summary is updated in the context memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28784471",
   "metadata": {},
   "source": [
    "# üß† Mental Wellbeing Module  \n",
    "*Cognitive Load & Burnout Awareness*\n",
    "\n",
    "Desk-based work places sustained demands on attention, emotional regulation, and\n",
    "mental energy. Over time, high cognitive load, constant interruptions, and limited\n",
    "recovery can contribute to stress accumulation, reduced focus, and early burnout\n",
    "signals‚Äîoften before individuals consciously recognize them.\n",
    "\n",
    "This module is designed to support **mental wellbeing awareness**, not diagnosis.\n",
    "It helps identify daily patterns related to stress, cognitive fatigue, and emotional\n",
    "load in the context of work routines.\n",
    "\n",
    "### What this module captures\n",
    "- Perceived stress level\n",
    "- Mood state\n",
    "- Mental energy and brain fog\n",
    "- Focus quality and workload perception\n",
    "- Distractions (internal vs external)\n",
    "- Burnout warning signs (detachment, overwhelm)\n",
    "- Sleep quality and coping mechanisms\n",
    "\n",
    "### Why this matters\n",
    "Mental fatigue and burnout rarely appear suddenly. They typically develop through\n",
    "small, repeated stressors combined with insufficient recovery. Desk work can\n",
    "intensify this process due to prolonged screen exposure, cognitive overload, and\n",
    "blurred boundaries between work and rest.\n",
    "\n",
    "By reflecting on daily mental signals, this module helps highlight trends that may\n",
    "affect productivity, wellbeing, and long-term resilience‚Äîbefore more severe\n",
    "consequences occur.\n",
    "\n",
    "### How AI is used in this section\n",
    "The AI provides **supportive, non-diagnostic guidance** focused on:\n",
    "- Simple grounding and reset techniques\n",
    "- Burnout prevention through small, realistic actions\n",
    "- Improving coping strategies during demanding workdays\n",
    "- Practical sleep hygiene recommendations\n",
    "\n",
    "The aim is to promote awareness, balance, and early prevention‚Äînot to replace\n",
    "professional care.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "523f9f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Mental Module ‚Äî Config + History Loader\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_mental_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Mental module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"mental\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d9e03",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Mental Vitals + Burnout Risk)\n",
    "\n",
    "This section builds the Mental Wellbeing UI.\n",
    "\n",
    "The input fields are structured into 3 major blocks:\n",
    "1. Emotional Vitals (stress, mood, energy)\n",
    "2. Cognitive Load (focus quality, workload, distractions)\n",
    "3. Burnout & Recovery (detachment, overwhelm, sleep quality, coping methods)\n",
    "\n",
    "A free-text journal is included for personal reflections.\n",
    "This free-text is also checked by safety filters when available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b91e5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Mental Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_mental_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(\"### Emotional Vitals\")\n",
    "\n",
    "    with gr.Row():\n",
    "        stress = gr.Slider(\n",
    "            minimum=1, maximum=10, step=1,\n",
    "            value=_to_int(saved_user_input.get(\"stress\", 5), 5),\n",
    "            label=_safe_t(lang, \"mental.stress\", locales_dir, default=\"Stress Level (1=Zen, 10=Panic)\")\n",
    "        )\n",
    "\n",
    "        mood_choices = [\"Calm\", \"Anxious\", \"Irritable\", \"Motivated\", \"Numb/Detached\", \"Sad\"]\n",
    "        saved_mood = _to_str(saved_user_input.get(\"mood\", \"Calm\"), \"Calm\")\n",
    "        if saved_mood not in mood_choices:\n",
    "            saved_mood = \"Calm\"\n",
    "\n",
    "        mood = gr.Dropdown(\n",
    "            choices=mood_choices,\n",
    "            value=saved_mood,\n",
    "            label=\"Current Mood\"\n",
    "        )\n",
    "\n",
    "        energy_choices = [\"Sharp\", \"Average\", \"Brain Fog/Sluggish\"]\n",
    "        saved_energy = _to_str(saved_user_input.get(\"energy\", \"Average\"), \"Average\")\n",
    "        if saved_energy not in energy_choices:\n",
    "            saved_energy = \"Average\"\n",
    "\n",
    "        energy = gr.Radio(\n",
    "            choices=energy_choices,\n",
    "            value=saved_energy,\n",
    "            label=\"Mental Energy\"\n",
    "        )\n",
    "\n",
    "    with gr.Accordion(\"Cognitive Function & Workload\", open=False):\n",
    "\n",
    "        focus_choices = [\"Deep Work / Flow\", \"Fragmented / Multitasking\", \"Unable to Concentrate\"]\n",
    "        saved_focus = _to_str(\n",
    "            saved_user_input.get(\"focus_quality\", \"Fragmented / Multitasking\"),\n",
    "            \"Fragmented / Multitasking\"\n",
    "        )\n",
    "        if saved_focus not in focus_choices:\n",
    "            saved_focus = \"Fragmented / Multitasking\"\n",
    "\n",
    "        workload_choices = [\"Light\", \"Manageable\", \"Heavy\", \"Impossible\"]\n",
    "        saved_workload = _to_str(saved_user_input.get(\"workload\", \"Manageable\"), \"Manageable\")\n",
    "        if saved_workload not in workload_choices:\n",
    "            saved_workload = \"Manageable\"\n",
    "\n",
    "        with gr.Row():\n",
    "            focus_quality = gr.Dropdown(\n",
    "                choices=focus_choices,\n",
    "                value=saved_focus,\n",
    "                label=\"Quality of Focus\"\n",
    "            )\n",
    "            workload = gr.Radio(\n",
    "                choices=workload_choices,\n",
    "                value=saved_workload,\n",
    "                label=\"Perceived Workload\"\n",
    "            )\n",
    "\n",
    "        distractions = gr.CheckboxGroup(\n",
    "            choices=[\"External (Noise/People)\", \"Digital (Notifications)\", \"Internal (Worry/Thoughts)\"],\n",
    "            value=_to_list(saved_user_input.get(\"distractions\", [])),\n",
    "            label=\"Main Distractions\"\n",
    "        )\n",
    "\n",
    "    with gr.Accordion(\"Burnout Risk & Recovery\", open=False):\n",
    "\n",
    "        social_choices = [\"Isolated\", \"Text/Chat only\", \"Meaningful Interaction\"]\n",
    "        saved_social = _to_str(saved_user_input.get(\"social\", \"Text/Chat only\"), \"Text/Chat only\")\n",
    "        if saved_social not in social_choices:\n",
    "            saved_social = \"Text/Chat only\"\n",
    "\n",
    "        sleepq_choices = [\"Restorative\", \"Trouble Falling Asleep\", \"Woke up Tired\", \"Insomnia\"]\n",
    "        saved_sleepq = _to_str(saved_user_input.get(\"sleep_quality\", \"Restorative\"), \"Restorative\")\n",
    "        if saved_sleepq not in sleepq_choices:\n",
    "            saved_sleepq = \"Restorative\"\n",
    "\n",
    "        with gr.Row():\n",
    "            detachment = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"detachment\", False)),\n",
    "                label=\"Feeling cynical/detached?\"\n",
    "            )\n",
    "            overwhelm = gr.Checkbox(\n",
    "                value=_to_bool(saved_user_input.get(\"overwhelm\", False)),\n",
    "                label=\"Feeling unable to keep up?\"\n",
    "            )\n",
    "            social = gr.Dropdown(\n",
    "                choices=social_choices,\n",
    "                value=saved_social,\n",
    "                label=\"Social Connection\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            sleep_quality = gr.Dropdown(\n",
    "                choices=sleepq_choices,\n",
    "                value=saved_sleepq,\n",
    "                label=\"Sleep Quality (Last Night)\"\n",
    "            )\n",
    "\n",
    "            coping = gr.CheckboxGroup(\n",
    "                choices=[\"Breathing/Meditation\", \"Venting to Friend\", \"Caffeine/Sugar\", \"Procrastination\", \"Exercise\"],\n",
    "                value=_to_list(saved_user_input.get(\"coping\", [])),\n",
    "                label=\"Coping Mechanisms Used\"\n",
    "            )\n",
    "\n",
    "    notes = gr.Textbox(\n",
    "        value=_to_str(saved_user_input.get(\"notes\", \"\"), \"\"),\n",
    "        label=_safe_t(lang, \"mental.notes\", locales_dir, default=\"Journal / Thoughts\"),\n",
    "        lines=3,\n",
    "        placeholder=\"What's on your mind?\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"stress\": stress,\n",
    "        \"mood\": mood,\n",
    "        \"energy\": energy,\n",
    "        \"focus_quality\": focus_quality,\n",
    "        \"workload\": workload,\n",
    "        \"distractions\": distractions,\n",
    "        \"detachment\": detachment,\n",
    "        \"overwhelm\": overwhelm,\n",
    "        \"social\": social,\n",
    "        \"sleep_quality\": sleep_quality,\n",
    "        \"coping\": coping,\n",
    "        \"notes\": notes,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba24c92",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "This section defines:\n",
    "- Status display messages (save success, errors, warnings)\n",
    "- A read-only AI output field that shows the generated guidance\n",
    "\n",
    "The most recent saved AI output is loaded automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1648195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Mental Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_mental_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"mental.output\", locales_dir, default=\"Mental Health Guidance\"),\n",
    "        interactive=False,\n",
    "        lines=8,\n",
    "        value=saved_ai_text\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c7793",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Guidance + Safety Checks + Saving\n",
    "\n",
    "This module is slightly more advanced than other tabs because it supports safety filtering.\n",
    "\n",
    "Workflow:\n",
    "1. Collect structured input into JSON\n",
    "2. Save user input history (timestamped)\n",
    "3. Run safety checks on the journal text (if available)\n",
    "4. Generate supportive non-diagnostic guidance using Gemini\n",
    "5. Save AI output history\n",
    "\n",
    "The AI is instructed to focus on:\n",
    "- burnout prevention\n",
    "- coping mechanism improvement\n",
    "- grounding techniques\n",
    "- sleep hygiene advice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "756291fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Mental Module ‚Äî AI + Saving + Wiring\n",
    "# ==========================================\n",
    "\n",
    "def connect_mental_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # IMPORTANT: local names (prevents cross-tab overwrite bugs)\n",
    "    local_domain = \"mental\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect user input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        stress_val, mood_val, energy_val,\n",
    "        focus_val, work_val, dist_val,\n",
    "        detach_val, over_val, social_val,\n",
    "        sleep_val, coping_val, notes_val\n",
    "    ):\n",
    "        return {\n",
    "            \"stress\": _to_int(stress_val, 5),\n",
    "            \"mood\": _to_str(mood_val, \"Calm\"),\n",
    "            \"energy\": _to_str(energy_val, \"Average\"),\n",
    "            \"focus_quality\": _to_str(focus_val, \"Fragmented / Multitasking\"),\n",
    "            \"workload\": _to_str(work_val, \"Manageable\"),\n",
    "            \"distractions\": _to_list(dist_val),\n",
    "            \"detachment\": _to_bool(detach_val),\n",
    "            \"overwhelm\": _to_bool(over_val),\n",
    "            \"social\": _to_str(social_val, \"Text/Chat only\"),\n",
    "            \"sleep_quality\": _to_str(sleep_val, \"Restorative\"),\n",
    "            \"coping\": _to_list(coping_val),\n",
    "            \"notes\": _to_str(notes_val, \"\"),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        stress_val, mood_val, energy_val,\n",
    "        focus_val, work_val, dist_val,\n",
    "        detach_val, over_val, social_val,\n",
    "        sleep_val, coping_val, notes_val\n",
    "    ):\n",
    "        print(\"[mental] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                stress_val, mood_val, energy_val,\n",
    "                focus_val, work_val, dist_val,\n",
    "                detach_val, over_val, social_val,\n",
    "                sleep_val, coping_val, notes_val\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Mental input saved. File: `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[mental] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        stress_val, mood_val, energy_val,\n",
    "        focus_val, work_val, dist_val,\n",
    "        detach_val, over_val, social_val,\n",
    "        sleep_val, coping_val, notes_val\n",
    "    ):\n",
    "        print(\"[mental] üîò Generate AI clicked\")\n",
    "\n",
    "        entry = collect_user_input(\n",
    "            stress_val, mood_val, energy_val,\n",
    "            focus_val, work_val, dist_val,\n",
    "            detach_val, over_val, social_val,\n",
    "            sleep_val, coping_val, notes_val\n",
    "        )\n",
    "\n",
    "        # safety flags (optional)\n",
    "        flags = []\n",
    "        if \"apply_safety_checks\" in globals() and callable(globals().get(\"apply_safety_checks\")):\n",
    "            payload = {\"free_text\": str(notes_val or \"\")}\n",
    "            try:\n",
    "                result = globals()[\"apply_safety_checks\"](payload)\n",
    "                flags = result.get(\"safety_flags\", []) if isinstance(result, dict) else []\n",
    "            except Exception as e:\n",
    "                print(f\"[mental] ‚ö†Ô∏è Safety check error: {e}\")\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a supportive preventive mental wellbeing assistant.\\n\"\n",
    "            \"Provide non-diagnostic guidance.\\n\"\n",
    "            \"1. Analyze coping mechanisms (healthy vs avoidance).\\n\"\n",
    "            \"2. If detachment/overwhelm is present, provide grounding techniques.\\n\"\n",
    "            \"3. Link sleep quality to energy and give one specific sleep hygiene tip.\\n\"\n",
    "            \"4. Provide burnout prevention micro-actions for desk workers.\\n\\n\"\n",
    "            f\"MENTAL LOG:\\n{json.dumps(entry, indent=2, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt=prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[mental] ‚ùå AI generation failed: {e}\")\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        # prepend safety warnings if needed\n",
    "        if flags:\n",
    "            warnings = \"\\n\".join(\n",
    "                f\"‚ö†Ô∏è {flag.get('message','')}\"\n",
    "                for flag in flags\n",
    "                if isinstance(flag, dict)\n",
    "            ).strip()\n",
    "\n",
    "            if warnings:\n",
    "                text = f\"{warnings}\\n\\n{text}\"\n",
    "\n",
    "        return text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[mental] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_ai_file, existing)\n",
    "\n",
    "            # update domain summary\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[mental] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Mental AI output saved. File: `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[mental] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Guidance\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"stress\"], ui_inputs[\"mood\"], ui_inputs[\"energy\"],\n",
    "        ui_inputs[\"focus_quality\"], ui_inputs[\"workload\"], ui_inputs[\"distractions\"],\n",
    "        ui_inputs[\"detachment\"], ui_inputs[\"overwhelm\"], ui_inputs[\"social\"],\n",
    "        ui_inputs[\"sleep_quality\"], ui_inputs[\"coping\"], ui_inputs[\"notes\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (Mental)\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _mental_demo_generate():\n",
    "            print(\"[mental-demo] üöÄ Demo generate using saved mental data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved mental demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved mental record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace mental wellbeing assistant.\\n\"\n",
    "                \"Analyze the following stress/mood/workload data.\\n\"\n",
    "                \"Provide supportive, non-diagnostic recommendations.\\n\"\n",
    "                \"Focus on stress management, burnout prevention, work boundaries, and recovery habits.\\n\"\n",
    "                \"Include red-flag warning signs requiring professional help.\\n\\n\"\n",
    "                f\"MENTAL WELLBEING DATA:\\n{last}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Mental demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"Mental Wellbeing Module\",\n",
    "            generate_fn=_mental_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[mental] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63700c",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Mental Tab Builder\n",
    "\n",
    "This wrapper function is the entry point for the Mental Wellbeing module.\n",
    "\n",
    "It:\n",
    "- loads the latest stored mental wellbeing entry\n",
    "- builds the full input UI\n",
    "- builds output UI (AI guidance + status)\n",
    "- connects Gemini generation + saving logic\n",
    "\n",
    "This design makes the module easy to maintain and easy to read for hackathon judges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37ba0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Mental Wellbeing Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_mental_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    local_domain = \"mental\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[mental] ‚úÖ build_mental_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_domain_history(store, local_domain)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"mental.title\",\n",
    "            locales_dir,\n",
    "            default=\"üß† Mental Well-Being & Cognitive Load\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (Mental Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò Mental Wellbeing Tab Guide\",\n",
    "        content_md=MENTAL_WELLBEING_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è Mental Wellbeing Info\",\n",
    "        open_label=\"‚ùå Hide Mental Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_mental_inputs(\n",
    "        saved_user_input,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output, status = build_mental_outputs(\n",
    "        saved_ai_text,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_mental_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669481c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d572923",
   "metadata": {},
   "source": [
    "Hydration Tab\n",
    "The Hydration tab is for tracking water intake or hydration habits. The user might input how much water they've drunk or rate their hydration. The tab then provides feedback or tips (like drinking more water at certain times). The hydration status is summarized and saved to context, contributing to the overall recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee8064b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# üíß Hydration & Kidney Health Module\n",
       "\n",
       "Hydration plays a critical role in concentration, energy levels, kidney function,\n",
       "and overall physical wellbeing‚Äîespecially for people who spend long hours at a desk.\n",
       "Mild dehydration is common in office settings and often goes unnoticed until symptoms\n",
       "such as headache, fatigue, or brain fog appear.\n",
       "\n",
       "This module is designed to move beyond simple ‚Äúwater tracking‚Äù by combining\n",
       "**daily hydration behaviors** with **physiological bio-feedback signals**. Together,\n",
       "these provide a more realistic picture of hydration status than intake alone.\n",
       "\n",
       "### What this module captures\n",
       "- Daily water intake (number of glasses)\n",
       "- Caffeine consumption (coffee, tea, energy drinks)\n",
       "- Sugary drink intake\n",
       "- Hydration habits (e.g., keeping a water bottle visible on the desk)\n",
       "- Urine color indicator\n",
       "- Thirst sensation\n",
       "- Common dehydration symptoms (headache, brain fog, dizziness)\n",
       "\n",
       "### Why this matters\n",
       "Relying on thirst alone can be misleading, as thirst is often a **late signal**\n",
       "of dehydration. Caffeine use, long screen time, and busy work routines can further\n",
       "mask early warning signs.\n",
       "\n",
       "By combining habits and body signals, this module helps identify patterns that may\n",
       "affect productivity, comfort, and kidney health‚Äîwithout requiring perfect tracking\n",
       "or medical interpretation.\n",
       "\n",
       "### How AI is used in this section\n",
       "The AI generates **non-diagnostic, preventive guidance** focused on:\n",
       "- Practical hydration targets for desk-based work\n",
       "- Habit nudges that fit real workdays\n",
       "- Early warning signals of possible dehydration\n",
       "- Short, actionable checklists for same-day improvement\n",
       "\n",
       "The goal is awareness and prevention‚Äînot diagnosis.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(HYDRATION_INFO_MD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fb3a5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hydration Module ‚Äî Config + History Loader\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_hydration_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Hydration module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"hydration\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaf6fe",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî Hydration Inputs\n",
    "\n",
    "This UI is structured into 2 blocks:\n",
    "\n",
    "### 1) Daily Intake\n",
    "Captures water, caffeine, sugary drinks, and desk habit signals.\n",
    "\n",
    "### 2) Hydration Signals (Bio-feedback)\n",
    "Captures urine color, thirst sensation, and dehydration symptoms.\n",
    "\n",
    "These signals are more reliable than \"guessing hydration\" because they reflect real physiology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "243c557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hydration Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_hydration_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(\"### Daily Intake\")\n",
    "\n",
    "    with gr.Row():\n",
    "        water_intake = gr.Slider(\n",
    "            minimum=0, maximum=15, step=1,\n",
    "            value=_to_int(saved_user_input.get(\"water_intake\", 0), 0),\n",
    "            label=_safe_t(lang, \"hydration.water\", locales_dir, default=\"Water Glasses (250ml)\")\n",
    "        )\n",
    "\n",
    "        caffeine_intake = gr.Number(\n",
    "            value=_to_float(saved_user_input.get(\"caffeine_intake\", 0), 0.0),\n",
    "            label=_safe_t(lang, \"hydration.caffeine\", locales_dir, default=\"Cups of Coffee/Tea\")\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        bottle_on_desk = gr.Checkbox(\n",
    "            value=_to_bool(saved_user_input.get(\"bottle_on_desk\", False)),\n",
    "            label=\"Water bottle is visible on desk?\"\n",
    "        )\n",
    "\n",
    "        sugary_drinks = gr.Number(\n",
    "            value=_to_float(saved_user_input.get(\"sugary_drinks\", 0), 0.0),\n",
    "            label=\"Sugary Drinks (Soda/Juice)\"\n",
    "        )\n",
    "\n",
    "    with gr.Accordion(\"Hydration Signals (Bio-Feedback)\", open=True):\n",
    "        gr.Markdown(\"*Your body is the best sensor. Check these signals:*\")\n",
    "\n",
    "        urine_choices = [\"Clear / Pale Yellow (Good)\", \"Yellow (Okay)\", \"Dark Yellow / Amber (Dehydrated)\"]\n",
    "        saved_urine = saved_user_input.get(\"urine_color\", \"Yellow (Okay)\")\n",
    "        if saved_urine not in urine_choices:\n",
    "            saved_urine = \"Yellow (Okay)\"\n",
    "\n",
    "        with gr.Row():\n",
    "            urine_color = gr.Dropdown(\n",
    "                choices=urine_choices,\n",
    "                value=saved_urine,\n",
    "                label=_safe_t(lang, \"hydration.urine\", locales_dir, default=\"Urine Color Indicator\")\n",
    "            )\n",
    "\n",
    "            thirst_level = gr.Radio(\n",
    "                choices=[\"Not Thirsty\", \"Mildly Thirsty\", \"Very Thirsty / Parched\"],\n",
    "                value=str(saved_user_input.get(\"thirst_level\", \"Not Thirsty\") or \"Not Thirsty\"),\n",
    "                label=\"Thirst Sensation\"\n",
    "            )\n",
    "\n",
    "        symptoms = gr.CheckboxGroup(\n",
    "            choices=[\"Dry Mouth/Lips\", \"Headache\", \"Dizziness\", \"Brain Fog\"],\n",
    "            value=_to_list(saved_user_input.get(\"symptoms\", [])),\n",
    "            label=\"Dehydration Symptoms\"\n",
    "        )\n",
    "\n",
    "    notes_input = gr.Textbox(\n",
    "        value=str(saved_user_input.get(\"notes\", \"\") or \"\"),\n",
    "        label=_safe_t(lang, \"hydration.notes\", locales_dir, default=\"Notes\"),\n",
    "        lines=1\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"water_intake\": water_intake,\n",
    "        \"caffeine_intake\": caffeine_intake,\n",
    "        \"bottle_on_desk\": bottle_on_desk,\n",
    "        \"sugary_drinks\": sugary_drinks,\n",
    "        \"urine_color\": urine_color,\n",
    "        \"thirst_level\": thirst_level,\n",
    "        \"symptoms\": symptoms,\n",
    "        \"notes_input\": notes_input,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a78b80",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "The output section contains:\n",
    "\n",
    "- **Status panel**: used to display save confirmations and error messages.\n",
    "- **AI output box**: a read-only field that displays Gemini-generated hydration analysis.\n",
    "\n",
    "The latest saved AI output is loaded automatically at startup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ffe12ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hydration Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_hydration_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"hydration.output\", locales_dir, default=\"Hydration Analysis\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=10\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d4aad8",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Analysis + Saving Logic\n",
    "\n",
    "This section implements the logic behind the three buttons:\n",
    "\n",
    "### Button 1: Save User Input\n",
    "Appends user input to a timestamped history file.\n",
    "\n",
    "### Button 2: Generate AI Analysis\n",
    "Uses Gemini to interpret hydration risks and suggest practical actions.\n",
    "\n",
    "### Button 3: Save AI Output\n",
    "Saves the generated analysis into an AI history file.\n",
    "\n",
    "This design supports longitudinal tracking and allows future visualization modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96552372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hydration Module ‚Äî AI + Saving + Wiring\n",
    "# ==========================================\n",
    "\n",
    "def connect_hydration_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown\n",
    "):\n",
    "\n",
    "    # -------------------------\n",
    "    # LOCAL DOMAIN CONSTANTS\n",
    "    # (prevents naming conflicts)\n",
    "    # -------------------------\n",
    "    local_domain = \"hydration\"\n",
    "    local_user_file = \"hydration_user_input.json\"\n",
    "    local_ai_file = \"hydration_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect JSON-safe input\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        water_val, caffeine_val, bottle_val, sugar_val,\n",
    "        urine_val, thirst_val, symp_val, notes_val\n",
    "    ):\n",
    "        return {\n",
    "            \"water_intake\": _to_int(water_val, 0),\n",
    "            \"caffeine_intake\": _to_float(caffeine_val, 0.0),\n",
    "            \"bottle_on_desk\": _to_bool(bottle_val),\n",
    "            \"sugary_drinks\": _to_float(sugar_val, 0.0),\n",
    "            \"urine_color\": str(urine_val or \"\"),\n",
    "            \"thirst_level\": str(thirst_val or \"\"),\n",
    "            \"symptoms\": _to_list(symp_val),\n",
    "            \"notes\": str(notes_val or \"\"),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        water_val, caffeine_val, bottle_val, sugar_val,\n",
    "        urine_val, thirst_val, symp_val, notes_val\n",
    "    ):\n",
    "        print(\"[hydration] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                water_val, caffeine_val, bottle_val, sugar_val,\n",
    "                urine_val, thirst_val, symp_val, notes_val\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Saved hydration input. File: `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[hydration] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        water_val, caffeine_val, bottle_val, sugar_val,\n",
    "        urine_val, thirst_val, symp_val, notes_val\n",
    "    ):\n",
    "        print(\"[hydration] üîò Generate AI clicked\")\n",
    "\n",
    "        user_input = collect_user_input(\n",
    "            water_val, caffeine_val, bottle_val, sugar_val,\n",
    "            urine_val, thirst_val, symp_val, notes_val\n",
    "        )\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a preventive hydration and kidney health assistant.\\n\"\n",
    "            \"Analyze the hydration data and provide non-diagnostic guidance.\\n\"\n",
    "            \"1) Consider caffeine as a mild diuretic.\\n\"\n",
    "            \"2) If urine is dark or headache exists, issue a clear hydration alert.\\n\"\n",
    "            \"3) If bottle_on_desk is false, explain nudge theory benefit.\\n\"\n",
    "            \"4) Give practical hydration targets and habits for desk workers.\\n\"\n",
    "            \"5) Provide a short checklist of next actions.\\n\\n\"\n",
    "            f\"HYDRATION DATA:\\n{user_input}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[hydration] ‚ùå AI generation failed: {e}\")\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[hydration] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_ai_file, existing)\n",
    "\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[hydration] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Saved AI output. File: `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[hydration] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Hydration Analysis\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"water_intake\"],\n",
    "        ui_inputs[\"caffeine_intake\"],\n",
    "        ui_inputs[\"bottle_on_desk\"],\n",
    "        ui_inputs[\"sugary_drinks\"],\n",
    "        ui_inputs[\"urine_color\"],\n",
    "        ui_inputs[\"thirst_level\"],\n",
    "        ui_inputs[\"symptoms\"],\n",
    "        ui_inputs[\"notes_input\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (Hydration)\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _hydration_demo_generate():\n",
    "            print(\"[hydration-demo] üöÄ Demo generate using saved hydration data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved hydration demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved hydration record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace hydration assistant.\\n\"\n",
    "                \"Analyze the following hydration and caffeine data.\\n\"\n",
    "                \"Provide actionable, non-diagnostic hydration recommendations.\\n\"\n",
    "                \"Discuss headaches, fatigue, urine color, caffeine balance, and daily water habits.\\n\\n\"\n",
    "                f\"HYDRATION DATA:\\n{last}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Hydration demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=\"hydration\",\n",
    "            label=\"Hydration Module\",\n",
    "            generate_fn=_hydration_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[hydration] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a279cd3",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Hydration Tab Builder\n",
    "\n",
    "This wrapper function assembles the full Hydration module:\n",
    "\n",
    "1. Loads the latest stored history\n",
    "2. Builds the UI input fields\n",
    "3. Builds the output fields\n",
    "4. Connects Gemini + saving logic\n",
    "\n",
    "This design keeps the notebook clean and makes the project easy to judge and maintain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80ade49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hydration Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_hydration_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    local_domain = \"hydration\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[hydration] ‚úÖ build_hydration_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_domain_history(store, local_domain)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"hydration.title\",\n",
    "            locales_dir,\n",
    "            default=\"üíß Hydration & Kidney Health\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (Hydration Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò Hydration Tab Guide\",\n",
    "        content_md=HYDRATION_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è Hydration Info\",\n",
    "        open_label=\"‚ùå Hide Hydration Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_hydration_inputs(\n",
    "        saved_user_input,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output, status = build_hydration_outputs(\n",
    "        saved_ai_text,\n",
    "        lang,\n",
    "        locales_dir,\n",
    "    )\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_hydration_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a0ae7",
   "metadata": {},
   "source": [
    "Productivity Tab\n",
    "The Productivity tab monitors work efficiency and break habits. The user could input their perceived productivity level or number of breaks taken. Using this, the AI offers suggestions to balance productivity with health (for instance, regular short breaks to maintain focus). This information is summarized and stored for later use in global advice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "018aaf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# üìà Productivity & Focus Module  \n",
       "*Attention, Workflow & Efficiency Awareness*\n",
       "\n",
       "Productivity during desk work is influenced not only by workload, but also by\n",
       "attention management, task structure, and environmental distractions. Cognitive\n",
       "overload, frequent interruptions, and unclear task boundaries can gradually\n",
       "reduce focus and perceived efficiency.\n",
       "\n",
       "This module is designed to support **productivity and focus awareness**, not\n",
       "performance evaluation. It helps identify patterns related to attention,\n",
       "distraction, and workflow that may affect daily output and mental effort.\n",
       "\n",
       "### What this module captures\n",
       "- Perceived focus quality\n",
       "- Workload intensity and pacing\n",
       "- Task switching frequency\n",
       "- Internal and external distractions\n",
       "- Energy consistency throughout the day\n",
       "- Break patterns and recovery pauses\n",
       "- Perceived productivity barriers\n",
       "\n",
       "### Why this matters\n",
       "Reduced productivity is often a signal of system strain rather than individual\n",
       "failure. Persistent distraction and overload can increase mental fatigue and\n",
       "reduce work satisfaction over time.\n",
       "\n",
       "By identifying attention patterns and workflow challenges, this module supports\n",
       "small, realistic adjustments that may improve focus and sustainability at work.\n",
       "\n",
       "### How AI is used in this section\n",
       "The AI provides **non-diagnostic, supportive guidance** focused on:\n",
       "- Attention management strategies\n",
       "- Structuring work to reduce cognitive overload\n",
       "- Improving task flow and break timing\n",
       "- Supporting sustainable productivity habits\n",
       "\n",
       "The aim is to enhance clarity and efficiency‚Äînot to measure or judge performance.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(PRODUCTIVITY_INFO_MD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf2e171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Productivity Module ‚Äî Config + History Load\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_productivity_history(store):\n",
    "    \"\"\"\n",
    "    Loads the most recent saved user input + AI output for the Productivity module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "    local_domain = \"productivity\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca926e",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî User Inputs (Daily Productivity Signals)\n",
    "\n",
    "This section builds the UI inputs for the Productivity tab.\n",
    "\n",
    "The user provides:\n",
    "- Focus quality and deep work hours\n",
    "- Whether they achieved flow state\n",
    "- Whether the most important task was completed\n",
    "- Health interference factors (pain, fatigue, brain fog)\n",
    "- Energy rhythm (peak energy + slump severity)\n",
    "- Distraction sources and focus techniques used\n",
    "\n",
    "These inputs will later be passed to Gemini for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39443727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Productivity Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_productivity_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(\"### Performance Metrics\")\n",
    "\n",
    "    with gr.Row():\n",
    "        focus_quality = gr.Slider(\n",
    "            minimum=0, maximum=10, step=1,\n",
    "            value=_to_int(saved_user_input.get(\"focus_quality\", 5), 5),\n",
    "            label=_safe_t(lang, \"productivity.focus\", locales_dir, default=\"Focus Quality (1=Scattered, 10=Laser)\")\n",
    "        )\n",
    "        deep_work = gr.Number(\n",
    "            value=_to_float(saved_user_input.get(\"deep_work\", 0), 0.0),\n",
    "            label=\"Deep Work Hours (Distraction-Free)\"\n",
    "        )\n",
    "\n",
    "    with gr.Row():\n",
    "        flow_state = gr.Checkbox(\n",
    "            value=_to_bool(saved_user_input.get(\"flow_state\", False)),\n",
    "            label=\"Achieved 'Flow State' today?\"\n",
    "        )\n",
    "        satisfaction = gr.Checkbox(\n",
    "            value=_to_bool(saved_user_input.get(\"satisfaction\", False)),\n",
    "            label=\"Completed MOST important task?\"\n",
    "        )\n",
    "\n",
    "    with gr.Accordion(\"Health Interference & Energy\", open=True):\n",
    "        gr.Markdown(\"*How much is your body holding you back?*\")\n",
    "\n",
    "        blocker_choices = [\"None\", \"Neck/Back Pain\", \"Eye Fatigue\", \"Brain Fog\", \"Hunger\", \"Headache\"]\n",
    "        saved_blocker = _to_str(saved_user_input.get(\"blocker\", \"None\"), \"None\")\n",
    "        if saved_blocker not in blocker_choices:\n",
    "            saved_blocker = \"None\"\n",
    "\n",
    "        peak_choices = [\"Early Morning\", \"Late Morning\", \"After Lunch\", \"Evening\", \"Late Night\"]\n",
    "        saved_peak = _to_str(saved_user_input.get(\"peak_energy\", \"Late Morning\"), \"Late Morning\")\n",
    "        if saved_peak not in peak_choices:\n",
    "            saved_peak = \"Late Morning\"\n",
    "\n",
    "        slump_choices = [\"No slump\", \"Mild dip\", \"Total crash\"]\n",
    "        saved_slump = _to_str(saved_user_input.get(\"slump_severity\", \"Mild dip\"), \"Mild dip\")\n",
    "        if saved_slump not in slump_choices:\n",
    "            saved_slump = \"Mild dip\"\n",
    "\n",
    "        with gr.Row():\n",
    "            health_tax = gr.Slider(\n",
    "                minimum=0, maximum=10, step=1,\n",
    "                value=_to_int(saved_user_input.get(\"health_tax\", 0), 0),\n",
    "                label=\"Physical Interference (Pain/Fatigue Impact)\"\n",
    "            )\n",
    "            blocker = gr.Dropdown(\n",
    "                choices=blocker_choices,\n",
    "                value=saved_blocker,\n",
    "                label=\"Primary Blocker\"\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            peak_energy = gr.Dropdown(\n",
    "                choices=peak_choices,\n",
    "                value=saved_peak,\n",
    "                label=\"Peak Energy Window\"\n",
    "            )\n",
    "            slump_severity = gr.Radio(\n",
    "                choices=slump_choices,\n",
    "                value=saved_slump,\n",
    "                label=\"Afternoon Slump Severity\"\n",
    "            )\n",
    "\n",
    "    with gr.Accordion(\"Habits & Distractions\", open=False):\n",
    "\n",
    "        distraction_choices = [\"Notifications/Email\", \"Colleagues/Meetings\", \"Noise\", \"Procrastination\", \"Phone/Social Media\"]\n",
    "        saved_dist = _to_str(saved_user_input.get(\"top_distraction\", \"Notifications/Email\"), \"Notifications/Email\")\n",
    "        if saved_dist not in distraction_choices:\n",
    "            saved_dist = \"Notifications/Email\"\n",
    "\n",
    "        switch_choices = [\"Low (Single Tasking)\", \"High (Multitasking)\"]\n",
    "        saved_switch = _to_str(saved_user_input.get(\"context_switching\", \"Low (Single Tasking)\"), \"Low (Single Tasking)\")\n",
    "        if saved_switch not in switch_choices:\n",
    "            saved_switch = \"Low (Single Tasking)\"\n",
    "\n",
    "        with gr.Row():\n",
    "            top_distraction = gr.Dropdown(\n",
    "                choices=distraction_choices,\n",
    "                value=saved_dist,\n",
    "                label=\"Top Distraction\"\n",
    "            )\n",
    "            context_switching = gr.Radio(\n",
    "                choices=switch_choices,\n",
    "                value=saved_switch,\n",
    "                label=\"Context Switching Level\"\n",
    "            )\n",
    "\n",
    "        methods = gr.CheckboxGroup(\n",
    "            choices=[\"Pomodoro Timer\", \"Time Blocking\", \"Music/White Noise\", \"Standing Desk\", \"Do Not Disturb Mode\"],\n",
    "            value=_to_list(saved_user_input.get(\"methods\", [])),\n",
    "            label=\"Techniques Used Today\"\n",
    "        )\n",
    "\n",
    "    notes_input = gr.Textbox(\n",
    "        value=_to_str(saved_user_input.get(\"notes\", \"\"), \"\"),\n",
    "        label=_safe_t(lang, \"productivity.notes\", locales_dir, default=\"Tasks & Observations\"),\n",
    "        lines=2\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"focus_quality\": focus_quality,\n",
    "        \"deep_work\": deep_work,\n",
    "        \"flow_state\": flow_state,\n",
    "        \"satisfaction\": satisfaction,\n",
    "        \"health_tax\": health_tax,\n",
    "        \"blocker\": blocker,\n",
    "        \"peak_energy\": peak_energy,\n",
    "        \"slump_severity\": slump_severity,\n",
    "        \"top_distraction\": top_distraction,\n",
    "        \"context_switching\": context_switching,\n",
    "        \"methods\": methods,\n",
    "        \"notes_input\": notes_input,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f3196",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Outputs\n",
    "\n",
    "This section defines the output UI components:\n",
    "\n",
    "- A **status box** for save/generate messages\n",
    "- An **AI output text box** for Gemini recommendations\n",
    "\n",
    "The AI output is loaded from the latest saved history so the user always sees their last generated analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e97501fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Productivity Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_productivity_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=_safe_t(lang, \"productivity.output\", locales_dir, default=\"Productivity Analysis\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=10\n",
    "    )\n",
    "\n",
    "    return output, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4153205",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Interaction + Saving Logic\n",
    "\n",
    "This section handles:\n",
    "\n",
    "1. Collecting user inputs into a clean JSON dictionary\n",
    "2. Saving user input records into `productivity_user_input.json`\n",
    "3. Sending the structured data to Gemini as a prompt\n",
    "4. Saving Gemini output into `productivity_ai_output.json`\n",
    "\n",
    "All saved data is stored as a **list of timestamped records**, allowing longitudinal tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3012313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Productivity Module ‚Äî AI + Saving + Wiring (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def connect_productivity_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output: gr.Textbox,\n",
    "    status: gr.Markdown,\n",
    "):\n",
    "\n",
    "    # -------------------------\n",
    "    # LOCAL DOMAIN CONSTANTS\n",
    "    # (prevents naming conflicts)\n",
    "    # -------------------------\n",
    "    local_domain = \"productivity\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect user input helper\n",
    "    # -------------------------\n",
    "    def collect_user_input(\n",
    "        focus_val, deep_val, flow_val, sat_val,\n",
    "        tax_val, blocker_val, peak_val, slump_val,\n",
    "        dist_val, switch_val, meth_val, notes_val\n",
    "    ):\n",
    "        return {\n",
    "            \"focus_quality\": _to_int(focus_val, 5),\n",
    "            \"deep_work\": _to_float(deep_val, 0.0),\n",
    "            \"flow_state\": _to_bool(flow_val),\n",
    "            \"satisfaction\": _to_bool(sat_val),\n",
    "            \"health_tax\": _to_int(tax_val, 0),\n",
    "            \"blocker\": _to_str(blocker_val, \"None\"),\n",
    "            \"peak_energy\": _to_str(peak_val, \"Late Morning\"),\n",
    "            \"slump_severity\": _to_str(slump_val, \"Mild dip\"),\n",
    "            \"top_distraction\": _to_str(dist_val, \"Notifications/Email\"),\n",
    "            \"context_switching\": _to_str(switch_val, \"Low (Single Tasking)\"),\n",
    "            \"methods\": _to_list(meth_val),\n",
    "            \"notes\": _to_str(notes_val, \"\"),\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Save user input (APPEND)\n",
    "    # -------------------------\n",
    "    def save_user_input(\n",
    "        focus_val, deep_val, flow_val, sat_val,\n",
    "        tax_val, blocker_val, peak_val, slump_val,\n",
    "        dist_val, switch_val, meth_val, notes_val\n",
    "    ):\n",
    "        print(\"[productivity] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(\n",
    "                focus_val, deep_val, flow_val, sat_val,\n",
    "                tax_val, blocker_val, peak_val, slump_val,\n",
    "                dist_val, switch_val, meth_val, notes_val\n",
    "            )\n",
    "\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Productivity input saved. File: `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[productivity] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Generate AI output\n",
    "    # -------------------------\n",
    "    def generate_ai(\n",
    "        focus_val, deep_val, flow_val, sat_val,\n",
    "        tax_val, blocker_val, peak_val, slump_val,\n",
    "        dist_val, switch_val, meth_val, notes_val\n",
    "    ):\n",
    "        print(\"[productivity] üîò Generate AI clicked\")\n",
    "\n",
    "        user_input = collect_user_input(\n",
    "            focus_val, deep_val, flow_val, sat_val,\n",
    "            tax_val, blocker_val, peak_val, slump_val,\n",
    "            dist_val, switch_val, meth_val, notes_val\n",
    "        )\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a sustainable productivity and desk-work performance assistant.\\n\"\n",
    "            \"Analyze the productivity data and provide actionable, non-diagnostic recommendations.\\n\"\n",
    "            \"1. Analyze the Health Tax and how physical discomfort affects focus.\\n\"\n",
    "            \"2. If slump severity is high, suggest a circadian-based schedule adjustment.\\n\"\n",
    "            \"3. If context switching is high but satisfaction is low, recommend a specific focus technique.\\n\"\n",
    "            \"4. Suggest one practical plan for tomorrow.\\n\\n\"\n",
    "            f\"PRODUCTIVITY DATA:\\n{json.dumps(user_input, indent=2, ensure_ascii=False)}\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[productivity] ‚ùå AI generation failed: {e}\")\n",
    "            return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ AI output generated (not saved yet).\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[productivity] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "            _save_json_best_effort(store, local_ai_file, existing)\n",
    "\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[productivity] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Productivity AI output saved. File: `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[productivity] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Buttons UI\n",
    "    # -------------------------\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Productivity Analysis\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"focus_quality\"],\n",
    "        ui_inputs[\"deep_work\"],\n",
    "        ui_inputs[\"flow_state\"],\n",
    "        ui_inputs[\"satisfaction\"],\n",
    "        ui_inputs[\"health_tax\"],\n",
    "        ui_inputs[\"blocker\"],\n",
    "        ui_inputs[\"peak_energy\"],\n",
    "        ui_inputs[\"slump_severity\"],\n",
    "        ui_inputs[\"top_distraction\"],\n",
    "        ui_inputs[\"context_switching\"],\n",
    "        ui_inputs[\"methods\"],\n",
    "        ui_inputs[\"notes_input\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output], outputs=[status])\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (Productivity) ‚Äî FIXED\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _productivity_demo_generate():\n",
    "            print(\"[productivity-demo] üöÄ Demo generate using saved productivity data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved productivity demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved productivity record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace productivity assistant.\\n\"\n",
    "                \"Analyze the following productivity, focus, and distraction data.\\n\"\n",
    "                \"Provide actionable, non-diagnostic productivity improvement recommendations.\\n\"\n",
    "                \"Focus on deep work, breaks, attention management, routines, and mental clarity.\\n\\n\"\n",
    "                f\"PRODUCTIVITY DATA:\\n{json.dumps(last, indent=2, ensure_ascii=False)}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Productivity demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"Productivity Module\",\n",
    "            generate_fn=_productivity_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[productivity] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce684dd7",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Productivity Tab Builder\n",
    "\n",
    "This is the final wrapper function that builds the Productivity tab.\n",
    "\n",
    "It:\n",
    "- Loads the latest history\n",
    "- Creates the UI inputs\n",
    "- Creates the output components\n",
    "- Connects buttons to AI generation and saving logic\n",
    "\n",
    "This function is what the main app uses when registering the Productivity tab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4708c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Productivity Module ‚Äî Final Tab Builder (FIXED)\n",
    "# ==========================================\n",
    "\n",
    "def build_productivity_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    local_domain = \"productivity\"\n",
    "    local_user_file = f\"{local_domain}_user_input.json\"\n",
    "    local_ai_file = f\"{local_domain}_ai_output.json\"\n",
    "\n",
    "    print(f\"[productivity] ‚úÖ build_productivity_tab executed. user_file={local_user_file}, ai_file={local_ai_file}\")\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_domain_history(store, local_domain)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"productivity.title\",\n",
    "            locales_dir,\n",
    "            default=\"üìà Sustainable Productivity & Focus\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (Productivity Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò Productivity Tab Guide\",\n",
    "        content_md=PRODUCTIVITY_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è Productivity Info\",\n",
    "        open_label=\"‚ùå Hide Productivity Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_productivity_inputs(saved_user_input, lang, locales_dir)\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output, status = build_productivity_outputs(saved_ai_text, lang, locales_dir)\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_productivity_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output=output,\n",
    "        status=status,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96d34d",
   "metadata": {},
   "source": [
    "Recovery/Sleep Tab\n",
    "The Recovery/Sleep tab deals with rest quality and recovery. The user can log sleep patterns or how rested they feel. The AI might provide tips for better sleep hygiene or recovery techniques if it detects poor rest. The outcome is a summary of the user's recovery status, which is saved for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8053a1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# üò¥ Recovery & Sleep Module  \n",
       "*Rest, Recovery & Sleep Awareness*\n",
       "\n",
       "Adequate recovery is essential for both physical and mental performance. Desk\n",
       "work, irregular schedules, stress, and extended screen exposure‚Äîespecially late\n",
       "in the day‚Äîcan interfere with sleep quality and overnight recovery.\n",
       "\n",
       "This module is designed to support **recovery and sleep awareness**, not diagnosis.\n",
       "It focuses on identifying rest patterns, sleep-related behaviors, and recovery\n",
       "signals that influence daily energy and resilience.\n",
       "\n",
       "### What this module captures\n",
       "- Sleep duration and perceived quality\n",
       "- Sleep consistency and timing\n",
       "- Daytime fatigue or sleepiness\n",
       "- Evening screen exposure\n",
       "- Recovery practices and wind-down routines\n",
       "- Use of caffeine or stimulants\n",
       "- Perceived restfulness upon waking\n",
       "\n",
       "### Why this matters\n",
       "Poor sleep and inadequate recovery often accumulate gradually, affecting mood,\n",
       "focus, physical comfort, and stress tolerance. These effects may be subtle at\n",
       "first but can compound over time.\n",
       "\n",
       "Early awareness of sleep and recovery patterns allows for simple behavioral\n",
       "adjustments that may support long-term wellbeing and daily performance.\n",
       "\n",
       "### How AI is used in this section\n",
       "The AI provides **non-diagnostic, preventive guidance** focused on:\n",
       "- Sleep hygiene and consistency\n",
       "- Evening routines that support recovery\n",
       "- Managing stimulants and screen exposure\n",
       "- Practical steps to improve daily restoration\n",
       "\n",
       "The goal is to promote sustainable recovery‚Äînot to replace sleep or medical care.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(RECOVERY_SLEEP_INFO_MD))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d0944e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Recovery/Sleep Module ‚Äî Config + History Loader (SAFE)\n",
    "# ==========================================\n",
    "\n",
    "def load_recovery_sleep_history(store):\n",
    "    \"\"\"\n",
    "    Load the latest saved user input and AI output for the Recovery/Sleep module.\n",
    "    Uses the unified load_domain_history() helper.\n",
    "    \"\"\"\n",
    "\n",
    "    local_domain = \"recovery_sleep\"\n",
    "    return load_domain_history(store, local_domain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a31eaa",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî Recovery & Sleep Inputs\n",
    "\n",
    "This tab collects both:\n",
    "### Sleep outcome metrics\n",
    "- Sleep duration\n",
    "- Feeling well-rested\n",
    "\n",
    "### Evening habits that influence sleep\n",
    "- Screen cutoff (1 hour before bed)\n",
    "- Blue light filter usage\n",
    "- Light stretching/movement\n",
    "\n",
    "### Stress & sleep environment\n",
    "- Stress level (burnout risk signal)\n",
    "- Room comfort (temperature/light/noise)\n",
    "\n",
    "These are highly relevant for desk workers because screen use, posture stiffness,\n",
    "and stress dysregulation strongly impact sleep quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d868b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Recovery/Sleep Module ‚Äî Inputs UI Builder\n",
    "# ==========================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_recovery_sleep_inputs(saved_user_input: dict, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    gr.Markdown(f\"### {_safe_t(lang, 'sleep.title', locales_dir, 'Recovery and Sleep Quality')}\")\n",
    "    gr.Markdown(\"Tracking habits that bridge the gap between your desk work and restorative rest.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Nightly Metrics\")\n",
    "\n",
    "            well_rested = gr.Checkbox(\n",
    "                value=bool(saved_user_input.get(\"well_rested\", False)),\n",
    "                label=_safe_t(lang, \"sleep.well_rested\", locales_dir, \"Feel well-rested today\")\n",
    "            )\n",
    "\n",
    "            sleep_hours = gr.Radio(\n",
    "                choices=[\"<5 hours\", \"5-7 hours\", \"7-9 hours\", \">9 hours\"],\n",
    "                value=saved_user_input.get(\"sleep_hours\", \"7-9 hours\"),\n",
    "                label=_safe_t(lang, \"sleep.duration\", locales_dir, \"Last Night's Sleep Duration\")\n",
    "            )\n",
    "\n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"#### Evening Habits (from 'Healthier at the Desk')\")\n",
    "\n",
    "            screen_cutoff = gr.Checkbox(\n",
    "                value=bool(saved_user_input.get(\"screen_cutoff\", False)),\n",
    "                label=\"Stopped screen use 1 hour before bed\"\n",
    "            )\n",
    "\n",
    "            blue_light_filter = gr.Checkbox(\n",
    "                value=bool(saved_user_input.get(\"blue_light_filter\", False)),\n",
    "                label=\"Used blue light filters/night mode on devices\"\n",
    "            )\n",
    "\n",
    "            evening_movement = gr.Checkbox(\n",
    "                value=bool(saved_user_input.get(\"evening_movement\", False)),\n",
    "                label=\"Light stretching/movement to ease desk stiffness\"\n",
    "            )\n",
    "\n",
    "    with gr.Row():\n",
    "        stress_level = gr.Slider(\n",
    "            minimum=1, maximum=10, step=1,\n",
    "            value=int(saved_user_input.get(\"stress_level\", 5)),\n",
    "            label=\"Workday Stress Level (1=Low, 10=Burnout Risk)\"\n",
    "        )\n",
    "\n",
    "        room_comfort = gr.Dropdown(\n",
    "            choices=[\"Cool & Dark\", \"Too Warm\", \"Too Bright\", \"Noisy\"],\n",
    "            value=saved_user_input.get(\"room_comfort\", \"Cool & Dark\"),\n",
    "            label=\"Sleep Environment\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"well_rested\": well_rested,\n",
    "        \"sleep_hours\": sleep_hours,\n",
    "        \"screen_cutoff\": screen_cutoff,\n",
    "        \"blue_light_filter\": blue_light_filter,\n",
    "        \"evening_movement\": evening_movement,\n",
    "        \"stress_level\": stress_level,\n",
    "        \"room_comfort\": room_comfort,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8993ee6",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Output Components\n",
    "\n",
    "The output section includes:\n",
    "- a status message field (save success, generation errors)\n",
    "- an AI output field that displays recovery advice\n",
    "\n",
    "This advice is meant to be actionable and non-diagnostic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "091a1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Recovery/Sleep Module ‚Äî Output UI Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_recovery_sleep_outputs(saved_ai_text: str, lang: str, locales_dir: Optional[Path]):\n",
    "\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    output_display = gr.Textbox(\n",
    "        label=_safe_t(lang, \"sleep.output\", locales_dir, \"AI Recovery Advice\"),\n",
    "        interactive=False,\n",
    "        value=saved_ai_text,\n",
    "        lines=10\n",
    "    )\n",
    "\n",
    "    return output_display, status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9ed2cf",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî AI Recovery Advice + Saving\n",
    "\n",
    "This section defines the core workflow:\n",
    "\n",
    "### Save User Input\n",
    "Appends the daily sleep entry into a timestamped history list.\n",
    "\n",
    "### Generate AI Advice\n",
    "Uses Gemini to produce recovery guidance focused on:\n",
    "- stress reduction habits\n",
    "- sleep environment optimization\n",
    "- screen time reduction strategies\n",
    "- desk-work recovery routines for tomorrow\n",
    "\n",
    "### Save AI Output\n",
    "Stores the generated advice for future review and longitudinal tracking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4ad91fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Recovery/Sleep Module ‚Äî AI + Saving + Wiring\n",
    "# ==========================================\n",
    "\n",
    "def connect_recovery_sleep_logic(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path],\n",
    "    ui_inputs: dict,\n",
    "    output_display: gr.Textbox,\n",
    "    status: gr.Markdown\n",
    "):\n",
    "\n",
    "    local_domain = \"recovery_sleep\"\n",
    "    local_user_file = \"recovery_sleep_user_input.json\"\n",
    "    local_ai_file = \"recovery_sleep_ai_output.json\"\n",
    "\n",
    "    def collect_user_input(rested, hours, screen, blue, move, stress, room):\n",
    "        return {\n",
    "            \"well_rested\": _to_bool(rested),\n",
    "            \"sleep_hours\": str(hours or \"\"),\n",
    "            \"screen_cutoff\": _to_bool(screen),\n",
    "            \"blue_light_filter\": _to_bool(blue),\n",
    "            \"evening_movement\": _to_bool(move),\n",
    "            \"stress_level\": _to_int(stress, 5),\n",
    "            \"room_comfort\": str(room or \"\")\n",
    "        }\n",
    "\n",
    "    def save_user_input(rested, hours, screen, blue, move, stress, room):\n",
    "        print(\"[recovery_sleep] üîò Save User Input clicked\")\n",
    "\n",
    "        try:\n",
    "            user_input = collect_user_input(rested, hours, screen, blue, move, stress, room)\n",
    "            record = {\"timestamp\": _now(), \"user_input\": user_input}\n",
    "\n",
    "            existing = store.load_json(local_user_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "\n",
    "            # ‚úÖ direct save (strong)\n",
    "            store.save_json(local_user_file, existing)\n",
    "\n",
    "            return f\"‚úÖ Recovery/Sleep data saved. File: `{_debug_store_path(store, local_user_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[recovery_sleep] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    def generate_ai(rested, hours, screen, blue, move, stress, room):\n",
    "        print(\"[recovery_sleep] üîò Generate AI clicked\")\n",
    "\n",
    "        user_input = collect_user_input(rested, hours, screen, blue, move, stress, room)\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a preventive health assistant specializing in workplace wellness.\\n\"\n",
    "            \"Analyze the following sleep and recovery data to provide actionable, \"\n",
    "            \"non-diagnostic advice for a desk-based professional.\\n\\n\"\n",
    "            f\"USER DATA:\\n{user_input}\\n\\n\"\n",
    "            \"INSTRUCTIONS:\\n\"\n",
    "            \"1. Focus on the connection between screen use and sleep quality.\\n\"\n",
    "            \"2. If stress is high, suggest micro-breaks or posture resets for the next day.\\n\"\n",
    "            \"3. Address the environment and pre-sleep habits mentioned in the data.\\n\"\n",
    "            \"4. Provide a simple 3-step recovery plan for tonight.\\n\"\n",
    "        )\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") and resp.text else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[recovery_sleep] ‚ùå AI Error: {e}\")\n",
    "            return \"\", f\"‚ö†Ô∏è AI Error: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ Advice generated (not saved yet).\"\n",
    "\n",
    "    def save_ai_output(text: str):\n",
    "        print(\"[recovery_sleep] üîò Save AI Output clicked\")\n",
    "\n",
    "        if not (text or \"\").strip():\n",
    "            return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "        try:\n",
    "            record = {\"timestamp\": _now(), \"ai_output\": text.strip()}\n",
    "\n",
    "            existing = store.load_json(local_ai_file, [])\n",
    "            if not isinstance(existing, list):\n",
    "                existing = []\n",
    "\n",
    "            existing.append(record)\n",
    "\n",
    "            # ‚úÖ direct save (strong)\n",
    "            store.save_json(local_ai_file, existing)\n",
    "\n",
    "            try:\n",
    "                updater = globals().get(\"update_domain_summary\")\n",
    "                if updater:\n",
    "                    updater(store, local_domain, text[:200])\n",
    "            except Exception as e:\n",
    "                print(f\"[recovery_sleep] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "            return f\"üíæ Recovery/Sleep AI output saved. File: `{_debug_store_path(store, local_ai_file)}`\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[recovery_sleep] ‚ùå Save failed: {e}\")\n",
    "            return f\"‚ùå Save failed: {e}\"\n",
    "\n",
    "    with gr.Row():\n",
    "        save_input_btn = gr.Button(\"üíæ Save User Input\", variant=\"secondary\")\n",
    "        gen_btn = gr.Button(\"ü§ñ Generate AI Recovery Advice\", variant=\"primary\")\n",
    "        save_ai_btn = gr.Button(\"üíæ Save AI Output\", variant=\"secondary\")\n",
    "\n",
    "    inputs_list = [\n",
    "        ui_inputs[\"well_rested\"],\n",
    "        ui_inputs[\"sleep_hours\"],\n",
    "        ui_inputs[\"screen_cutoff\"],\n",
    "        ui_inputs[\"blue_light_filter\"],\n",
    "        ui_inputs[\"evening_movement\"],\n",
    "        ui_inputs[\"stress_level\"],\n",
    "        ui_inputs[\"room_comfort\"],\n",
    "    ]\n",
    "\n",
    "    save_input_btn.click(fn=save_user_input, inputs=inputs_list, outputs=[status])\n",
    "    gen_btn.click(fn=generate_ai, inputs=inputs_list, outputs=[output_display, status])\n",
    "    save_ai_btn.click(fn=save_ai_output, inputs=[output_display], outputs=[status])\n",
    "\n",
    "    try:\n",
    "        def _recovery_sleep_demo_generate():\n",
    "            print(\"[recovery_sleep-demo] üöÄ Demo generate using saved recovery_sleep data\")\n",
    "\n",
    "            raw = store.load_json(local_user_file, [])\n",
    "            if not isinstance(raw, list) or not raw:\n",
    "                return \"‚ö†Ô∏è No saved recovery_sleep demo input found.\", \"No data\"\n",
    "\n",
    "            last = raw[-1].get(\"user_input\", {})\n",
    "            if not isinstance(last, dict) or not last:\n",
    "                return \"‚ö†Ô∏è Saved recovery_sleep record is empty.\", \"No data\"\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace recovery and sleep assistant.\\n\"\n",
    "                \"Analyze the following sleep and recovery data.\\n\"\n",
    "                \"Provide actionable, non-diagnostic recommendations to improve sleep quality and recovery.\\n\"\n",
    "                \"Include screen cutoff, stress, evening routines, and room comfort.\\n\"\n",
    "                \"Mention red flags (severe insomnia, breathing issues, extreme fatigue).\\n\\n\"\n",
    "                f\"SLEEP/RECOVERY DATA:\\n{last}\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Recovery/Sleep demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=local_domain,\n",
    "            label=\"Recovery / Sleep Module\",\n",
    "            generate_fn=_recovery_sleep_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[recovery_sleep] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b33f1",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Recovery & Sleep Tab Builder\n",
    "\n",
    "This wrapper function builds the Recovery/Sleep tab as one clean unit.\n",
    "\n",
    "It:\n",
    "- loads the latest saved data\n",
    "- builds the UI inputs\n",
    "- builds the AI output area\n",
    "- connects button logic for save/generate/save\n",
    "\n",
    "This modular structure is hackathon-friendly and easy to maintain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5162580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Recovery/Sleep Module ‚Äî Final Tab Builder\n",
    "# ==========================================\n",
    "\n",
    "def build_recovery_sleep_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state: gr.State,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    saved_user_input, saved_ai_text = load_recovery_sleep_history(store)\n",
    "\n",
    "    # --- Title ---\n",
    "    gr.Markdown(\n",
    "        _safe_t(\n",
    "            lang,\n",
    "            \"sleep.title\",\n",
    "            locales_dir,\n",
    "            default=\"üò¥ Recovery & Sleep Quality\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Info Panel Button (Recovery/Sleep Tab) ---\n",
    "    add_info_panel(\n",
    "        title=\"üìò Recovery & Sleep Tab Guide\",\n",
    "        content_md=RECOVERY_SLEEP_INFO_MD,\n",
    "        button_label=\"‚ÑπÔ∏è Recovery/Sleep Info\",\n",
    "        open_label=\"‚ùå Hide Recovery/Sleep Info\",\n",
    "    )\n",
    "\n",
    "    # --- Inputs ---\n",
    "    ui_inputs = build_recovery_sleep_inputs(saved_user_input, lang, locales_dir)\n",
    "\n",
    "    # --- Outputs ---\n",
    "    output_display, status = build_recovery_sleep_outputs(saved_ai_text, lang, locales_dir)\n",
    "\n",
    "    # --- Logic wiring ---\n",
    "    connect_recovery_sleep_logic(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        locales_dir=locales_dir,\n",
    "        ui_inputs=ui_inputs,\n",
    "        output_display=output_display,\n",
    "        status=status\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c8565a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def trim_any_json_file(path: Path, keep_last: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    If JSON file contains a LIST ‚Üí trim it to last N entries.\n",
    "    If JSON contains a DICT ‚Üí leave it unchanged.\n",
    "    If invalid ‚Üí report error.\n",
    "    \"\"\"\n",
    "\n",
    "    if not path.exists():\n",
    "        return {\"file\": path.name, \"status\": \"missing\"}\n",
    "\n",
    "    try:\n",
    "        data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "    except Exception as e:\n",
    "        return {\"file\": path.name, \"status\": f\"invalid_json: {e}\"}\n",
    "\n",
    "    # If dict, don't touch\n",
    "    if isinstance(data, dict):\n",
    "        return {\"file\": path.name, \"status\": \"dict (skipped)\"}\n",
    "\n",
    "    # If list, trim\n",
    "    if isinstance(data, list):\n",
    "        original_len = len(data)\n",
    "\n",
    "        if original_len <= keep_last:\n",
    "            return {\"file\": path.name, \"status\": f\"ok ({original_len} entries)\"}\n",
    "\n",
    "        trimmed = data[-keep_last:]\n",
    "\n",
    "        try:\n",
    "            path.write_text(\n",
    "                json.dumps(trimmed, ensure_ascii=False, indent=2),\n",
    "                encoding=\"utf-8\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return {\"file\": path.name, \"status\": f\"write_failed: {e}\"}\n",
    "\n",
    "        return {\"file\": path.name, \"status\": f\"trimmed {original_len} ‚Üí {len(trimmed)}\"}\n",
    "\n",
    "    # Unknown type\n",
    "    return {\"file\": path.name, \"status\": f\"unknown_type ({type(data).__name__})\"}\n",
    "\n",
    "\n",
    "def refresh_all_json_files(store, keep_last: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Scans ALL .json files inside store.data_dir and trims list-based history files.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = Path(getattr(store, \"data_dir\", \"data\"))\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = sorted(list(data_dir.glob(\"*.json\")))\n",
    "\n",
    "    if not files:\n",
    "        return \"‚ö†Ô∏è No JSON files found.\"\n",
    "\n",
    "    report = [f\"### üßπ Full Data Refresh Report (keep_last={keep_last})\"]\n",
    "\n",
    "    for f in files:\n",
    "        result = trim_any_json_file(f, keep_last=keep_last)\n",
    "        report.append(f\"- `{result['file']}` ‚Üí {result['status']}\")\n",
    "\n",
    "    return \"\\n\".join(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50330137",
   "metadata": {},
   "source": [
    "Now the general recommendations tab or the action center it uses what ever availlable of the data from all the prevoius cells\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7d9a1",
   "metadata": {},
   "source": [
    "## General Workspace Health Chat (Ask AI)\n",
    "\n",
    "This cell defines a general-purpose, scoped AI chat for the application.\n",
    "\n",
    "The chat allows users to ask open-ended questions related to **workspace health,\n",
    "ergonomics, daily habits, and preventive wellbeing**. Unlike the structured\n",
    "assessment tabs, this section supports exploratory questions while remaining\n",
    "within a clearly defined, non-diagnostic scope.\n",
    "\n",
    "Key design principles:\n",
    "- The AI provides **preventive, non-diagnostic guidance only**\n",
    "- Medical diagnosis or treatment advice is intentionally excluded\n",
    "- Model calls are triggered **only on explicit user action**\n",
    "\n",
    "Optional personalization:\n",
    "- Users may choose to include their previously saved inputs to personalize\n",
    "  responses\n",
    "- Personal data is **opt-in** and loaded only when the user explicitly enables it\n",
    "- No data is sent to the model automatically or without user consent\n",
    "\n",
    "This design balances flexibility, safety, and transparency, while clearly\n",
    "demonstrating responsible use of a generative model within the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "413c05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "def _load_user_data_for_context(store) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load user-input-only data from the data folder.\n",
    "    Excludes AI outputs and summaries.\n",
    "    \"\"\"\n",
    "    data_dir = Path(getattr(store, \"data_dir\", Path(\"data\")))\n",
    "    if not data_dir.exists():\n",
    "        return {}\n",
    "\n",
    "    context = {}\n",
    "    for p in data_dir.glob(\"*_user_input.json\"):\n",
    "        try:\n",
    "            context[p.stem.replace(\"_user_input\", \"\")] = json.loads(\n",
    "                p.read_text(encoding=\"utf-8\")\n",
    "            )\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Tab Builder\n",
    "# =========================================================\n",
    "def build_general_chat_tab(store, gemini, lang_state, locales_dir):\n",
    "\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    # -------------------------\n",
    "    # Header\n",
    "    # -------------------------\n",
    "    gr.Markdown(\"### üß† Ask AI ‚Äî Workspace Health\")\n",
    "    gr.Markdown(\n",
    "        \"Ask general questions about workspace health, ergonomics, habits, and prevention. \"\n",
    "        \"This chat provides **non-diagnostic, preventive guidance**.\"\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # User input\n",
    "    # -------------------------\n",
    "    user_question = gr.Textbox(\n",
    "        label=\"Your question\",\n",
    "        placeholder=\"e.g. How can I reduce neck pain during long desk work?\",\n",
    "        lines=3,\n",
    "    )\n",
    "\n",
    "    use_context = gr.Checkbox(\n",
    "        label=\"Use my saved data to personalize the answer (optional)\",\n",
    "        value=False,\n",
    "    )\n",
    "\n",
    "    ask_btn = gr.Button(\"üß† Ask AI\")\n",
    "    output = gr.Markdown(\"\")\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Logic\n",
    "    # -------------------------\n",
    "    def ask_ai(question: str, use_ctx: bool):\n",
    "        if not question or not question.strip():\n",
    "            return \"‚ö†Ô∏è Please enter a question.\", \"\"\n",
    "\n",
    "        # Base system context (always included)\n",
    "        system_prompt = \"\"\"\n",
    "You are a preventive workplace health assistant.\n",
    "\n",
    "SCOPE:\n",
    "- Workspace ergonomics\n",
    "- Desk-work habits\n",
    "- Posture, movement, hydration, focus, recovery\n",
    "- General wellbeing in office or desk-based work\n",
    "\n",
    "RULES:\n",
    "- Do NOT provide diagnosis or treatment\n",
    "- Do NOT replace medical professionals\n",
    "- Provide practical, preventive, non-alarming guidance\n",
    "- If a question requires medical care, advise consulting a professional\n",
    "\"\"\"\n",
    "\n",
    "        # Optional personalization\n",
    "        user_context_text = \"\"\n",
    "        if use_ctx:\n",
    "            user_data = _load_user_data_for_context(store)\n",
    "            if user_data:\n",
    "                user_context_text = f\"\"\"\n",
    "OPTIONAL USER CONTEXT (for personalization only):\n",
    "{json.dumps(user_data, indent=2, ensure_ascii=False)}\n",
    "\"\"\"\n",
    "            else:\n",
    "                user_context_text = \"\\n(No saved user data available.)\\n\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "USER QUESTION:\n",
    "{question}\n",
    "\n",
    "{user_context_text}\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            resp = gemini.generate(prompt=prompt, response_language=lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "        except Exception as e:\n",
    "            return \"\", f\"‚ö†Ô∏è AI request failed: {e}\"\n",
    "\n",
    "        if not text:\n",
    "            return \"\", \"‚ö†Ô∏è AI returned empty output.\"\n",
    "\n",
    "        return text, \"‚úÖ Answer generated.\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Wiring\n",
    "    # -------------------------\n",
    "    ask_btn.click(\n",
    "        fn=ask_ai,\n",
    "        inputs=[user_question, use_context],\n",
    "        outputs=[output, status],\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Demo Hook Registration (Ask AI / General Chat Tab)\n",
    "    # -------------------------\n",
    "    try:\n",
    "        def _ask_ai_demo_generate():\n",
    "            print(\"[ask-ai-demo] üöÄ Demo generate using saved user input data\")\n",
    "\n",
    "            if \"build_context_from_data_folder\" in globals() and callable(globals()[\"build_context_from_data_folder\"]):\n",
    "                context = globals()[\"build_context_from_data_folder\"](store)\n",
    "            else:\n",
    "                return \"‚ö†Ô∏è build_context_from_data_folder() not found.\", \"No context builder\"\n",
    "\n",
    "            if not context or not str(context).strip():\n",
    "                return \"‚ö†Ô∏è No saved user input data found in data folder.\", \"No data\"\n",
    "\n",
    "            demo_question = (\n",
    "                \"I work long hours at a desk. Based on my saved health/workplace data, \"\n",
    "                \"what are the top 5 things I should improve this week?\"\n",
    "            )\n",
    "\n",
    "            prompt = (\n",
    "                \"You are a preventive workplace health assistant.\\n\"\n",
    "                \"Answer the user's question using the provided saved data.\\n\"\n",
    "                \"Be concise, practical, and non-diagnostic.\\n\"\n",
    "                \"If some data is missing, mention it gently.\\n\\n\"\n",
    "                f\"USER DATA:\\n{context}\\n\\n\"\n",
    "                f\"USER QUESTION:\\n{demo_question}\\n\\n\"\n",
    "                \"Answer with:\\n\"\n",
    "                \"- 5 bullet recommendations\\n\"\n",
    "                \"- 1 short daily routine example\\n\"\n",
    "            )\n",
    "\n",
    "            current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "            resp = gemini.generate(prompt, response_language=current_lang)\n",
    "            text = resp.text.strip() if hasattr(resp, \"text\") else str(resp).strip()\n",
    "\n",
    "            return text, \"‚úÖ Ask AI demo output generated.\"\n",
    "\n",
    "        register_demo_hook(\n",
    "            domain=\"ask_ai\",\n",
    "            label=\"üí¨ Ask AI (General Chat)\",\n",
    "            generate_fn=_ask_ai_demo_generate\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ask_ai] ‚ö†Ô∏è Demo hook registration failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17d6a8",
   "metadata": {},
   "source": [
    "# üè¢ Global Recommendations (Action Center)\n",
    "\n",
    "This tab is the final synthesis layer of the whole platform.\n",
    "\n",
    "It does two things:\n",
    "\n",
    "## 1) General Recommendations\n",
    "Uses all saved domain data (baseline, MSK, eye, hydration, mental, etc.)\n",
    "to generate a single coherent preventive health report.\n",
    "\n",
    "## 2) Tasks & Reminders Generator\n",
    "Transforms the AI analysis into:\n",
    "- daily actionable tasks\n",
    "- scheduled reminders\n",
    "\n",
    "This makes the output operational (not just advice).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90c2cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Global Recommendations Tab ‚Äî Session Loader (FIXED)\n",
    "# =================================================\n",
    "\n",
    "def load_global_recommendations_state(store):\n",
    "    # SECTION 1 (AI recommendations output)\n",
    "    gen_domain = \"general_recommendations\"\n",
    "    gen_ai_file = f\"{gen_domain}_ai_output.json\"\n",
    "\n",
    "    raw_ai = store.load_json(gen_ai_file, [])\n",
    "    ai_list = raw_ai if isinstance(raw_ai, list) else []\n",
    "    latest_ai = ai_list[-1] if ai_list else {}\n",
    "    last_recs_text = latest_ai.get(\"ai_output\", \"\") if isinstance(latest_ai.get(\"ai_output\", \"\"), str) else \"\"\n",
    "\n",
    "    # SECTION 2 (Tasks & reminders stored as \"user_input\")\n",
    "    tasks_domain = \"tasks_reminders\"\n",
    "    tasks_user_file = f\"{tasks_domain}_user_input.json\"\n",
    "\n",
    "    raw_tasks = store.load_json(tasks_user_file, [])\n",
    "    tasks_list = raw_tasks if isinstance(raw_tasks, list) else []\n",
    "    latest_tasks = tasks_list[-1] if tasks_list else {}\n",
    "    saved_tasks_input = latest_tasks.get(\"user_input\", {}) if isinstance(latest_tasks.get(\"user_input\", {}), dict) else {}\n",
    "\n",
    "    last_tasks_text = saved_tasks_input.get(\"tasks_list\", \"\")\n",
    "    last_reminders_text = saved_tasks_input.get(\"reminders_list\", \"\")\n",
    "\n",
    "    return last_recs_text, last_tasks_text, last_reminders_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea901bb5",
   "metadata": {},
   "source": [
    "## Step 1 ‚Äî UI Layout\n",
    "\n",
    "This tab has two sections:\n",
    "\n",
    "### Section 1: General Recommendations\n",
    "- Displays full AI health analysis report\n",
    "\n",
    "### Section 2: Tasks & Reminders\n",
    "- Extracts daily tasks\n",
    "- Extracts scheduled reminders\n",
    "\n",
    "Both sections support saving into session history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7310f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Global Recommendations Tab ‚Äî UI Builder\n",
    "# =================================================\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_global_recommendations_ui(last_recs_text, last_tasks_text, last_reminders_text):\n",
    "\n",
    "    gr.Markdown(\"## üè¢ General Recommendations (Action Center)\")\n",
    "    gr.Markdown(\n",
    "        \"This tab synthesizes **preventive workplace health guidance** using \"\n",
    "        \"**all data entered across the platform**.\"\n",
    "    )\n",
    "\n",
    "    # --- SECTION 1 ---\n",
    "    with gr.Accordion(\"1) General Recommendations\", open=True):\n",
    "\n",
    "        rec_output = gr.Textbox(\n",
    "            label=\"AI Health Analysis\",\n",
    "            lines=14,\n",
    "            interactive=False,\n",
    "            value=last_recs_text,\n",
    "        )\n",
    "\n",
    "        rec_status = gr.Markdown(\"\")\n",
    "\n",
    "        with gr.Row():\n",
    "            gen_btn = gr.Button(\"Generate Recommendations\", variant=\"primary\")\n",
    "            save_report_btn = gr.Button(\"Save to Text File\")\n",
    "\n",
    "    # --- SECTION 2 ---\n",
    "    with gr.Accordion(\"2) Daily Tasks & Reminders\", open=True):\n",
    "\n",
    "        gr.Markdown(\"Convert your health analysis into a concrete action plan.\")\n",
    "\n",
    "        with gr.Row():\n",
    "            task_output = gr.Textbox(\n",
    "                label=\"Daily Action Tasks\",\n",
    "                lines=8,\n",
    "                interactive=False,\n",
    "                value=last_tasks_text\n",
    "            )\n",
    "\n",
    "            reminder_output = gr.Textbox(\n",
    "                label=\"Scheduled Reminders\",\n",
    "                lines=8,\n",
    "                interactive=False,\n",
    "                value=last_reminders_text\n",
    "            )\n",
    "\n",
    "        task_status = gr.Markdown(\"\")\n",
    "\n",
    "        with gr.Row():\n",
    "            gen_tasks_btn = gr.Button(\"Generate Tasks from Analysis\", variant=\"primary\")\n",
    "            save_tasks_btn = gr.Button(\"Save Tasks & Reminders\")\n",
    "\n",
    "    return {\n",
    "        \"rec_output\": rec_output,\n",
    "        \"rec_status\": rec_status,\n",
    "        \"gen_btn\": gen_btn,\n",
    "        \"save_report_btn\": save_report_btn,\n",
    "        \"task_output\": task_output,\n",
    "        \"reminder_output\": reminder_output,\n",
    "        \"task_status\": task_status,\n",
    "        \"gen_tasks_btn\": gen_tasks_btn,\n",
    "        \"save_tasks_btn\": save_tasks_btn,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872c608",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî AI Logic\n",
    "\n",
    "This tab uses two AI workflows:\n",
    "\n",
    "### A) General Recommendations Generator\n",
    "Builds context from all stored user data and generates a unified report.\n",
    "\n",
    "### B) Tasks & Reminders Generator\n",
    "Uses the report text to produce:\n",
    "- daily action tasks\n",
    "- scheduled reminders\n",
    "\n",
    "Then saves the outputs into session history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1b56eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Global Recommendations Tab ‚Äî AI + Saving Logic (RAW USER INPUT FIX)\n",
    "# =================================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def build_context_from_data_folder(store) -> str:\n",
    "    \"\"\"\n",
    "    Builds context ONLY from *_user_input.json files.\n",
    "    Uses the latest record in each file (list[-1][\"user_input\"]).\n",
    "    Excludes AI outputs completely.\n",
    "    \"\"\"\n",
    "\n",
    "    data_dir = Path(getattr(store, \"data_dir\", Path(\"data\")))\n",
    "    if not data_dir.exists():\n",
    "        return \"\"\n",
    "\n",
    "    # Only raw user input files\n",
    "    files = sorted(data_dir.glob(\"*_user_input.json\"))\n",
    "\n",
    "    context_chunks = []\n",
    "\n",
    "    for f in files:\n",
    "        domain = f.stem.replace(\"_user_input\", \"\")\n",
    "\n",
    "        try:\n",
    "            raw = json.loads(f.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # expected format: list of {\"timestamp\":..., \"user_input\": {...}}\n",
    "        if isinstance(raw, list) and raw:\n",
    "            last = raw[-1]\n",
    "            if isinstance(last, dict) and isinstance(last.get(\"user_input\"), dict):\n",
    "                user_data = last[\"user_input\"]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # fallback if stored as dict\n",
    "        elif isinstance(raw, dict):\n",
    "            user_data = raw.get(\"user_input\", raw)\n",
    "            if not isinstance(user_data, dict):\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Build readable context section\n",
    "        context_chunks.append(\n",
    "            f\"## {domain.upper()} USER INPUT\\n\"\n",
    "            + json.dumps(user_data, indent=2, ensure_ascii=False)\n",
    "        )\n",
    "\n",
    "    return \"\\n\\n\".join(context_chunks).strip()\n",
    "\n",
    "\n",
    "def generate_global_recommendations(store, gemini, lang_state):\n",
    "    context = build_context_from_data_folder(store)\n",
    "\n",
    "    if not context.strip():\n",
    "        return \"\", \"‚ö†Ô∏è No usable user input data found yet.\"\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a preventive workplace health reasoning assistant.\\n\\n\"\n",
    "        \"TASK:\\n\"\n",
    "        \"Generate a cohesive summary of risks and actionable recommendations.\\n\"\n",
    "        \"Use ONLY the provided user input data.\\n\\n\"\n",
    "        \"RULES:\\n\"\n",
    "        \"- Non-diagnostic guidance only\\n\"\n",
    "        \"- Ergonomics + routines + hydration + sleep + stress + eye strain\\n\"\n",
    "        \"- Mention missing areas gently\\n\"\n",
    "        \"- Provide practical step-by-step recommendations\\n\\n\"\n",
    "        f\"--- RAW USER DATA ---\\n{context}\"\n",
    "    )\n",
    "\n",
    "    current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    try:\n",
    "        response = gemini.generate(prompt, response_language=current_lang)\n",
    "        text = response.text.strip() if response and hasattr(response, \"text\") else \"\"\n",
    "    except Exception as e:\n",
    "        return \"\", f\"‚ö†Ô∏è AI generation failed: {e}\"\n",
    "\n",
    "    if not text.strip():\n",
    "        return \"\", \"‚ö†Ô∏è AI returned empty recommendations.\"\n",
    "\n",
    "    # -------------------------\n",
    "    # Save AI output (APPEND)\n",
    "    # -------------------------\n",
    "    GENERAL_REC_FILE = \"general_recommendations_ai_output.json\"\n",
    "\n",
    "    try:\n",
    "        record = {\n",
    "            \"timestamp\": _now(),\n",
    "            \"ai_output\": text.strip()\n",
    "        }\n",
    "\n",
    "        existing = store.load_json(GENERAL_REC_FILE, [])\n",
    "        if not isinstance(existing, list):\n",
    "            existing = []\n",
    "\n",
    "        existing.append(record)\n",
    "\n",
    "        _save_json_best_effort(store, GENERAL_REC_FILE, existing)\n",
    "\n",
    "        # optional summary update\n",
    "        try:\n",
    "            updater = globals().get(\"update_domain_summary\")\n",
    "            if updater:\n",
    "                updater(store, \"general_recommendations\", text[:200])\n",
    "        except Exception as e:\n",
    "            print(f\"[general_recommendations] ‚ö†Ô∏è update_domain_summary failed: {e}\")\n",
    "\n",
    "        return text, f\"‚úÖ Recommendations generated and saved -> `{_debug_store_path(store, GENERAL_REC_FILE)}`\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return text, f\"‚ö†Ô∏è Generated but failed to save: {e}\"\n",
    "\n",
    "\n",
    "def generate_tasks_and_reminders_from_analysis(gemini, lang_state, analysis_text: str):\n",
    "    if not analysis_text.strip():\n",
    "        return \"\", \"\", \"‚ö†Ô∏è Please generate the Health Analysis in Section 1 first.\"\n",
    "\n",
    "    prompt = (\n",
    "        \"Based on the following health analysis, create two distinct lists:\\n\"\n",
    "        \"1. DAILY ACTION TASKS: Specific physical actions the user should do today (e.g., 'Adjust chair height').\\n\"\n",
    "        \"2. SCHEDULED REMINDERS: Time-based triggers (e.g., 'Every 20 minutes: Look 20 feet away').\\n\"\n",
    "        \"Format the response clearly with two headers: [TASKS] and [REMINDERS].\\n\\n\"\n",
    "        f\"ANALYSIS:\\n{analysis_text}\"\n",
    "    )\n",
    "\n",
    "    current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    try:\n",
    "        response = gemini.generate(prompt, response_language=current_lang)\n",
    "        raw_text = response.text if hasattr(response, \"text\") else \"\"\n",
    "\n",
    "        tasks = \"\"\n",
    "        reminders = \"\"\n",
    "\n",
    "        if \"[TASKS]\" in raw_text and \"[REMINDERS]\" in raw_text:\n",
    "            parts = raw_text.split(\"[REMINDERS]\")\n",
    "            tasks = parts[0].replace(\"[TASKS]\", \"\").strip()\n",
    "            reminders = parts[1].strip()\n",
    "        else:\n",
    "            tasks = raw_text.strip()\n",
    "\n",
    "        return tasks, reminders, \"‚úÖ Tasks and Reminders generated.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"\", \"\", f\"‚ö†Ô∏è Failed to generate tasks: {e}\"\n",
    "\n",
    "\n",
    "def save_tasks_and_reminders(store, t_text: str, r_text: str):\n",
    "    if not t_text.strip() and not r_text.strip():\n",
    "        return \"‚ö†Ô∏è Nothing to save.\"\n",
    "\n",
    "    TASKS_REMINDERS_FILE = \"tasks_reminders_list.json\"\n",
    "\n",
    "    payload = {\n",
    "        \"timestamp\": _now(),\n",
    "        \"tasks\": t_text.strip(),\n",
    "        \"reminders\": r_text.strip(),\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        existing = store.load_json(TASKS_REMINDERS_FILE, [])\n",
    "        if not isinstance(existing, list):\n",
    "            existing = []\n",
    "\n",
    "        existing.append(payload)\n",
    "\n",
    "        _save_json_best_effort(store, TASKS_REMINDERS_FILE, existing)\n",
    "\n",
    "        return f\"üíæ Tasks & Reminders saved -> `{_debug_store_path(store, TASKS_REMINDERS_FILE)}`\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Save failed: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "088c3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## BASELINE USER INPUT\n",
      "{\n",
      "  \"height\": 171.0,\n",
      "  \"weight\": 91.0,\n",
      "  \"bp_systolic\": 130,\n",
      "  \"bp_diastolic\": 90,\n",
      "  \"rhr\": 75,\n",
      "  \"body_fat\": 30.0,\n",
      "  \"waist_cm\": 0.0,\n",
      "  \"activity_level\": \"Moderately active\",\n",
      "  \"notes\": \"\"\n",
      "}\n",
      "\n",
      "## EYE USER INPUT\n",
      "{\n",
      "  \"strain_level\": 6,\n",
      "  \"session_length\": \"4+ hours\",\n",
      "  \"symptoms\": [\n",
      "    \"Eye Twitching\",\n",
      "    \"Headache (behind eyes)\",\n",
      "    \"Watery Eyes\"\n",
      "  ],\n",
      "  \"lighting\": \"Natural Light\",\n",
      "  \"screen_brightness\": \"Balanced\",\n",
      "  \"glare\": false,\n",
      "  \"distance_check\": true,\n",
      "  \"correction\": \"None (Naked Eye)\",\n",
      "  \"rule_20_20_20\": \"Occasionally\",\n",
      "  \"used_drops\": false,\n",
      "  \"notes\": \"\"\n",
      "}\n",
      "\n",
      "## GENERAL_RECOMMENDATIONS USER INPUT\n",
      "{\n",
      "  \"context_used\": \"data_folder\"\n",
      "}\n",
      "\n",
      "## HYDRATION USER INPUT\n",
      "{\n",
      "  \"water_intake\": 6,\n",
      "  \"caffeine_intake\": 3.0,\n",
      "  \"bottle_on_desk\": false,\n",
      "  \"sugary_drinks\": 3.0,\n",
      "  \"urine_color\": \"Yellow (Okay)\",\n",
      "  \"thirst_level\": \"Not Thirsty\",\n",
      "  \"symptoms\": [],\n",
      "  \"notes\": \"\"\n",
      "}\n",
      "\n",
      "## LONGITUDINAL USER INPUT\n",
      "{\n",
      "  \"notes\": \"\",\n",
      "  \"hb\": 15,\n",
      "  \"wbc\": 10000,\n",
      "  \"platelets\": null,\n",
      "  \"glucose\": 100,\n",
      "  \"hba1c\": 5,\n",
      "  \"cholesterol\": 200,\n",
      "  \"triglycerides\": 160,\n",
      "  \"vit_d\": 0,\n",
      "  \"vit_b12\": 0,\n",
      "  \"tsh\": 0,\n",
      "  \"custom_name\": \"\",\n",
      "  \"custom_value\": 0,\n",
      "  \"custom_unit\": \"\"\n",
      "}\n",
      "\n",
      "## MENTAL USER INPUT\n",
      "{\n",
      "  \"stress\": 7,\n",
      "  \"mood\": \"Calm\",\n",
      "  \"energy\": \"Brain Fog/Sluggish\",\n",
      "  \"focus_quality\": \"Fragmented / Multitasking\",\n",
      "  \"workload\": \"Heavy\",\n",
      "  \"distractions\": [\n",
      "    \"External (Noise/People)\"\n",
      "  ],\n",
      "  \"detachment\": true,\n",
      "  \"overwhelm\": false,\n",
      "  \"social\": \"Text/Chat only\",\n",
      "  \"sleep_quality\": \"Restorative\",\n",
      "  \"coping\": [\n",
      "    \"Caffeine/Sugar\",\n",
      "    \"Procrastination\"\n",
      "  ],\n",
      "  \"notes\": \"\"\n",
      "}\n",
      "\n",
      "## MSK USER INPUT\n",
      "{\n",
      "  \"pain_level\": 4,\n",
      "  \"onset_timing\": \"End of Workday\",\n",
      "  \"focus_area\": [\n",
      "    \"Shoulders/Upper Back\",\n",
      "    \"Neck\"\n",
      "  ],\n",
      "  \"pain_nature\": \"Stiffness/Tightness\",\n",
      "  \"neck_rom\": \"Limited (Stiff)\",\n",
      "  \"seated_duration\": \"1 hour\",\n",
      "  \"morning_stiffness\": true,\n",
      "  \"good_posture\": false,\n",
      "  \"triggers\": [\n",
      "    \"Stress/Tension\",\n",
      "    \"Long Typing Sessions\",\n",
      "    \"Cold Temperature\"\n",
      "  ],\n",
      "  \"relief_methods\": [\n",
      "    \"Stretching\"\n",
      "  ],\n",
      "  \"impact_work\": true,\n",
      "  \"impact_sleep\": false,\n",
      "  \"notes\": \"\"\n",
      "}\n",
      "\n",
      "## PRODUCTIVITY USER INPUT\n",
      "{\n",
      "  \"focus_quality\": 5,\n",
      "  \"deep_work\": 0.0,\n",
      "  \"flow_state\": true,\n",
      "  \"satisfaction\": false,\n",
      "  \"health_tax\": 4,\n",
      "  \"blocker\": \"Eye Fatigue\",\n",
      "  \"peak_energy\": \"Late Morning\",\n",
      "  \"slump_severity\": \"Mild dip\",\n",
      "  \"top_distraction\": \"Colleagues/Meetings\",\n",
      "  \"context_switching\": \"High (Multitasking)\",\n",
      "  \"methods\": [],\n",
      "  \"notes\": \"\"\n",
      "}\n",
      "\n",
      "## RECOVERY_SLEEP USER INPUT\n",
      "{\n",
      "  \"well_rested\": false,\n",
      "  \"sleep_hours\": \"5-7 hours\",\n",
      "  \"screen_cutoff\": false,\n",
      "  \"blue_light_filter\": false,\n",
      "  \"evening_movement\": false,\n",
      "  \"stress_level\": 6,\n",
      "  \"room_comfort\": \"Noisy\"\n",
      "}\n",
      "\n",
      "## TASKS_REMINDERS USER INPUT\n",
      "{\n",
      "  \"tasks_list\": \"*   Stand up and stretch your shoulders and upper back.\\n*   Adjust your chair height for better posture.\\n*   Position your monitor to reduce neck strain.\\n*   Adjust your workspace lighting to minimize glare.\\n*   Adjust your screen brightness to match ambient light.\\n*   Keep a water bottle at your desk and sip from it.\\n*   Take 30 minutes for moderate physical activity today.\\n*   Perform a self-assessment of your workstation ergonomics.\",\n",
      "  \"reminders_list\": \"*   Every 30-60 minutes: Stand up, stretch, and move around your workspace.\\n*   Every 20 minutes: Look at something 20 feet away for at least 20 seconds (20-20-20 rule).\\n*   Throughout the day: Sip water consistently to stay hydrated.\\n*   Periodically: Check for signs of fatigue, dry mouth, or headaches, and increase water intake if needed.\"\n",
      "}\n",
      "\n",
      "## WORKSPACE USER INPUT\n",
      "{\n",
      "  \"good_posture\": true,\n",
      "  \"breaks\": \"No breaks\",\n",
      "  \"eat_at_desk\": true,\n",
      "  \"input_device\": \"Standard Mouse\",\n",
      "  \"keyboard_type\": \"Laptop Keyboard\",\n",
      "  \"wrist_support\": \"No\",\n",
      "  \"armrests\": \"Level with desk\",\n",
      "  \"lumbar_support\": false,\n",
      "  \"monitor_height\": \"Below Eye Level (Looking Down)\",\n",
      "  \"feet_position\": \"Flat on floor\",\n",
      "  \"noise_level\": \"Distracting/Loud\",\n",
      "  \"temperature\": \"Cold\",\n",
      "  \"clutter\": \"Cluttered\",\n",
      "  \"notes\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# create store globally\n",
    "store = LocalStore(DATA_DIR)\n",
    "print(build_context_from_data_folder(store))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffb2cc4",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äî Wiring the Buttons\n",
    "\n",
    "This connects:\n",
    "- Generate Recommendations ‚Üí fills analysis output\n",
    "- Generate Tasks ‚Üí uses analysis output as input\n",
    "- Save Tasks ‚Üí saves tasks + reminders into session history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e3a3199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Global Recommendations Tab ‚Äî Event Wiring\n",
    "# =================================================\n",
    "\n",
    "def connect_global_recommendations_events(store, gemini, lang_state, ui):\n",
    "\n",
    "    ui[\"gen_btn\"].click(\n",
    "        fn=lambda: generate_global_recommendations(store, gemini, lang_state),\n",
    "        outputs=[ui[\"rec_output\"], ui[\"rec_status\"]],\n",
    "    )\n",
    "\n",
    "    ui[\"gen_tasks_btn\"].click(\n",
    "        fn=lambda analysis_text: generate_tasks_and_reminders_from_analysis(gemini, lang_state, analysis_text),\n",
    "        inputs=[ui[\"rec_output\"]],\n",
    "        outputs=[ui[\"task_output\"], ui[\"reminder_output\"], ui[\"task_status\"]],\n",
    "    )\n",
    "\n",
    "    ui[\"save_tasks_btn\"].click(\n",
    "        fn=lambda t_text, r_text: save_tasks_and_reminders(store, t_text, r_text),\n",
    "        inputs=[ui[\"task_output\"], ui[\"reminder_output\"]],\n",
    "        outputs=[ui[\"task_status\"]],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934688e",
   "metadata": {},
   "source": [
    "## Final Assembly ‚Äî Global Recommendations Tab\n",
    "\n",
    "This final function:\n",
    "\n",
    "1. Loads latest saved outputs  \n",
    "2. Builds the UI  \n",
    "3. Connects AI logic + button wiring  \n",
    "\n",
    "So the tab becomes fully modular and hackathon-clean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "08e6a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# Global Recommendations Tab ‚Äî Final Builder\n",
    "# =================================================\n",
    "\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_global_recommendations_tab(\n",
    "    store,\n",
    "    gemini,\n",
    "    lang_state,\n",
    "    locales_dir: Optional[Path] = None,\n",
    "):\n",
    "\n",
    "    last_recs_text, last_tasks_text, last_reminders_text = load_global_recommendations_state(store)\n",
    "\n",
    "    ui = build_global_recommendations_ui(\n",
    "        last_recs_text=last_recs_text,\n",
    "        last_tasks_text=last_tasks_text,\n",
    "        last_reminders_text=last_reminders_text\n",
    "    )\n",
    "\n",
    "    # ============================\n",
    "    # üßπ Data Maintenance Tools\n",
    "    # ============================\n",
    "    with gr.Accordion(\"üßπ Data Maintenance Tools\", open=False):\n",
    "        keep_limit = gr.Number(value=5, label=\"Keep last N records\", precision=0)\n",
    "        refresh_btn = gr.Button(\"üîÑ Refresh / Fix All JSON Files\", variant=\"secondary\")\n",
    "        refresh_status = gr.Markdown(\"\")\n",
    "\n",
    "    refresh_btn.click(\n",
    "        fn=lambda n: refresh_all_json_files(store, keep_last=int(n)),\n",
    "        inputs=[keep_limit],\n",
    "        outputs=[refresh_status]\n",
    "    )\n",
    "\n",
    "    # ============================\n",
    "    # Main logic wiring\n",
    "    # ============================\n",
    "    connect_global_recommendations_events(\n",
    "        store=store,\n",
    "        gemini=gemini,\n",
    "        lang_state=lang_state,\n",
    "        ui=ui\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bc1d4",
   "metadata": {},
   "source": [
    "Checklist Tab\n",
    "The Checklist tab provides a list of healthy tasks or habits (like \"stretch every hour\" or \"drink water\"). The user can mark items as done. When submitted, it can save the completion status and possibly update the global context summary (indicating the user has completed certain healthy actions). This helps ensure that actionable tasks are tracked and encourages consistent habits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f16eec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Utilities\n",
    "# =========================================================\n",
    "def _now():\n",
    "    return datetime.now().isoformat()\n",
    "\n",
    "\n",
    "def _atomic_write(path: Path, data: Dict[str, Any]):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(\".tmp\")\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "    tmp.replace(path)\n",
    "\n",
    "\n",
    "def _safe_json_extract(text: str) -> Dict[str, Any]:\n",
    "    if not text:\n",
    "        return {}\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        start = text.index(\"{\")\n",
    "        end = text.rindex(\"}\") + 1\n",
    "        return json.loads(text[start:end])\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def _sort_items(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    return sorted(\n",
    "        items,\n",
    "        key=lambda x: (\n",
    "            not x.get(\"priority\", False),     # ‚≠ê first\n",
    "            x.get(\"type\") != \"repetitive\",    # repetitive before non-repetitive\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def _items_to_table(items: List[Dict[str, Any]]) -> List[List[Any]]:\n",
    "    items = _sort_items(items)\n",
    "    return [\n",
    "        [\n",
    "            it.get(\"priority\", False),\n",
    "            it.get(\"completed_today\", False),\n",
    "            it.get(\"type\", \"\"),\n",
    "            it.get(\"item\", \"\"),\n",
    "        ]\n",
    "        for it in items\n",
    "    ]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Tab Builder (Notebook-safe)\n",
    "# =========================================================\n",
    "def build_checklist_tab(store, gemini, lang_state, locales_dir):\n",
    "\n",
    "    # -------------------------\n",
    "    # LOCAL CONSTANTS (SAFE)\n",
    "    # -------------------------\n",
    "    local_domain = \"checklist\"\n",
    "    data_path = Path(\"data\") / f\"{local_domain}.json\"\n",
    "    summary_key = \"global_context_summary\"\n",
    "    tasks_reminders_file = \"tasks_reminders_list.json\"\n",
    "\n",
    "    def _load_raw_checklist() -> List[str]:\n",
    "        \"\"\"\n",
    "        Load checklist tasks from data/tasks_reminders_list.json\n",
    "        Uses the latest entry only.\n",
    "        \"\"\"\n",
    "        data = store.load_json(tasks_reminders_file, []) or []\n",
    "\n",
    "        if not isinstance(data, list) or not data:\n",
    "            return []\n",
    "\n",
    "        latest = data[-1]\n",
    "        tasks_text = latest.get(\"tasks\", \"\")\n",
    "\n",
    "        if not tasks_text:\n",
    "            return []\n",
    "\n",
    "        return [\n",
    "            line.lstrip(\"*\").strip()\n",
    "            for line in tasks_text.splitlines()\n",
    "            if line.strip()\n",
    "        ]\n",
    "\n",
    "    # -------------------------\n",
    "    # Load saved data\n",
    "    # -------------------------\n",
    "    saved = store.load_json(f\"{local_domain}.json\", {}) or {}\n",
    "    checklist_items = saved.get(\"items\", [])\n",
    "\n",
    "    summary_obj = store.load_json(f\"{summary_key}.json\", {}) or {}\n",
    "    summary_time = summary_obj.get(\"generated_at\")\n",
    "    summary_text = summary_obj.get(\"summary\", \"\")\n",
    "\n",
    "    raw_checklist = _load_raw_checklist()\n",
    "\n",
    "    # -------------------------\n",
    "    # UI Header\n",
    "    # -------------------------\n",
    "    gr.Markdown(\"### ‚úÖ Daily Checklist\")\n",
    "    gr.Markdown(\"Build a practical, prioritized checklist from your approved tasks.\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 1) Source checklist\n",
    "    # =====================================================\n",
    "    with gr.Accordion(\"1) Source checklist (from tasks & reminders)\", open=False):\n",
    "        gr.Markdown(\n",
    "            \"\\n\".join(f\"- {x}\" for x in raw_checklist)\n",
    "            if raw_checklist\n",
    "            else \"_No tasks available yet._\"\n",
    "        )\n",
    "\n",
    "    # =====================================================\n",
    "    # 2) Data summary\n",
    "    # =====================================================\n",
    "    with gr.Accordion(\"2) Data summary (used for prioritization)\", open=True):\n",
    "        summary_status = gr.Markdown(\n",
    "            f\"Using summary generated on **{summary_time}**\"\n",
    "            if summary_time\n",
    "            else \"_No summary generated yet._\"\n",
    "        )\n",
    "        btn_summary = gr.Button(\"Generate / Refresh data summary\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 3) Optional user context\n",
    "    # =====================================================\n",
    "    user_context = gr.Textbox(\n",
    "        label=\"Optional context for today\",\n",
    "        placeholder=\"e.g. very busy day, low energy, back pain today\",\n",
    "        lines=2,\n",
    "    )\n",
    "\n",
    "    # =====================================================\n",
    "    # 4) Generate checklist\n",
    "    # =====================================================\n",
    "    btn_generate = gr.Button(\"Generate my checklist\")\n",
    "\n",
    "    checklist_state = gr.State(checklist_items)\n",
    "\n",
    "    checklist_df = gr.Dataframe(\n",
    "        headers=[\"‚≠ê\", \"Done\", \"Type\", \"Item\"],\n",
    "        datatype=[\"bool\", \"bool\", \"str\", \"str\"],\n",
    "        interactive=True,\n",
    "        row_count=(0, \"dynamic\"),\n",
    "    )\n",
    "\n",
    "    btn_delete = gr.Button(\"üóëÔ∏è Delete selected row\")\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    # =====================================================\n",
    "    # Logic\n",
    "    # =====================================================\n",
    "    def generate_summary():\n",
    "        prompt = \"\"\"\n",
    "Summarize all saved workplace health data.\n",
    "\n",
    "Rules:\n",
    "- Patterns only\n",
    "- No advice\n",
    "- No diagnosis\n",
    "- JSON only\n",
    "\n",
    "FORMAT:\n",
    "{ \"summary\": \"text\" }\n",
    "\"\"\"\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        resp = gemini.generate(prompt, response_language=current_lang)\n",
    "        data = _safe_json_extract(resp.text if hasattr(resp, \"text\") else \"\")\n",
    "\n",
    "        if \"summary\" not in data:\n",
    "            return \"‚ö†Ô∏è Failed to generate summary.\"\n",
    "\n",
    "        payload = {\n",
    "            \"generated_at\": _now(),\n",
    "            \"summary\": data[\"summary\"],\n",
    "        }\n",
    "\n",
    "        store.save_json(f\"{summary_key}.json\", payload)\n",
    "        return f\"‚úÖ Summary generated on {payload['generated_at']}\"\n",
    "\n",
    "    def generate_checklist(user_ctx):\n",
    "        if not raw_checklist:\n",
    "            return [], \"‚ö†Ô∏è No source checklist.\"\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        # -------------------------\n",
    "        # Classification\n",
    "        # -------------------------\n",
    "        class_prompt = f\"\"\"\n",
    "Classify checklist items into:\n",
    "- non_repetitive\n",
    "- repetitive\n",
    "\n",
    "Return JSON only.\n",
    "\n",
    "FORMAT:\n",
    "{{\"non_repetitive\":[], \"repetitive\":[]}}\n",
    "\n",
    "\n",
    "ITEMS:\n",
    "{json.dumps(raw_checklist, ensure_ascii=False)}\n",
    "\"\"\"\n",
    "\n",
    "        classified = _safe_json_extract(\n",
    "            gemini.generate(class_prompt, response_language=current_lang).text\n",
    "        )\n",
    "\n",
    "        items: List[Dict[str, Any]] = []\n",
    "\n",
    "        for it in classified.get(\"non_repetitive\", []):\n",
    "            items.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"item\": it,\n",
    "                \"type\": \"non_repetitive\",\n",
    "                \"priority\": False,\n",
    "                \"completed_today\": False,\n",
    "            })\n",
    "\n",
    "        for it in classified.get(\"repetitive\", []):\n",
    "            items.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"item\": it,\n",
    "                \"type\": \"repetitive\",\n",
    "                \"priority\": False,\n",
    "                \"completed_today\": False,\n",
    "            })\n",
    "\n",
    "        # -------------------------\n",
    "        # ‚≠ê Prioritization\n",
    "        # -------------------------\n",
    "        rep_items = [i[\"item\"] for i in items if i[\"type\"] == \"repetitive\"]\n",
    "\n",
    "        if rep_items:\n",
    "            pr_prompt = f\"\"\"\n",
    "You are assisting a workplace health platform.\n",
    "\n",
    "TASK:\n",
    "From the list of repetitive habits below, select a SMALL daily focus set.\n",
    "\n",
    "STRICT RULES:\n",
    "- Select ONLY from the provided habits.\n",
    "- Do NOT rewrite or add habits.\n",
    "- Prefer low-effort, high-impact actions.\n",
    "- Max 5 items.\n",
    "- JSON only.\n",
    "\n",
    "FORMAT:\n",
    "{{\n",
    "  \"prioritized_habits\": [\n",
    "    {{ \"item\": \"\", \"reason\": \"\" }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "REPETITIVE HABITS:\n",
    "{json.dumps(rep_items, indent=2, ensure_ascii=False)}\n",
    "\n",
    "OPTIONAL CONTEXT SUMMARY:\n",
    "{summary_text}\n",
    "\n",
    "USER CONTEXT:\n",
    "{user_ctx}\n",
    "\"\"\"\n",
    "            pr_data = _safe_json_extract(\n",
    "                gemini.generate(pr_prompt, response_language=current_lang).text\n",
    "            )\n",
    "\n",
    "            starred = {\n",
    "                x[\"item\"]\n",
    "                for x in pr_data.get(\"prioritized_habits\", [])\n",
    "                if isinstance(x, dict) and \"item\" in x\n",
    "            }\n",
    "\n",
    "            for it in items:\n",
    "                if it[\"item\"] in starred:\n",
    "                    it[\"priority\"] = True\n",
    "\n",
    "        items = _sort_items(items)\n",
    "        _atomic_write(data_path, {\"updated_at\": _now(), \"items\": items})\n",
    "\n",
    "        return _items_to_table(items), \"‚úÖ Checklist generated with priorities.\"\n",
    "\n",
    "    def update_from_table(rows):\n",
    "        if rows is None:\n",
    "            return checklist_state.value\n",
    "\n",
    "        rows = rows.values.tolist()\n",
    "        items = checklist_state.value\n",
    "\n",
    "        if len(rows) != len(items):\n",
    "            return items\n",
    "\n",
    "        for row, item in zip(rows, items):\n",
    "            item[\"priority\"] = bool(row[0])\n",
    "            item[\"completed_today\"] = bool(row[1])\n",
    "\n",
    "        items = _sort_items(items)\n",
    "        _atomic_write(data_path, {\"updated_at\": _now(), \"items\": items})\n",
    "        return items\n",
    "\n",
    "    def delete_selected(rows):\n",
    "        if rows is None:\n",
    "            return checklist_state.value, \"‚ö†Ô∏è No selection.\"\n",
    "\n",
    "        rows = rows.values.tolist()\n",
    "        if not rows:\n",
    "            return checklist_state.value, \"‚ö†Ô∏è No selection.\"\n",
    "\n",
    "        items = checklist_state.value\n",
    "        items.pop(-1)  # safe fallback deletion\n",
    "\n",
    "        items = _sort_items(items)\n",
    "        _atomic_write(data_path, {\"updated_at\": _now(), \"items\": items})\n",
    "        return items, \"üóëÔ∏è Item deleted.\"\n",
    "\n",
    "    # =====================================================\n",
    "    # Wiring\n",
    "    # =====================================================\n",
    "    btn_summary.click(generate_summary, outputs=[summary_status])\n",
    "\n",
    "    btn_generate.click(\n",
    "        generate_checklist,\n",
    "        inputs=[user_context],\n",
    "        outputs=[checklist_df, status],\n",
    "    )\n",
    "\n",
    "    checklist_df.change(\n",
    "        update_from_table,\n",
    "        inputs=[checklist_df],\n",
    "        outputs=[checklist_state],\n",
    "    )\n",
    "\n",
    "    btn_delete.click(\n",
    "        delete_selected,\n",
    "        inputs=[checklist_df],\n",
    "        outputs=[checklist_state, status],\n",
    "    )\n",
    "\n",
    "    checklist_state.change(\n",
    "        lambda items: _items_to_table(items),\n",
    "        inputs=[checklist_state],\n",
    "        outputs=[checklist_df],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79701ca",
   "metadata": {},
   "source": [
    "Reminders Tab\n",
    "The Reminders tab allows the scheduling of recurring health reminders (for example, a reminder to stand up and stretch every 60 minutes). The user can set the interval or schedule (via sliders or checkboxes) and the app will save this schedule (though actual reminder notifications might require external integration). This tab mainly records the reminder preferences and confirms they are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4eff8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Tab Builder (Notebook-safe)\n",
    "# =========================================================\n",
    "def build_reminders_tab(store, gemini, lang_state, locales_dir):\n",
    "\n",
    "    # -------------------------\n",
    "    # LOCAL CONSTANTS (SAFE)\n",
    "    # -------------------------\n",
    "    local_domain = \"reminders\"\n",
    "    tasks_reminders_file = \"tasks_reminders_list.json\"\n",
    "    google_cal_import_url = \"https://calendar.google.com/calendar/u/0/r/settings/import\"\n",
    "\n",
    "    def _safe_json_extract(text: str) -> Dict[str, Any]:\n",
    "        if not text:\n",
    "            return {}\n",
    "        text = text.strip()\n",
    "        try:\n",
    "            start = text.index(\"{\")\n",
    "            end = text.rindex(\"}\") + 1\n",
    "            return json.loads(text[start:end])\n",
    "        except Exception:\n",
    "            return {}\n",
    "\n",
    "    def _load_raw_reminders() -> List[str]:\n",
    "        data = store.load_json(tasks_reminders_file, []) or []\n",
    "\n",
    "        if not isinstance(data, list) or not data:\n",
    "            return []\n",
    "\n",
    "        latest = data[-1]\n",
    "        reminders_text = latest.get(\"reminders\", \"\")\n",
    "\n",
    "        if not reminders_text:\n",
    "            return []\n",
    "\n",
    "        return [\n",
    "            line.lstrip(\"*\").strip()\n",
    "            for line in reminders_text.splitlines()\n",
    "            if line.strip()\n",
    "        ]\n",
    "\n",
    "    def _load_schedule():\n",
    "        path = Path(\"data\") / \"reminder_schedule.json\"\n",
    "        if not path.exists():\n",
    "            return None\n",
    "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    def _schedule_to_rows(schedule_json):\n",
    "        if not schedule_json:\n",
    "            return []\n",
    "        rows = []\n",
    "        for s in schedule_json.get(\"schedule\", []):\n",
    "            reminders = \" + \".join(\n",
    "                r.get(\"text\", \"\") for r in s.get(\"combined_reminders\", [])\n",
    "            )\n",
    "            rows.append([\n",
    "                s.get(\"time\", \"\"),\n",
    "                \", \".join(s.get(\"days\", [])),\n",
    "                reminders\n",
    "            ])\n",
    "        return rows\n",
    "\n",
    "    # =====================================================\n",
    "    # UI\n",
    "    # =====================================================\n",
    "    gr.Markdown(\"### ‚è∞ Smart Reminders\")\n",
    "    gr.Markdown(\"Plan low-noise, merged workplace reminders based on your tasks and habits.\")\n",
    "\n",
    "    raw_reminders = _load_raw_reminders()\n",
    "\n",
    "    reminder_df = gr.Dataframe(\n",
    "        headers=[\"Keep\", \"Reminder\"],\n",
    "        datatype=[\"bool\", \"str\"],\n",
    "        value=[[True, r] for r in raw_reminders],\n",
    "        interactive=True,\n",
    "        row_count=(0, \"dynamic\"),\n",
    "        label=\"Imported reminder candidates\",\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"Uncheck any reminder you do not want to include. You are always in control.\")\n",
    "\n",
    "    gr.Markdown(\"### üïí Work Schedule\")\n",
    "\n",
    "    work_days = gr.CheckboxGroup(\n",
    "        choices=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n",
    "        value=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\"],\n",
    "        label=\"Work days\",\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        start_time = gr.Textbox(label=\"Work start time\", value=\"08:00\")\n",
    "        end_time = gr.Textbox(label=\"Work end time\", value=\"16:00\")\n",
    "\n",
    "    merge_window = gr.Slider(\n",
    "        minimum=5,\n",
    "        maximum=30,\n",
    "        step=5,\n",
    "        value=10,\n",
    "        label=\"Merge window (¬± minutes)\",\n",
    "    )\n",
    "\n",
    "    btn_generate = gr.Button(\"Generate smart reminder schedule\")\n",
    "    status = gr.Markdown(\"\")\n",
    "\n",
    "    def generate_schedule(df, days, start, end, window):\n",
    "        if df is None:\n",
    "            return \"‚ö†Ô∏è No reminders available.\", []\n",
    "\n",
    "        rows = df.values.tolist()\n",
    "        selected = [r[1] for r in rows if r[0] is True]\n",
    "\n",
    "        if not selected:\n",
    "            return \"‚ö†Ô∏è No reminders selected.\", []\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are assisting a workplace health platform.\n",
    "\n",
    "TASK:\n",
    "Create a merged, low-noise reminder schedule for a desk-based workday.\n",
    "\n",
    "STRICT OUTPUT RULES:\n",
    "- Return JSON ONLY\n",
    "- Do NOT include explanations, markdown, or text outside JSON\n",
    "- Do NOT include code fences\n",
    "\n",
    "REQUIRED FORMAT:\n",
    "{{\n",
    "  \"schedule\": [\n",
    "    {{\n",
    "      \"time\": \"HH:MM\",\n",
    "      \"days\": [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\"],\n",
    "      \"combined_reminders\": [\n",
    "        {{ \"text\": \"reminder text\" }}\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "REMINDERS:\n",
    "{json.dumps(selected, indent=2, ensure_ascii=False)}\n",
    "\n",
    "WORK SCHEDULE:\n",
    "Days: {days}\n",
    "Start: {start}\n",
    "End: {end}\n",
    "\n",
    "MERGE WINDOW:\n",
    "¬±{window} minutes\n",
    "\"\"\"\n",
    "\n",
    "        current_lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "        resp = gemini.generate(prompt, response_language=current_lang)\n",
    "        data = _safe_json_extract(resp.text if hasattr(resp, \"text\") else \"\")\n",
    "\n",
    "        if not data or \"schedule\" not in data:\n",
    "            return \"‚ö†Ô∏è Failed to generate reminder schedule (invalid model output).\", []\n",
    "\n",
    "        store.save_json(\"reminder_schedule.json\", data)\n",
    "        return \"‚úÖ Reminder schedule generated and saved.\", _schedule_to_rows(data)\n",
    "\n",
    "    gr.Markdown(\"### üìÖ Reminder Schedule Preview\")\n",
    "\n",
    "    initial_data = _load_schedule()\n",
    "    initial_rows = _schedule_to_rows(initial_data)\n",
    "\n",
    "    schedule_view = gr.Dataframe(\n",
    "        headers=[\"Time\", \"Days\", \"Reminders\"],\n",
    "        datatype=[\"str\", \"str\", \"str\"],\n",
    "        value=initial_rows,\n",
    "        interactive=False,\n",
    "        row_count=(0, \"dynamic\"),\n",
    "    )\n",
    "\n",
    "    status_view = gr.Markdown(\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        btn_run = gr.Button(\"‚ñ∂Ô∏è Run reminders in app (demo)\")\n",
    "        btn_export = gr.Button(\"üìÖ Export as calendar (.ics)\")\n",
    "        btn_google = gr.Button(\"üìÜ Send to Google Calendar\")\n",
    "\n",
    "    def run_reminders_demo():\n",
    "        data = _load_schedule()\n",
    "        if not data:\n",
    "            return \"‚ö†Ô∏è No schedule to run.\"\n",
    "\n",
    "        schedule = data.get(\"schedule\", [])\n",
    "\n",
    "        def reminder_loop():\n",
    "            fired = set()\n",
    "            while True:\n",
    "                now = datetime.now()\n",
    "                now_str = now.strftime(\"%H:%M\")\n",
    "                for s in schedule:\n",
    "                    if s.get(\"time\") == now_str and now_str not in fired:\n",
    "                        text = \" | \".join(\n",
    "                            r.get(\"text\", \"\") for r in s.get(\"combined_reminders\", [])\n",
    "                        )\n",
    "                        print(f\"‚è∞ REMINDER: {text}\")\n",
    "                        fired.add(now_str)\n",
    "                time.sleep(30)\n",
    "\n",
    "        threading.Thread(target=reminder_loop, daemon=True).start()\n",
    "        return \"‚ñ∂Ô∏è Demo reminders running (app must stay open).\"\n",
    "\n",
    "    def export_ics():\n",
    "        data = _load_schedule()\n",
    "        if not data:\n",
    "            return \"‚ö†Ô∏è No schedule to export.\"\n",
    "\n",
    "        now = datetime.now()\n",
    "        lines = [\"BEGIN:VCALENDAR\", \"VERSION:2.0\", \"PRODID:-//Healthier at the Desk//EN\"]\n",
    "\n",
    "        for s in data.get(\"schedule\", []):\n",
    "            try:\n",
    "                hour, minute = map(int, s[\"time\"].split(\":\"))\n",
    "                event_time = now.replace(hour=hour, minute=minute, second=0)\n",
    "                summary = \" + \".join(\n",
    "                    r.get(\"text\", \"\") for r in s.get(\"combined_reminders\", [])\n",
    "                )\n",
    "                lines.extend([\n",
    "                    \"BEGIN:VEVENT\",\n",
    "                    f\"DTSTART:{event_time.strftime('%Y%m%dT%H%M%S')}\",\n",
    "                    f\"DTEND:{(event_time + timedelta(minutes=5)).strftime('%Y%m%dT%H%M%S')}\",\n",
    "                    f\"SUMMARY:{summary}\",\n",
    "                    \"END:VEVENT\",\n",
    "                ])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        lines.append(\"END:VCALENDAR\")\n",
    "        out = Path(\"data\") / \"reminder_schedule.ics\"\n",
    "        out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        out.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "        return f\"üìÖ Calendar file exported: {out.name}\"\n",
    "\n",
    "    def open_google_calendar_import():\n",
    "        return (\n",
    "            \"‚úÖ Calendar file ready.\\n\\n\"\n",
    "            \"1Ô∏è‚É£ Click the link below\\n\"\n",
    "            \"2Ô∏è‚É£ Import the exported .ics file\\n\"\n",
    "            \"3Ô∏è‚É£ Choose your Google Calendar\\n\\n\"\n",
    "            f\"üëâ {google_cal_import_url}\"\n",
    "        )\n",
    "\n",
    "    btn_generate.click(\n",
    "        generate_schedule,\n",
    "        inputs=[reminder_df, work_days, start_time, end_time, merge_window],\n",
    "        outputs=[status, schedule_view],\n",
    "    )\n",
    "\n",
    "    btn_run.click(run_reminders_demo, outputs=[status_view])\n",
    "    btn_export.click(export_ics, outputs=[status_view])\n",
    "    btn_google.click(open_google_calendar_import, outputs=[status_view])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a4d6e",
   "metadata": {},
   "source": [
    "Context Tab\n",
    "The Context tab gives the user insight into the summarized context data from each domain. It may list or allow selection of different health domains and display the short summaries (that were generated and saved via update_domain_summary). This helps the user understand what information the AI has \"remembered\" about each area. It might also allow clearing or refreshing context for a domain if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "705f0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def build_context_tab(store, gemini, lang_state: gr.State, locales_dir: Path):\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    gr.Markdown(t(lang, \"context.title\", locales_dir, default=\"Context Memory Viewer\"))\n",
    "\n",
    "    # üîπ Added explanatory line (safe, non-intrusive)\n",
    "    gr.Markdown(\n",
    "        t(\n",
    "            lang,\n",
    "            \"context.description\",\n",
    "            locales_dir,\n",
    "            default=\"This section shows what the system currently remembers and allows selective reset.\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    domain_to_clear = gr.Dropdown(\n",
    "        choices=[\n",
    "            \"baseline\",\n",
    "            \"longitudinal\",\n",
    "            \"msk\",\n",
    "            \"mental\",\n",
    "            \"eye\",\n",
    "            \"hydration\",\n",
    "            \"productivity\",\n",
    "        ],\n",
    "        label=t(lang, \"context.domain_reset\", locales_dir, default=\"Domain to Reset\"),\n",
    "    )\n",
    "\n",
    "    confirm = gr.Checkbox(\n",
    "        label=t(lang, \"context.confirm_delete\", locales_dir, default=\"Confirm Deletion\")\n",
    "    )\n",
    "\n",
    "    status = gr.Textbox(\n",
    "        label=t(lang, \"context.status\", locales_dir, default=\"Status / Current Context\"),\n",
    "        interactive=False,\n",
    "    )\n",
    "\n",
    "    def on_refresh():\n",
    "        ctx = load_context(store)\n",
    "        return json.dumps(ctx, ensure_ascii=False, indent=2)\n",
    "\n",
    "    def on_clear(domain, confirm):\n",
    "        if not domain or not confirm:\n",
    "            return t(\n",
    "                lang,\n",
    "                \"context.select_confirm\",\n",
    "                locales_dir,\n",
    "                default=\"Select a domain and check confirm to clear.\",\n",
    "            )\n",
    "        delete_domain(store, domain)\n",
    "        return t(\n",
    "            lang,\n",
    "            \"context.cleared\",\n",
    "            locales_dir,\n",
    "            default=f\"Cleared context for {domain}.\",\n",
    "            domain=domain,\n",
    "        )\n",
    "\n",
    "    refresh_btn = gr.Button(t(lang, \"common.refresh\", locales_dir, default=\"Refresh\"))\n",
    "    clear_btn = gr.Button(t(lang, \"common.clear\", locales_dir, default=\"Clear\"))\n",
    "\n",
    "    refresh_btn.click(\n",
    "        fn=on_refresh,\n",
    "        inputs=[],\n",
    "        outputs=[status],\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        fn=on_clear,\n",
    "        inputs=[domain_to_clear, confirm],\n",
    "        outputs=[status],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879270be",
   "metadata": {},
   "source": [
    "Reports Tab\n",
    "The Reports tab can generate comprehensive reports based on the user‚Äôs data. For example, the user might request a \"weekly report\" or \"summary report\" from all logged information. The tab will gather data from all relevant JSON files (or use context summaries) and then prompt the AI to produce a structured report (e.g., highlighting progress, issues, and suggestions). This report is displayed to the user as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ac86ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def build_reports_tab(store, gemini, lang_state: gr.State, locales_dir):\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "\n",
    "    gr.Markdown(t(lang, \"reports.title\", locales_dir, default=\"Generate Health Report\"))\n",
    "\n",
    "    # üîπ Added explanatory line (safe, non-intrusive)\n",
    "    gr.Markdown(\n",
    "        t(\n",
    "            lang,\n",
    "            \"reports.description\",\n",
    "            locales_dir,\n",
    "            default=\"Generate high-level summaries from accumulated health context.\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    report_type = gr.Dropdown(\n",
    "        choices=[\"Daily\", \"Weekly\", \"Monthly\"],\n",
    "        label=t(lang, \"reports.type\", locales_dir, default=\"Report Type\"),\n",
    "    )\n",
    "\n",
    "    output = gr.Textbox(\n",
    "        label=t(lang, \"reports.output\", locales_dir, default=\"Generated Report\"),\n",
    "        interactive=False,\n",
    "    )\n",
    "\n",
    "    def on_submit(report_type):\n",
    "        # Load all context summaries\n",
    "        ctx = store.load_json(\"context_summaries.json\", default={}) or {}\n",
    "        prompt = f\"Generate a {report_type.lower()} report from the following context summaries: {ctx}\"\n",
    "        resp = gemini.generate(prompt=prompt, response_language=lang_state.value)\n",
    "        text = resp.text if hasattr(resp, \"text\") else str(resp)\n",
    "        return text\n",
    "\n",
    "    gen_btn = gr.Button(t(lang, \"common.generate\", locales_dir, default=\"Generate\"))\n",
    "    gen_btn.click(fn=on_submit, inputs=[report_type], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d6372e",
   "metadata": {},
   "source": [
    "Settings Tab\n",
    "The Settings tab provides controls for application settings. In this skeleton, it includes the ability to clear all stored data. If the user confirms, the tab deletes the entire data directory (wiping all saved user data) and recreates an empty structure. This is useful for privacy or starting over. (It could also be extended to include language selection or other settings as needed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4efbb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "\n",
    "def build_settings_tab(store, gemini, lang_state: gr.State, locales_dir: Path):\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "    gr.Markdown(\"### \" + t(lang, \"settings.title\", locales_dir, default=\"Settings\") + \"\\n\\n\" + t(lang, \"settings.subtitle\", locales_dir, default=\"Local-only settings for this app.\"))\n",
    "\n",
    "    clear_confirm = gr.Checkbox(\n",
    "        label=t(lang, \"settings.clear_confirm\", locales_dir, default=\"Clear all data (this will delete all saved data!)\")\n",
    "    )\n",
    "\n",
    "    status = gr.Textbox(\n",
    "        label=t(lang, \"common.status\", locales_dir, default=\"Status\"),\n",
    "        interactive=False,\n",
    "    )\n",
    "\n",
    "    def on_clear(confirm):\n",
    "        if not confirm:\n",
    "            return t(lang, \"settings.prompt_confirm\", locales_dir, default=\"Please check the box to confirm data clearance.\")\n",
    "\n",
    "        # Delete the entire data directory\n",
    "        shutil.rmtree(store.data_dir)\n",
    "        store.data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        return t(lang, \"settings.cleared\", locales_dir, default=\"All data cleared.\")\n",
    "\n",
    "    clear_btn = gr.Button(t(lang, \"common.clear\", locales_dir, default=\"Clear\"))\n",
    "    clear_btn.click(\n",
    "        fn=on_clear,\n",
    "        inputs=[clear_confirm],\n",
    "        outputs=[status],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee01fe",
   "metadata": {},
   "source": [
    "Help Tab\n",
    "The Help tab displays instructions and information on how to use the application. It contains static Markdown text explaining the features of the app, guidance on using each tab, and reassurance about privacy (e.g., that data is stored locally). This helps users understand the purpose and usage of the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63599eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "\n",
    "def build_help_tab(store, gemini, lang_state: gr.State, locales_dir: Path):\n",
    "    lang = lang_state.value if hasattr(lang_state, \"value\") else lang_state\n",
    "    gr.Markdown(t(lang, \"help.md\", locales_dir, default=\"\"\"### Help\n",
    "\n",
    "**Important Notes:**\n",
    "\n",
    "- **Privacy:** All your inputs and data are stored *locally* on your device. Nothing is sent to any server (unless you enable the Gemini AI with an API key, which then sends prompts to the model).\n",
    "- **Using the Tabs:** Each tab focuses on a different aspect of your health or the app's functionality. Fill in the inputs and click the submit/generate buttons to interact.\n",
    "- **AI Recommendations:** The suggestions provided by the AI (Gemini) are not medical advice. They are for informational purposes. Always consult a professional for serious health concerns.\n",
    "- **Extensibility:** This is a starter skeleton. You can extend each tab or integrate an actual AI API for more personalized and accurate insights.\n",
    "\n",
    "Use the Settings tab to clear your data anytime. We hope this tool helps you maintain a healthier workday!\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116371d5",
   "metadata": {},
   "source": [
    "Launching the Application\n",
    "Now that all components (configuration, core modules, and tabs) have been defined in the notebook, we can launch the Gradio application. Normally, running app.py directly would start the server. In this notebook, we manually construct the app and launch it.\n",
    "Running the code below will instantiate the Gradio interface and launch it on the default local server (by default at 127.0.0.1:7860). In a Jupyter environment, Gradio will either display an interactive widget or provide a link to open the interface in a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c61e643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def build_app():\n",
    "    \"\"\"\n",
    "    Assemble the Gradio application.\n",
    "    Assumes all tab builder functions and shared objects\n",
    "    (TAB_BUILDERS, t(), LocalStore, GeminiClient, etc.) already exist.\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Local data store (defined ONCE here)\n",
    "    # -----------------------------\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    DATA_DIR.mkdir(exist_ok=True)\n",
    "    store = LocalStore(DATA_DIR)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Gemini / LM client (defined ONCE here)\n",
    "    # -----------------------------\n",
    "    client = GeminiClient()\n",
    "\n",
    "    LOCALES_DIR = Path(\"locales\")\n",
    "\n",
    "    # Build-time language (UI labels are rendered at build time)\n",
    "    lang = DEFAULT_LANG if \"DEFAULT_LANG\" in globals() else \"en\"\n",
    "\n",
    "    TAB_TITLE_KEYS = {\n",
    "        \"Baseline\": \"tab.baseline\",\n",
    "        \"Workspace\": \"tab.workspace\",\n",
    "        \"Longitudinal\": \"tab.longitudinal\",\n",
    "        \"MSK\": \"tab.msk\",\n",
    "        \"Eye\": \"tab.eye\",\n",
    "        \"Mental\": \"tab.mental\",\n",
    "        \"Hydration\": \"tab.hydration\",\n",
    "        \"Productivity\": \"tab.productivity\",\n",
    "        \"Recovery / Sleep\": \"tab.recovery_sleep\",\n",
    "\n",
    "        # Optional localization support\n",
    "        \"Checklist\": \"tab.checklist\",\n",
    "        \"Reminders\": \"tab.reminders\",\n",
    "\n",
    "        \"Context\": \"tab.context\",\n",
    "        \"Reports\": \"tab.reports\",\n",
    "        \"Settings\": \"tab.settings\",\n",
    "        \"Help\": \"tab.help\",\n",
    "    }\n",
    "\n",
    "    with gr.Blocks(\n",
    "        title=t(\n",
    "            lang,\n",
    "            \"app.title\",\n",
    "            LOCALES_DIR,\n",
    "            default=APP_NAME if \"APP_NAME\" in globals() else \"Workday Health Reasoning Platform\",\n",
    "        )\n",
    "    ) as demo:\n",
    "\n",
    "        # Language state (used for model response language)\n",
    "        lang_state = gr.State(lang)\n",
    "\n",
    "        # -----------------------------\n",
    "        # App header\n",
    "        # -----------------------------\n",
    "        gr.Markdown(\n",
    "            f\"# {t(lang, 'app.title', LOCALES_DIR, default='Workday Health Reasoning Platform')}\"\n",
    "        )\n",
    "        gr.Markdown(\n",
    "            t(\n",
    "                lang,\n",
    "                \"app.subtitle\",\n",
    "                LOCALES_DIR,\n",
    "                default=\"Privacy-first, local-only, context-aware health assistant for desk workers.\",\n",
    "            )\n",
    "        )\n",
    "        gr.Markdown(\n",
    "            t(\n",
    "                lang,\n",
    "                \"msg.local_only\",\n",
    "                LOCALES_DIR,\n",
    "                default=\"All data is stored locally on this device. Nothing is uploaded unless you call the model.\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # -----------------------------\n",
    "        # App-level introduction (collapsible)\n",
    "        # -----------------------------\n",
    "        with gr.Accordion(\"‚ÑπÔ∏è About this app\", open=False):\n",
    "            gr.Markdown(ABOUT_APP_MD)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Main tabs\n",
    "        # -----------------------------\n",
    "        # Support notebooks where TAB_BUILDERS is defined in a different cell.\n",
    "        TAB_BUILDERS_LOCAL = globals().get(\"TAB_BUILDERS\", [])\n",
    "        with gr.Tabs():\n",
    "            for title, builder in TAB_BUILDERS_LOCAL:\n",
    "                key = TAB_TITLE_KEYS.get(title)\n",
    "                tab_label = t(lang, key, LOCALES_DIR, default=title) if key else title\n",
    "\n",
    "                with gr.TabItem(tab_label):\n",
    "                    builder(\n",
    "                        store=store,\n",
    "                        gemini=client,\n",
    "                        lang_state=lang_state,\n",
    "                        locales_dir=LOCALES_DIR,\n",
    "                    )\n",
    "\n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c890b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Tab registry (notebook version)\n",
    "# Ordered for clarity, reasoning flow, and judging\n",
    "# -------------------------------------------------\n",
    "\n",
    "TAB_BUILDERS = [\n",
    "    # 1Ô∏è‚É£ Action Center (cross-domain synthesis)\n",
    "    (\"General Recommendations\", build_global_recommendations_tab),\n",
    "    (\"Ask AI\", build_general_chat_tab),\n",
    "\n",
    "\n",
    "    # 2Ô∏è‚É£ Core user inputs\n",
    "    (\"Baseline\", build_baseline_tab),\n",
    "    (\"Workspace\", build_workspace_tab),\n",
    "    (\"Longitudinal\", build_longitudinal_tab),\n",
    "\n",
    "    # 3Ô∏è‚É£ Health domains\n",
    "    (\"MSK\", build_msk_tab),\n",
    "    (\"Eye\", build_eye_tab),\n",
    "    (\"Mental\", build_mental_tab),\n",
    "    (\"Hydration\", build_hydration_tab),\n",
    "    (\"Productivity\", build_productivity_tab),\n",
    "    (\"Recovery / Sleep\", build_recovery_sleep_tab),\n",
    "\n",
    "    # 4Ô∏è‚É£ Actions & planning  ‚úÖ NEW\n",
    "    (\"Checklist\", build_checklist_tab),\n",
    "    (\"Reminders\", build_reminders_tab),\n",
    "\n",
    "    # 5Ô∏è‚É£ Transparency & outputs\n",
    "    (\"Context\", build_context_tab),\n",
    "    (\"Reports\", build_reports_tab),\n",
    "\n",
    "    # 6Ô∏è‚É£ System / support\n",
    "    (\"Settings\", build_settings_tab),\n",
    "    (\"Help\", build_help_tab),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc246dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\general_recommendations_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\tasks_reminders_user_input.json\n",
      "[baseline] ‚úÖ build_baseline_tab executed. user_file=baseline_user_input.json, ai_file=baseline_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\baseline_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\baseline_ai_output.json\n",
      "[baseline] load user=baseline_user_input.json ai=baseline_ai_output.json\n",
      "[workspace] ‚úÖ build_workspace_tab executed. user_file=workspace_user_input.json, ai_file=workspace_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\workspace_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\workspace_ai_output.json\n",
      "[workspace] load user=workspace_user_input.json ai=workspace_ai_output.json\n",
      "[longitudinal] ‚úÖ build_longitudinal_tab executed\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\longitudinal_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\longitudinal_ai_output.json\n",
      "[longitudinal] load user=longitudinal_user_input.json ai=longitudinal_ai_output.json\n",
      "[msk] ‚úÖ build_msk_tab executed. user_file=msk_user_input.json, ai_file=msk_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\msk_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\msk_ai_output.json\n",
      "[msk] load user=msk_user_input.json ai=msk_ai_output.json\n",
      "[eye] ‚úÖ build_eye_tab executed. user_file=eye_user_input.json, ai_file=eye_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\eye_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\eye_ai_output.json\n",
      "[eye] load user=eye_user_input.json ai=eye_ai_output.json\n",
      "[mental] ‚úÖ build_mental_tab executed. user_file=mental_user_input.json, ai_file=mental_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\mental_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\mental_ai_output.json\n",
      "[mental] load user=mental_user_input.json ai=mental_ai_output.json\n",
      "[hydration] ‚úÖ build_hydration_tab executed. user_file=hydration_user_input.json, ai_file=hydration_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\hydration_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\hydration_ai_output.json\n",
      "[hydration] load user=hydration_user_input.json ai=hydration_ai_output.json\n",
      "[productivity] ‚úÖ build_productivity_tab executed. user_file=productivity_user_input.json, ai_file=productivity_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\productivity_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\productivity_ai_output.json\n",
      "[productivity] load user=productivity_user_input.json ai=productivity_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\recovery_sleep_user_input.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\recovery_sleep_ai_output.json\n",
      "[recovery_sleep] load user=recovery_sleep_user_input.json ai=recovery_sleep_ai_output.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\checklist.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\global_context_summary.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\tasks_reminders_list.json\n",
      "[LocalStore] ‚úÖ JSON loaded: F:\\research projects\\AI\\HealthierAtDesk_SUBMIT\\data\\tasks_reminders_list.json\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build and launch the Gradio app (this will start a local server for the UI)\n",
    "app = build_app()\n",
    "app.launch(server_name=\"127.0.0.1\",  show_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After launching, you should see the UI accessible at the above address. You can interact with all the tabs as described. All data you input will be saved to the data directory locally, and you can stop the server by interrupting the notebook kernel or closing the app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3d172",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
